---
title: "FUNDAMENTOS ESTADISTICA R"
author: "EJERCICIO"
date: '2021'
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = 'C:/Users/mbarrios/Desktop/2018_MEDSF/2021_MEDS/R/Wine')
```
## 1 Introduction

This is a short lab on Statistical Inference with R.  
Through the lab you will practice R Base comands for:  

* Sampling from a (population) dataset:  random amd stratified sampling
* Frequencies: absolute and relative
* Descriptive statistics:  
    + Measures of Center: mean, median, mode
    + Order Satistics and Quantiles: quantiles and quartiles
    + Measures of Spread: Variance, Standard Deviation, Interquartile Range, Median Absolute Deviation
    + Measures of Shape: Skewness, Kurtosis
* Common Distributions
    + Bernoulli
    + Binomial
    + Poisson
    + Normal
* Parameter Estimation
    + Point estimation
    + Interval estimation
* Hipothesis Testing
    + 1-way test
    + 2-way test
  

## 2 Preparing the Data  

We are going to work with the classical wine quality datasets <https://archive.ics.uci.edu/ml/datasets/Wine+Quality>.  
Load both datasets (red and white wine), join them and see the variables inside:
```{r working data}
redwine = read.table(file="winequality-red.csv", na.strings=c("", "NA"), sep=";", header = TRUE) 
redwine$color = "red"
whitewine = read.table(file="winequality-white.csv", na.strings=c("", "NA"), sep=";", header = TRUE) 
whitewine$color = "white"
wine = rbind(redwine, whitewine)
str(wine)
```

The variable "alcohol" has been wrongly loaded as categorical; need to correct (coerce to numeric)
```{r}
wine$alcohol = as.numeric(wine$alcohol)
typeof(wine$alcohol)
```

Also, we need to create a new variable "class" acording to the wine quality:  

* class = "excellent", if quality > 7
* class = "good", if quality in == 7
* class = "regular", if quality in [5, 6]
* class = "poor", if quality < 5
```{r}
wine$class = "nothing yet"
wine$class[ wine$quality %in% c(8,9) ] = "1 Excellent"
wine$class[ wine$quality == 7 ] = "2 Good"
wine$class[ wine$quality %in% c(5,6) ] = "3 Regular"
wine$class[ wine$quality <= 4 ] = "4 Poor"
str(wine)
summary(wine)
```

Let's see some frequency tables to understand the data 
```{r}
table(wine$quality)
table(wine$class)
table(wine$color)
table(wine$color, wine$class)
```

Now we are ready to play!


## 3 Sampling  

### 3.1. Random Sampling

A random sample means that each element/row of the original dataset, has the same probability of being sampled/extracted.   

In order to extract a random sample from a dataset, we need to sample the row indexes of the dataset. An then extract that sampled rows.  

Here we extract a random sample of size=6 
```{r}
set.seed(1) # use a seed to extrat the same random sample each time you run this code
index_sample = sample(x = 1:nrow(wine), size = 6)
wine_sample_rnd = wine[index_sample, ]
wine_sample_rnd
```


### 3.2. Stratified Sampling

A stratified sample is always defined for a categorical variable (or set of categorical variables), commonly named as strata. Then, for the data inside each possible category a random sample is extracted.  

In order to extract a stratified sample from a dataset, we need to:  
0. Load the "sampling" library
1. Define the strata variables
2. Sort the dataset according to the strata variables (this is important to later define the sample sizes)
3. See the cross-categories for the strata variables (after sorting)
4. Define the sample size for each category
5. Run the stratified sampling

let's do a simple example using the variable "color" as  strata
```{r}
# 0. Load the "sampling" library
library(sampling)
# 1. Define the strata variables
strata_vars = c("color")
# 2. Sort the dataset according to the strata variables
wine = wine[ order(wine[ ,strata_vars]), ]
# 3. See the cross-categories for the strata variables
table(wine[strata_vars])
# 4. Define the sample size for each category (2 reds and 5 wines)
stratum_size = c(2, 5)
# 5. Run the stratified sampling
st = strata(data = wine, stratanames = strata_vars, size = stratum_size, method="srswor")
wine_sample_str = getdata(wine, st)
wine_sample_str
table(wine_sample_str[strata_vars])
```

Now let's do something more complex: using the strata variables "color" and "class" make a stratified sample of size:   

* red-excellent = 1,
* red-good = 2,
* red-regular = 3,
* red-poor = 4,
* white-excellent = 5,
* white-good = 6,
* white-regular = 7, and finally
* white-poor = 8
```{r}
# 0. Load the "sampling" library
library(sampling)
# 1. Define the strata variables
strata_vars = c("color", "class")
# 2. Sort the dataset according to the strata variables
wine = wine[  order(wine[ ,strata_vars[1]], wine[ ,strata_vars[2]]), ]
# 3. See the cross-categories for the strata variables
table(wine[strata_vars])
# 4. Define the sample size for each category 
stratum_size = c(1, 2, 3, 4, 5, 6, 7, 8)
# 5. Run the stratified sampling
st = strata(data = wine, stratanames = strata_vars, size = stratum_size, method="srswor")
wine_sample_str2 = getdata(wine, st)
table(wine_sample_str2[strata_vars])
```
NOTE that you need to sort the data according to the strata variables and then define the sample size for each stratum using that order   

## 4 Frequencies for categorical variables   

### 4.1. Absolute frequencies   
Frequency table for the categorical variable "color"
```{r}
table(wine$color)
```

Frequency table for the categorical variable "color" X "class"
```{r}
table(wine$color, wine$class)
```


### 4.2. Relative frequencies   
Relative frequency table for the categorical variable "color"
```{r}
prop.table(table(wine$color))
```

Relative frequency table for the categorical variable "color" X "class"
```{r}
prop.table(table(wine$color, wine$class))
```
## 5. Descriptive Statistics   
The summary() function in R gives some descriptive statistics for each variable in a dataset   
```{r}
summary(wine, na.rm = T)
```

### 5.1. Measures of Center   

#### Mean
Let's calculate the mean quality
```{r}
mean(wine$quality, na.rm = T)
```
Now let's calculate the mean for all numerical variables 
```{r}
numeric_cols = sapply(wine, is.numeric)
apply(X = wine[, numeric_cols], MARGIN = 2, FUN = mean, na.rm = T)
```

What is the quality mean by color?
```{r}
aggregate(wine[, c("quality")], list(wine$color), mean, na.rm=T)
```

What is the quality mean by color and class?
```{r}
aggregate(x = wine$quality, list( wine$class, wine$color), mean, na.rm=T)
```

#### Weighted Arithmetic Mean   

EXAMPLE: Given the average salary (in thousands of €) of the workers in a group of seven companies, salary = (20, 25, 27, 30, 19, 29, 33), what is the average salary for all the workers, knowing that the number of workers per company are n = (1500, 400, 380, 333, 5050, 1350, 300)?   
```{r}
salary = c(20, 25, 27, 30, 19, 29, 33)
n = c(1500, 400, 380, 333, 5050, 1350, 300)
weighted.mean(x = salary, w = n)
```

#### Median
Let's calculate the median quality
```{r}
median(wine$quality, na.rm = T)
```
Now let's calculate the median for all numerical variables 
```{r}
numeric_cols = sapply(wine, is.numeric)
apply(X = wine[, numeric_cols], MARGIN = 2, FUN = median, na.rm = T)
```

What is the quality median by color?
```{r}
aggregate(wine[, c("quality")], list(wine$color), median, na.rm=T)
```

What is the quality median by color and class?
```{r}
aggregate(x = wine$quality, list( wine$class, wine$color), median, na.rm=T)
```


#### Mode
Let's calculate the mode for quality
```{r}
w = table(wine$quality)
w[max(w)==w] 
```

Let's calculate the mode for alcohol
```{r}
w = table(wine$alcohol)
w[max(w)==w] 
```

### 5.2. Order Satistics and Quantiles   

The P-order statistics for a variable (with 0 < p < 1) is the variable value that has a p-% of observations smaller than itself.   

The most important order statistics are:   

* 1st Quartile, p=0.25
* 2nd Quartile, p=0.50
* 3th Quartile, p=0.75   

Let's calculate the order statistics with p = (0,01, 0.25, 0.50, 0.75, 0.99) for the variable "residual.sugar"
```{r}
quantile(wine$residual.sugar, probs = c(0.01, 0.25, 0.50, 0.75, 0.99))
```
The median is the 50% quantile
```{r}
median(wine$residual.sugar, na.rm = T)
```

What is the residual.sugar 25%-quantile by color?
```{r}
aggregate(x = wine$residual.sugar, list(wine$color), function(x) {quantile(x, probs = 0.25)})
```

### 5.3. Measures of Spread   

#### Standard Deviation (Sample Variance)  
The variance measures the mean squared distance from each observation to the sample mean.   

Let's calculate the standard deviation of quality
```{r standard deviation}
sd(wine$quality, na.rm = T)
```
Let's calculate the variance of quality
```{r}
var(wine$quality, na.rm = T)
```

Now let's calculate the sd and variance for all numerical variables 
```{r}
numeric_cols = sapply(wine, is.numeric)
# standard deviation
apply(X = wine[, numeric_cols], MARGIN = 2, FUN = sd, na.rm = T)
# variance
apply(X = wine[, numeric_cols], MARGIN = 2, FUN = var, na.rm = T)
```

What is the variance of residual.sugar by color?
```{r}
aggregate(wine[, c("residual.sugar")], list(wine$color), var, na.rm=T)
```

What is the standard deviation of residual.sugar by color and class?
```{r}
aggregate(x = wine$residual.sugar, list( wine$class, wine$color), sd, na.rm=T)
```

#### Interquartile Range (IQR)   
The Inter-Quantile Range (IQR) is the distance between the 1st and 3td Quartiles.   

What is the IQR (interquartile range) for residual.sugar
```{r}
IQR(wine$residual.sugar)
```

What is the IQR for residual.sugar by color
```{r}
aggregate(x = wine$residual.sugar, list(wine$color), IQR, na.rm=T)
```


#### Median Absolute Deviation (MAD)   
The Median Absolute Deviation (MAD) measures the median absolute distance from each observation to the sample median. 

What is the MAD for residual.sugar
```{r}
mad(wine$residual.sugar)
```

What is the MAD for residual.sugar by color
```{r}
aggregate(x = wine$residual.sugar, list(wine$color), mad, na.rm=T)
```


### 5.4. Measures of Shape   

#### Skewness   
The sample skewness measures how symmetric is a variable related to its mean. When the absolute value of the Skewness is grater than 2*√(6/n), the variable is said to be strongly asymmetric. The sign of the Skewness indicates the direction of the asymmetry: left (-) or right (+).   

Let's calculate the Skewness of residual.sugarity
```{r}
library(e1071)
skewness(wine$residual.sugar)
```


#### Kurtosis   (Kurtosis(N(0,1))=3, if 3 is substracted, it's excess of kurtosis
Measures if the data is concentrated around the sample mean:   

* Kurtosis > 0, are called leptokurtic
* Kurtosis < 0 are called platykurtic
* Kurtosis = 0, are called mesokurtic


Let's calculate the Kurtosos of residual_sugarity
```{r}
library(e1071)
kurtosis(wine$residual.sugar)
```

## 6. Common Distributions   

### 6.1. Bernoulli   
A Bernoulli trial is a random experiment in which there are only two possible outcomes: success (with probability p) and failure (with probability q = 1 - p).   

A Bernoulli distribution is a especial case of the Binomial distribution, when the number of trials is n = 1.

### 6.2. Binomial   
EXAMPLE: A four-child family. Each child may be either a boy (B) or a girl (G). For simplicity
we suppose that P(B) = P(G) = 0.5 and that the genders of the children are determined independently.
If we let X count the number of B’s, then X ~ binom(size = 4; prob = 0.5).

Calculate the probability for each possible outcome B's = [0, 1, 2, 3, 4]
```{r}
n  = 4
p = 0.5
dbinom(0:n, size = n, prob = p) # probability density distribution
```

Calculate the probability of having 2 or less B's
```{r}
sum(dbinom(0:2, size = n, prob = p)) # probability density distribution
```

Calculate the mean for B's
```{r}
vals = 0:n
probs = dbinom(vals, size = n, prob = p) # probability density distribution
weighted.mean(x = vals, w = probs)
```
Note that the mean is n*p.   

Calculate the median for B's
```{r}
qbinom(0.5, size = n, prob = p) # find the value for that cumulative probability
```

Generates 25 random values from the distribution above: X ~ binom(size = 4; prob = 0.5).
```{r}
rbinom(25, size = n, prob = p) # generate random numbers
```


### 6.3. Poisson   
Poisson distribution was designed to model “events” like:   

* customers arriving in to a queue (supermarket, bank, call center, ...).
* traffic accidents

EXAMPLE: At a supermaket queue, on the average, 3 customers arrive at the queue every 10 minutes. Let X count the
number of customers that arrive per minute. Then X ~ pois(lambda = 3/10).  

What is the probability that no customer arrives during one minute?
```{r}
myLambda = 3/10
dpois(x = 0, lambda = myLambda) # probability density distribution
```

What is the probability that at least 5 customers arrive in 15 minutes?
```{r}
myLambda_10 = (3/10)*15 # arrival rate for 15 minutes
1 - sum(dpois(x = 0:4, lambda = myLambda_10) )
1 - ppois(q = 4, lambda = myLambda_10) # is the same
```

Calculate the mean for X ~ pois(lambda = 3/10)
```{r}
vals = 0:1000
probs = dpois(vals, lambda = myLambda)
weighted.mean(x = vals, w = probs)
```
Note that the mean is lambda.   

Calculate the median for X ~ pois(lambda = 3/10)
```{r}
qpois(0.5, lambda = myLambda)
```

Generates 25 random values from the distribution above: X ~ Pois(lambda = 3/10).
```{r}
rpois(25, lambda = myLambda) # generate random numbers
```


### 6.4. Normal   
What is the probabilty of finding a person with height between 190cm and 210cm, in a population where the height mean is 175cm and the standard deviation is 11   
```{r}
mu = 175
sigma = 11
pnorm(q = 210, mean = mu, sd = sigma) - pnorm(q = 190, mean = mu, sd = sigma)
```
And the probability of finding a person with height higher than 210cm
```{r}
1 - pnorm(q = 210, mean = mu, sd = sigma)
```
Napoleon says that 85% of the people is higher than him, what is his height?
```{r}
qnorm(p = 1-0.85, mean = mu, sd = sigma)
```

## 7. Parameter Estimation   

### 7.1. Point estimation   
Assuming that the wine residual_sugar follows a normal distribution, estimate the parameter (mean, standard deviation)   
```{r}
mu = mean(wine$residual.sugar, na.rm = T)
mu
sd = sd(wine$residual.sugar, na.rm = T)
sd
```
What is the probability of finding a wine with residual.sugar > 0.45?   
```{r}
1 -  pnorm(q = 0.45, mean = mu, sd = sd)
```


### 7.2. Interval estimation
Find the shortest interval that contains a 95% of the possible values for residual_sugar
```{r}
prob = 0.95
p_lb = (1-prob)/2
lb = qnorm(p = p_lb, mean = mu, sd = sd)
paste("lb = ", lb)
p_ub = 1 - p_lb
ub = qnorm(p = p_ub, mean = mu, sd = sd)
paste("ub = ", ub)
# check results
pnorm(q = ub, mean = mu, sd = sd) - pnorm(q = lb, mean = mu, sd = sd)
```

## 8. Hipothesis Testing   

### 8.1. One-sample Test for the mean   

###  Population variance $\sigma^2$ is known

EXAMPLE: The population mean for wine residual_sugar is known to be $\mu=5.5$ and the population variance $\sigma^2=16$   

Remember that for this case:
$$Z=\frac{\overline{x}-\mu_0}{\frac{\sigma}{\sqrt{n}}} \sim N(0,1)$$

Is the wine residual.sugar from the Minho region (your wine dataset) statisticallly different than the population mean at a 10% significant level
```{r}
# H0: mu = 5.5
# H1: mu <> 5.5
#install.packages("TeachingDemos")
library(TeachingDemos) # needed for z.test()
pop_mu = 5.5
pop_sd = sqrt(16)
significant_level = 0.10
z.test(x = wine$residual.sugar, mu = pop_mu, sd = pop_sd, 
       conf.level = 1- significant_level, alternative = "two.sided")
```
The p-value is high, 0.2527, so we accept H0. Also you can see that the population mean 5.5 is inside the confidence interval built for the sample mean (5.36, 5.52), so we must accept H0. There is statistical evidence (90%) to accept H0: residual.sugar for Minho wine is similar to the one from the whole population of wines   

Is the wine residual.sugar from the Minho region, smaller than the population mean at a 5% significant level
```{r}
# H0: mu = 5.5
# H1: mu < 5.5
pop_mu = 5.5
pop_sd = sqrt(16)
significant_level = 0.05
z.test(x = wine$residual.sugar, mu = pop_mu, sd = pop_sd, 
       conf.level = 1- significant_level, alternative = "less")
```
The p-value is high, 0.1263, so we accept H0. Also you can see that the population mean 5.5 is inside the confidence interval built for the sample mean (-Inf, 5.525), so we must accept H0. There is statistical evidence (95%) to accept H0: residual.sugar for Minho wine is similar (is NOT smaller) to the one from the whole population of wines   


###  Population variance  $\sigma2$ is unknown   

When $\sigma$ is unknown:
$$T=\frac{\overline{x}-\mu_0}{\frac{s}{\sqrt{n}}} \sim t_{n-1}$$

Is the wine residual.sugar from the Minho region (your wine dataset) statisticallly different than the population mean at a 10% significant level
```{r}
# H0: mu = 5.5
# H1: mu <> 5.5
pop_mu = 5.5
significant_level = 0.10
t.test(x = wine$residual.sugar, mu = pop_mu, conf.level = 1- significant_level, alternative = "two.sided")
```
The p-value is high, 0.3362, so we accept H0. Also you can see that the population mean 5.5 is inside the confidence interval built for the sample mean (5.346, 5.540), so we must accept H0. There is statistical evidence (90%) to accept H0: residual_sugar for Minho wine is similar to the one from the whole population of wines   

Is the wine residual_sugar from the Minho region, smaller than the population mean at a 5% significant level
```{r}
# H0: mu = 5.5
# H1: mu < 5.5
pop_mu = 5.5
significant_level = 0.05
t.test(x = wine$residual.sugar, mu = pop_mu, conf.level = 1- significant_level, alternative = "less")
```
The p-value is high, 0.1681, so we accept H0. Also you can see that the population mean 5.5 is inside the confidence interval built for the sample mean (-Inf, 5.540), so we must accept H0. There is statistical evidence (95%) to accept H0: residual_sugar for Minho wine is similar (is NOT smaller) to the one from the whole population of wines   


### 8.2. Two-samples Test for the mean   
EXAMPLE: is the residual_sugar for red wine different to the one of white wine ($\alpha=0.05 $)
```{r}
# H0: mu_red = mu_white (or mu_red - mu_white = 0)
# H1: mu_red <> mu_white (or mu_red - mu_white <> 0)
significant_level = 0.05
t.test(residual.sugar ~ color, data = wine, paired = F, conf.level = 1- significant_level)
```
The p-value is small, 2.2e-16, so we reject H0. Also you can see that 0 (population difference) is NOT inside the confidence interval built for the difference of the two sample means (-4.01, -3.69), so we must reject H0. There is statistical evidence (95%) to reject H0: residual_sugar for Minho red wine is different to the one of white wine


### 8.3. One-sample Test for proportions   
EXAMPLE: The proportion of excellent wines in the world is 5%. Is the proportion of excellent wines at Minho smaller than 5% (use $\alpha=0.01$)?
```{r}
# H0: p = 0.05
# H0: p < 0.05
pop_p = 0.05
num_excellent = sum(wine$class=="1 Excellent")
num_total = nrow(wine)
significant_level = 0.01
prop.test(x = num_excellent, n = num_total, p = pop_p, 
          alternative = "less", conf.level = 1- significant_level, correct = FALSE)
```
The p-value is very low, 2.584e-13, so we reject H0. Also you can see that 0.05 (population proportion) is NOT inside the confidence interval built for the proportion (0.000, 0.036), so we must reject H0. There is statistical evidence (99%) to reject H0: the proportion of excellent wines is significantly smaller than 5%

### 8.5. Goodness-of-Fit Test Kolmogorov-Smirnov   
Is the distribution of residual.sugar a Normal one 
```{r}
ks.test(wine$residual.sugar, "pnorm")
```
The p-value is very low, so we reject the null hypothesis H0: Residual_sugar does not follow a normal distribution.   

Also, you can compare the histogram for residual.sugar and a normal distribution with the same mean and variance
```{r}
m = mean(wine$residual.sugar)
std = sqrt(var(wine$residual.sugar))
hist(wine$residual.sugar, density=10, breaks=50, prob=TRUE, 
xlab="residual.sugar", ylim=c(0, 0.5), xlim=c(0, 30), 
main="normal curve over histogram")
curve(dnorm(x, mean=m, sd=std), 
      col="darkblue", lwd=2, add=TRUE)
```


