{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark ML - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import findspark\n",
    "import findspark\n",
    "\n",
    "# Configure the environment\n",
    "findspark.init()\n",
    "\n",
    "# Import the Spark components required for the session creation\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Configure and create the session\n",
    "conf = SparkConf()\n",
    "conf = conf.setAppName('mds-session')\n",
    "conf = conf.setMaster('local[*]')\n",
    "spark = SparkSession.builder.config(conf = conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import pandas as pd\n",
    "from plotnine import *\n",
    "from plotnine import options as plot_options\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import (\n",
    "    KMeans\n",
    ")\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a sample CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a sample data set\n",
    "data = spark.read.options(sep=',', header=True, inferSchema=True).csv('./data/housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the assembler\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "\n",
    "# Apply the transformation\n",
    "vectorized_data = assembler.transform(data)\n",
    "\n",
    "# Check the transformed data\n",
    "vectorized_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KMeans clustering\n",
    "kmeans = KMeans(\n",
    "    featuresCol='features',\n",
    "    predictionCol='cluster',\n",
    "    k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trained_kmeans = kmeans.fit(vectorized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the predictions\n",
    "predictions = trained_kmeans.transform(vectorized_data)\n",
    "\n",
    "# Create the evaluator\n",
    "evaluator = ClusteringEvaluator(predictionCol='cluster', featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the clustering quality\n",
    "silhouette = evaluator.evaluate(predictions, {evaluator.metricName: 'silhouette'}) \n",
    "\n",
    "# Display model metrics\n",
    "print(f'Silhouette: {silhouette}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cluster frequencies\n",
    "frequencies = predictions.groupBy('cluster').count().toPandas()\n",
    "\n",
    "(\n",
    "    ggplot(frequencies, aes(x='cluster', y='count', fill='cluster')) + geom_bar(stat='identity')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the explanation of the clusters\n",
    "cluster_explanation = predictions.groupby('cluster').agg(*[F.mean(col).alias(col) for col in features]).toPandas()\n",
    "cluster_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the explanation of the clusters\n",
    "cluster_explanation = cluster_explanation.assign(cluster = cluster_explanation.cluster.astype(str))\n",
    "cluster_explanation = cluster_explanation.melt(id_vars='cluster')\n",
    "current_fig_size = plot_options.figure_size\n",
    "plot_options.figure_size = (4, 30)\n",
    "(\n",
    "    ggplot(cluster_explanation, aes(x='cluster', y='value', fill='cluster')) + \n",
    "        geom_bar(stat='identity') + \n",
    "        facet_wrap('~variable', scales='free', ncol=1)\n",
    ").draw()\n",
    "plot_options.figure_size = current_fig_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
