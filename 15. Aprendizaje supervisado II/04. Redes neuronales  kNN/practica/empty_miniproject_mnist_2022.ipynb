{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Submission Instructions\n",
    "\n",
    "Just fill in the markdown and code cells below with your arguments and functions, and run the Python lines given. Make sure the notebook works fine by executing `Kernel/Restart & Run All`.\n",
    "  \n",
    "Once the notebook is ready,\n",
    "1. Create a folder named `ftdl_last_name1_last_name2` with the team's last names.\n",
    "\n",
    "2. Put in that folder:\n",
    "\n",
    "* a file `mp_ftdl_last_name1_last_name2.ipynb` with the cells below completed. Make sure it works by executing Kernel/Restart & Run All.\n",
    "* a file `mp_ftdl_last_name1_last_name2.html` with an html rendering of the previous .ipynb file (just apply File / Download as HTML after a correct run of Kernel/Restart & Run All).\n",
    "* a file `mp_ftdl_last_name1_last_name2.pdf` with a pdf print of the html file **without any code**.\n",
    "\n",
    "3. Compress the folder to a `ftdl_last_name1_last_name2.7z` 7z (or zip) file.\n",
    "\n",
    "**Very important!!!**\n",
    "\n",
    "Make sure you follow the file naming conventions above; the miniproject won't be graded until that is so."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recommendations in notebook writing\n",
    "\n",
    "Notebooks are a great tool for data and model exploration. But in that process a lot of Python garbage can get into them as a consequence of the trial and error process.\n",
    "\n",
    "But once these tasks are done and one arrives to final ideas and insights on the problem under study, the notebook should be **thoroughly cleaned** and the notebook should **concentrate on the insights and conclussions** without, of course, throwing away the good work done.\n",
    "\n",
    "Below there are a few guidelines about this.\n",
    "\n",
    "* Put the useful bits of your code as functions on a **Python module** (plus script, if needed) that is imported at the notebook's beginning. \n",
    "* Of course that module should be **properly documented** and **formatted** (try to learn about PEP 8 if you are going to write a lot of Python).\n",
    "* Leave in the notebook **as little code as possible**, ideally one- or two-line cells calling a function, plotting results or so on.\n",
    "* **Avoid boilerplate code**. If needed, put it in a module.\n",
    "* Put on the notebook some way to **hide/display the code** (as shown below).\n",
    "* The displayed information **should be just that, informative**. So forget about large tables, long output cells, dataframe or array displays and so on.\n",
    "* Emphasize **insights and conclusions**, using as much markdown as needed to clarifiy and explain them.\n",
    "* Make sure that **number cells consecutively starting at 1.**\n",
    "* And, of course, make sure that **there are no errors left**. To avoid these last pitfalls, run `Kernel\\Restart Kernel and Run All Cells`.\n",
    "\n",
    "And notice that whoever reads your notebook is likely to toggle off your code and consider just the markdown cells. Because of this, once you feel that your notebook is finished,\n",
    "* let it rest for one day, \n",
    "* then open it up, toggle off the code \n",
    "* and read it to check **whether it makes sense to you**.\n",
    "\n",
    "If this is not the case, **the notebook is NOT finished!!!**\n",
    "\n",
    "Following these rules you are much more likely to get good grades at school (and possibly also larger bonuses at work)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**IMPORTANT: before turning in your work, please REMOVE FROM IT THE PREVIOUS TWO CELLS**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''\n",
    "<script>code_show=true; \n",
    "\n",
    "function code_toggle() {\n",
    "    if (code_show){\n",
    "    $('div.input').hide();\n",
    "    } else {\n",
    "    $('div.input').show();\n",
    "    }\n",
    "    code_show = !code_show\n",
    "} \n",
    "\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to show or hide your raw code.\"></form>\n",
    "''')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The MNIST Problem\n",
    "\n",
    "The MNIST database (Modified National Institute of Standards and Technology database[1]) is a large database of handwritten digits that is commonly used for training and testing advanced machine learning algorithms. General references are:\n",
    "\n",
    "**MNIST database**. Wikipedia. https://en.wikipedia.org/wiki/MNIST_database.\n",
    "\n",
    "**THE MNIST DATABASE of handwritten digits**. Yann LeCun, Courant Institute, NYU Corinna Cortes, Google Labs, New York Christopher J.C. Burges, Microsoft Research, Redmond. http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "**Classification datasets results**. Rodrigo Benenson. https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n",
    "\n",
    "The MNIST database contains 60,000 training images and 10,000 testing images. In our dataset the images will be 32 x 32 greyscale digit rasters.\n",
    "In order to manage our computations in reasonable time, we are going to build our models working only with the test subset, which you can also further randomly split into train-validation and test subsets. If possible, you can also use the original train subset as a test one.\n",
    "\n",
    "Do that taking into account you computing environment, but also trying to get models as good as possible."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Student contributions\n",
    "\n",
    "* Student `last_name_1` has ...\n",
    "* Student `last_name_2` has ..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%matplotlib inline\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import sys\r\n",
    "import time\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "import joblib\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold, GridSearchCV, StratifiedShuffleSplit\r\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\r\n",
    "\r\n",
    "from sklearn.pipeline import Pipeline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Data\n",
    "\n",
    "There are several ways of getting the MNIST dataset. A simple one is to import it from the Keras library:\n",
    "\n",
    "`from keras.datasets import mnist`  \n",
    "`from matplotlib import pyplot`\n",
    " \n",
    "`(train_X, train_y), (test_X, test_y) = mnist.load_data()`\n",
    "\n",
    "We are going to use another version where the shape of each pattern is given by a $32 \\times 32 \\times 1$ tensor, as the original $28 \\times 28$ images have been 0 padded. Thus, you may have to reshape it to either a matrix or a vector depending on the task you want to perform."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "f_bnch = \"E:\\\\data_bunch\\\\mnist\\\\mnist_32.bnch.joblib\"\r\n",
    "mnist = joblib.load(f_bnch)\r\n",
    "print(mnist.keys())\r\n",
    "\r\n",
    "print(\"data_shape: {0}\".format(mnist['data'].shape))\r\n",
    "print(\"data_test_shape: {0}\".format(mnist['data_test'].shape))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['DESCR', 'data', 'target', 'data_test', 'target_test'])\n",
      "data_shape: (60000, 32, 32, 1)\n",
      "data_test_shape: (10000, 32, 32, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Exploration, Visualization and Correlations\n",
    "\n",
    "Descriptive statistics, boxplots and histograms."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Some examples\n",
    "\n",
    "Plot 10 randomly chosen digit images as 5 x 2 subplots."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#code the plotting here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Descriptive analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build a DataFrame to make easier the exploratory analysis."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#define the DataFrame here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Describe the basic statistics of the pixels on the positions in the range `[494 : 502]` of the reshaped patterns."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#perform the description here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Boxplots\n",
    "\n",
    "Compute and display the boxplots of pixels in the range `[494 : 502]`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#code the boxplots here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Histograms and scatterplots\n",
    "\n",
    "Plot pairplots and histograms over the previous pixel range using `sns.pairplot`.  \n",
    "To do so select first two target digits which you may think should be quite different (e.g., 6 and 7) and apply `pairplot` only on patterns from those two targets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#select two target digits and apply sns.pairplot on the indicated pixel range"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correlations\n",
    "\n",
    "Use the previous digit selection and pixel range but drop the `target` column.\n",
    "\n",
    "Use directly a heatmap to display the correlations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#display the correlations of the pixel range as a heatmap"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Analysis Conclusions\n",
    "\n",
    "Write down here a summary of your conclusions after the basic data analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classiffiers\n",
    "\n",
    "We are going to build a $k$-NN and an MLP classifier **over the test dataset**.  \n",
    "But before working with any classifier, we split first the test dataset into a train-validation and a test subset.  \n",
    "Use for this the class `StratifiedShuffleSplit` from scikit-learn. Set the `test_size` parameter to either `0.5` or `0.75`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Splitting the test dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#split the test dataset here specifying cleraly your choices"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MLP Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CV Hyperparametrization\n",
    "\n",
    "Define an appropriate `MLPClassifier` and discuss in some detail your choices of the `MLPClassifier` parameters to ensure a proper convergence.\n",
    "\n",
    "Then, perform CV to select proper `alpha` and `hidden_layer_sizes` hyperparameters."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#define an appropriate MLP classifier and perform CV to select proper alpha and hidden_layer_sizes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Search Results \n",
    "\n",
    "We first examine the test scores of the 5 best hyperparameters."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "#transfor the CV results into a DataFrame and display the 5 best results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We analyze the CV results to check whether the CV ranges used are correct."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#plot the test scores that correspond to each alpha; do this only for the best MLP architecture found"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test MLPC Performance\n",
    "\n",
    "We check the test accuracy and confusion matrix."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "#compute the test predictions, their accuracy and confusion matrix and discuss your results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusions on the MLP classifier\n",
    "\n",
    "Give here a discussion as complete as possible of your results "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predicting probabilities\n",
    "\n",
    "We compute class probabilities over the test subset and pairplot them over the 10 classes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "#compute the test prediction probabilities, and pairplot them here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusions on the probability pairplots\n",
    "\n",
    "Explain and discuss the pairplot structure here and what information you may derive from it about your model performance."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}