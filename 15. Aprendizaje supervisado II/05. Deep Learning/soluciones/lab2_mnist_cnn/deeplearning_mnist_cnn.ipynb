{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9E0dsQoakDk8",
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "# Ejercicio: clasificando dígitos con redes convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0Tjn7LIkDlA",
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "<img src=\"https://albarji-labs-materials.s3-eu-west-1.amazonaws.com/lenet.png\" style=\"width:900px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36mbSZobkDlB",
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "En este ejercicio revisitamos el problema de clasificación de dígitos manuscritos, en esta ocasión empleando redes neuronales convolucionales. Veremos cómo esta arquitectura nos permite obtener niveles más altos de acierto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSPtVEWkkDlB",
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "## Guía general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUSLhrc_kDlC",
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "A lo largo del notebook encontrarás celdas que debes rellenar con tu propio código. Sigue las instrucciones del notebook y presta atención a los siguientes iconos:\n",
    "\n",
    "<img src=\"https://albarji-labs-materials.s3-eu-west-1.amazonaws.com/question.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
    "\n",
    "***\n",
    "\n",
    "<font color=#ad3e26>\n",
    "Deberás resolver el ejercicio escribiendo tu propio código o respuesta en la celda inmediatamente inferior.</font>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LH-mL_7ckDlE"
   },
   "source": [
    "<img src=\"https://albarji-labs-materials.s3-eu-west-1.amazonaws.com/exclamation.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
    "\n",
    "***\n",
    "<font color=#2655ad>\n",
    "Esto es una pista u observación de utilidad que puede ayudarte a resolver el ejercicio. Presta atención a estas pistas para comprender el ejercicio en mayor profundidad.\n",
    "</font>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twyor3HwkDlF"
   },
   "source": [
    "<img src=\"https://albarji-labs-materials.s3-eu-west-1.amazonaws.com/pro.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
    "\n",
    "***\n",
    "<font color=#259b4c>\n",
    "Este es un ejercicio avanzado que te puede ayudar a profundizar en el tema. ¡Buena suerte!</font>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whjYZL6DkDlG"
   },
   "source": [
    "Para evitar problemas con imports o incompatibilidades se recomienda ejecutar este notebook en uno de los [entornos de Deep Learning recomendados](https://github.com/albarji/teaching-environments-deeplearning), o hacer uso [Google Colaboratory](https://colab.research.google.com/). Si usas Colaboratory, asegúrate de [conectar una GPU](https://colab.research.google.com/notebooks/gpu.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a fijar las semillas aleatorias de numpy y tensorflow para obtener resultados reproducibles entre varias ejecuciones del notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2OlPZhWkDlG"
   },
   "source": [
    "Finalmente, si necesitas ayuda en el uso de cualquier función Python, coloca el cursor sobre su nombre y presiona Shift+Tab. Aparecerá una ventana con su documentación. Esto solo funciona dentro de celdas de código.\n",
    "\n",
    "¡Vamos alla!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZQJhiTukDlH"
   },
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_I8AU_7kDlI"
   },
   "source": [
    "<img src=\"https://albarji-labs-materials.s3-eu-west-1.amazonaws.com/question.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
    "\n",
    "***\n",
    "\n",
    "<font color=#ad3e26>\n",
    "Carga y prepara los datos como hiciste en el notebook anterior. En particular, los pasos que necesitas repetir son:\n",
    "    <ul>\n",
    "        <li>Carga los datos usando la función `mnist.load_data` de `tensorflow.keras.datasets`.</li>\n",
    "        <li>Normaliza los valores de los píxeles de entrada, dividiéndolos por 255, tanto para train como para test.</li>\n",
    "        <li>Codifica los datos de salida como vectores one-hot, tanto para train como para test.</li>\n",
    "    </ul>\n",
    "    De momento <b>no es necesario que hagas reshape de los datos</b> para convertirlos en vectores 1-dimensionales.\n",
    "</font>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xPoZ1Zw9kDlJ",
    "outputId": "f8c41274-a998-468e-c673-652fdb86992a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train_norm = X_train.astype('float32') / 255\n",
    "X_test_norm = X_test.astype('float32') / 255\n",
    "Y_train = to_categorical(y_train, 10) # We have 10 classes to codify\n",
    "Y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXFtoS-9kDlK"
   },
   "source": [
    "El resto del notebook asume que has cargado correctamente tus imágenes de entrenamiento como **X_train_norm**, etiquetas de entrenamiento como **Y_train**, imágenes de test como **X_test_norm** y etiquetas de test como **Y_test**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6SYKs2GkDlL"
   },
   "source": [
    "## Imports de Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TE5RMsTkDlM"
   },
   "source": [
    "Necesitaremos importar la siguientes clases de Keras, que ya conoces del notebook anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VqEzWixGkDlM"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spBjIohIkDlN"
   },
   "source": [
    "## Redes neuronales convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDqE8myhkDlO"
   },
   "source": [
    "Para mejorar en este problema de clasificación de imágenes necesitamos tratar los datos como verdaderas imágenes, y tener en cuenta la proximidad entre píxeles para tomar las decisiones, en lugar de \"aplanar\" todos los píxeles y meterlos a una red neuronal densa. Las capas **Convolucionales** y de **Pooling** son las ideales para ello."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DA1tI6XLkDlO"
   },
   "source": [
    "### Formateando los datos como tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d87hdAxtkDlO"
   },
   "source": [
    "Así como en el notebook anterior aplanamos los datos para poder introducirlos en nuestras redes, para las redes convolucionales necesitaremos organizar los datos en la forma de un tensor 4-dimensional. Los dimensiones de este tensor representan lo siguiente:\n",
    "* El índice de la imagen (ej. tercera imagen del dataset)\n",
    "* El índice de la fila\n",
    "* El índice de la columna\n",
    "* El índice del canal (ej. canal de color rojo en imágenes a color)\n",
    "\n",
    "Nuestros datos ahora mismo tienen la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5P8jM0ikDlO",
    "outputId": "e633c444-4558-4cb9-c993-7fddba0f2d21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkRDGBqckDlP"
   },
   "source": [
    "Así que, una vez más, tendremos que hacer uso de la función reshape para transformar los datos al formato adecuado. Tenemos 60000 imágenes en nuestros datos de entrenamiento, y esas imágenes tienen 28 filas por 28 columnas. Dado que estas imágenes son en escala de grises, la dimensión del canal solo contiene un canal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lrCAgCHkDlP",
    "outputId": "bbd843e5-d029-4ce9-b045-0107b9df5c49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintensor = X_train_norm.reshape(60000, 28, 28, 1)\n",
    "traintensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYgxFQsRkDlQ"
   },
   "source": [
    "Ahora los datos están en la forma correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxrlDMCmkDlR"
   },
   "source": [
    "<img src=\"https://albarji-labs-materials.s3-eu-west-1.amazonaws.com/question.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
    "\n",
    "***\n",
    "\n",
    "<font color=#ad3e26>\n",
    "    Repite la transformación para los datos de test. Ten en cuenta que en test solo contamos con 10000 imágenes. Guarda el tensor resultante en una variable llamada <b>testtensor</b>.\n",
    "</font>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "b9bsXarOkDlS"
   },
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "testtensor = X_test_norm.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CahfgiPkDlS"
   },
   "source": [
    "### Capas de convolución y de pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0paJejlKkDlT"
   },
   "source": [
    "Cuando definimos una red convolucional, las capas de convolución y de pooling trabajan juntas. La forma más habitual de utilizar estas capas es con el siguiente patrón:\n",
    "* Capa convolucional con activación ReLU\n",
    "* Capa de Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qj7lhyHokDlT"
   },
   "source": [
    "Siguiendo este patrón, podemos definir una red convolucional mínima como"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4W8hmkOFkDlT"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "kernel_size = 3 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "convnet = Sequential()\n",
    "\n",
    "convnet.add(Convolution2D(\n",
    "    32, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 1), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    ")) \n",
    "convnet.add(MaxPooling2D(pool_size=(pool_size, pool_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4T4QW1WpkDlU"
   },
   "source": [
    "Pero hay un problema: en algún punto debemos convertir los datos tensoriales a datos \"planos\" en forma de vector, ya que la salida final de la red debe ser un vector de 10 valores, representando probabilidades de clase. Podemos hacer esto mediante una capa `Flatten`. Tras ella, podemos añadir la habitual capa `Dense` para producir las salidas de la red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9Pyb05SzkDlU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMp4Jl2_kDlU"
   },
   "source": [
    "Comprobemos qué tipo de red hemos creado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H-qhF7dhkDlV",
    "outputId": "0849eca0-607a-43a6-8c98-ea829c4a59b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                54090     \n",
      "=================================================================\n",
      "Total params: 54,410\n",
      "Trainable params: 54,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqwa7oHPkDlV"
   },
   "source": [
    "<img src=\"https://albarji-labs-materials.s3-eu-west-1.amazonaws.com/question.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
    "\n",
    "***\n",
    "\n",
    "<font color=#ad3e26>\n",
    "    Compila la red que hemos definido, escogiendo \"adam\" como optimizador, y entrénala con los datos de train en su versión tensorial. Emplea un tamaño de batch de 128 y 20 épocas de entrenamiento. Tras entrenar, mide el accuracy sobre el conjunto de test. ¿Han resultado de utilidad las nuevas capas?\n",
    "</font>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1OhXbFvxkDlW",
    "outputId": "9c567cfb-6696-4e8b-8ad3-304b1cf3bfa2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 - 2s - loss: 0.3466 - accuracy: 0.9048\n",
      "Epoch 2/20\n",
      "469/469 - 2s - loss: 0.1299 - accuracy: 0.9637\n",
      "Epoch 3/20\n",
      "469/469 - 2s - loss: 0.0912 - accuracy: 0.9743\n",
      "Epoch 4/20\n",
      "469/469 - 2s - loss: 0.0722 - accuracy: 0.9797\n",
      "Epoch 5/20\n",
      "469/469 - 2s - loss: 0.0617 - accuracy: 0.9820\n",
      "Epoch 6/20\n",
      "469/469 - 2s - loss: 0.0538 - accuracy: 0.9845\n",
      "Epoch 7/20\n",
      "469/469 - 2s - loss: 0.0482 - accuracy: 0.9858\n",
      "Epoch 8/20\n",
      "469/469 - 2s - loss: 0.0441 - accuracy: 0.9870\n",
      "Epoch 9/20\n",
      "469/469 - 2s - loss: 0.0395 - accuracy: 0.9885\n",
      "Epoch 10/20\n",
      "469/469 - 2s - loss: 0.0369 - accuracy: 0.9888\n",
      "Epoch 11/20\n",
      "469/469 - 2s - loss: 0.0336 - accuracy: 0.9901\n",
      "Epoch 12/20\n",
      "469/469 - 2s - loss: 0.0313 - accuracy: 0.9908\n",
      "Epoch 13/20\n",
      "469/469 - 2s - loss: 0.0281 - accuracy: 0.9919\n",
      "Epoch 14/20\n",
      "469/469 - 2s - loss: 0.0262 - accuracy: 0.9925\n",
      "Epoch 15/20\n",
      "469/469 - 2s - loss: 0.0241 - accuracy: 0.9933\n",
      "Epoch 16/20\n",
      "469/469 - 2s - loss: 0.0226 - accuracy: 0.9937\n",
      "Epoch 17/20\n",
      "469/469 - 2s - loss: 0.0204 - accuracy: 0.9945\n",
      "Epoch 18/20\n",
      "469/469 - 2s - loss: 0.0188 - accuracy: 0.9950\n",
      "Epoch 19/20\n",
      "469/469 - 2s - loss: 0.0180 - accuracy: 0.9952\n",
      "Epoch 20/20\n",
      "469/469 - 2s - loss: 0.0156 - accuracy: 0.9961\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0554 - accuracy: 0.9839\n",
      "Test loss 0.055401287972927094\n",
      "Test accuracy 0.9839000105857849\n"
     ]
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "convnet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "convnet.fit(\n",
    "    traintensor, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")\n",
    "score = convnet.evaluate(testtensor, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kswOA3ybkDlX"
   },
   "source": [
    "<img src=\"https://albarji-labs-materials.s3-eu-west-1.amazonaws.com/question.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
    "\n",
    "***\n",
    "\n",
    "<font color=#ad3e26>\n",
    "    Construye y entrena una red convolucional más grande, con las siguientes capas:\n",
    "<ul>\n",
    "     <li>Convolución de 32 canales, tamaño de kernel 3, activación ReLU</li>\n",
    "     <li>Otra convolución de 32 canales, tamaño de kernel 3, activación ReLU</li>\n",
    "     <li>MaxPooling de tamaño 2</li>\n",
    "     <li>Flatten</li>\n",
    "     <li>Dense de 128 unidades, con activación ReLU</li>\n",
    "     <li>Dropout del 50%</li>\n",
    "     <li>Dense de salida con activación softmax</li>\n",
    "</ul>\n",
    "¿Has conseguido mejores resultados con esta red más compleja?\n",
    "</font>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTfKG9gzkDlX",
    "outputId": "e6f6e4bf-432e-4a33-808b-46c0a831996d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2485 - accuracy: 0.9240\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0803 - accuracy: 0.9762\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0609 - accuracy: 0.9822\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0479 - accuracy: 0.9854\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0408 - accuracy: 0.9876\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0350 - accuracy: 0.9889\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0289 - accuracy: 0.9912\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0268 - accuracy: 0.9915\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0250 - accuracy: 0.9919\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0205 - accuracy: 0.9930\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0201 - accuracy: 0.9934\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0176 - accuracy: 0.9939\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0173 - accuracy: 0.9942\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0148 - accuracy: 0.9950\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0150 - accuracy: 0.9947\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0132 - accuracy: 0.9954\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0133 - accuracy: 0.9957\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0126 - accuracy: 0.9958\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0102 - accuracy: 0.9962\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0112 - accuracy: 0.9960\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.9934\n",
      "Test loss 0.031674858182668686\n",
      "Test accuracy 0.993399977684021\n"
     ]
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "kernel_size = 3 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "large_convnet = Sequential()\n",
    "\n",
    "large_convnet.add(Convolution2D(32, # Number convolution channels to generate\n",
    "                        (kernel_size, kernel_size),\n",
    "                        padding='valid',\n",
    "                        input_shape=(img_rows, img_cols, 1),\n",
    "                        activation=\"relu\"))\n",
    "large_convnet.add(Convolution2D(32, (kernel_size, kernel_size), activation=\"relu\"))\n",
    "large_convnet.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "large_convnet.add(Flatten())\n",
    "large_convnet.add(Dense(128, activation=\"relu\"))\n",
    "large_convnet.add(Dropout(0.5))\n",
    "large_convnet.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "large_convnet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "large_convnet.fit(\n",
    "    traintensor, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=1 # Level of verbosity of the log messages\n",
    ")\n",
    "score = large_convnet.evaluate(testtensor, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWGRNSPykDlX"
   },
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_CEqgMbkDlY"
   },
   "source": [
    "La <a href=http://yann.lecun.com/exdb/lenet/>LeNet</a> es una arquitectura particular de red convolucional que ha demostrado ser particularmente efectiva para este problema. Como ejercicio final, vamos a construir una red similar a LeNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAT6yB8pkDlY"
   },
   "source": [
    "<img src=\"https://albarji-labs-materials.s3-eu-west-1.amazonaws.com/question.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
    "\n",
    "***\n",
    "\n",
    "<font color=#ad3e26>\n",
    "Construye y entrena la siguiente red:\n",
    "<ul>\n",
    "     <li>Convolución de 32 canales, tamaño de kernel 5, activación ReLU</li>\n",
    "     <li>MaxPooling de tamaño 2</li>\n",
    "     <li>Convolución de 50 canales, tamaño de kernel 5, activación ReLU</li>\n",
    "     <li>MaxPooling de tamaño 2</li>\n",
    "     <li>Flatten</li>\n",
    "     <li>Dense de 256 unidades, con activación ReLU</li>\n",
    "     <li>Dropout del 50%</li>\n",
    "     <li>Dense de salida con activación softmax</li>\n",
    "</ul>\n",
    "¿Es esta el mejor resultado que has obtenido? \n",
    "</font>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iIQVHw2OkDlY",
    "outputId": "8bbf1a69-8d9c-49bf-8bf4-cc07c6cc0a5c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2323 - accuracy: 0.9284\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0657 - accuracy: 0.9802\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0483 - accuracy: 0.9854\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0368 - accuracy: 0.9885\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0295 - accuracy: 0.9907\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.9920\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0210 - accuracy: 0.9935\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0185 - accuracy: 0.9942\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0170 - accuracy: 0.9944\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0148 - accuracy: 0.9954\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0131 - accuracy: 0.9957\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0108 - accuracy: 0.9963\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0118 - accuracy: 0.9961\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0104 - accuracy: 0.9963\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0081 - accuracy: 0.9974\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0094 - accuracy: 0.9971\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0093 - accuracy: 0.9967\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0072 - accuracy: 0.9978\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0075 - accuracy: 0.9976\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0073 - accuracy: 0.9976\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0279 - accuracy: 0.9931\n",
      "Test loss 0.0279130470007658\n",
      "Test accuracy 0.9930999875068665\n"
     ]
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "\n",
    "lenet = Sequential()\n",
    "\n",
    "lenet.add(Convolution2D(\n",
    "    32,\n",
    "    (5, 5),\n",
    "    padding='valid',\n",
    "    input_shape=(img_rows, img_cols, 1),\n",
    "    activation=\"relu\"\n",
    "))\n",
    "lenet.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "lenet.add(Convolution2D(50, (5, 5), activation=\"relu\"))\n",
    "lenet.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "lenet.add(Flatten())\n",
    "lenet.add(Dense(256, activation=\"relu\"))\n",
    "lenet.add(Dropout(0.5))\n",
    "lenet.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "lenet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "lenet.fit(\n",
    "    traintensor, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=1 # Level of verbosity of the log messages\n",
    ")\n",
    "score = lenet.evaluate(testtensor, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9FYISU3kDlZ"
   },
   "source": [
    "## Bonus track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCSBiIR9kDlZ"
   },
   "source": [
    "<img src=\"https://albarji-labs-materials.s3-eu-west-1.amazonaws.com/pro.png\" height=\"80\" width=\"80\" style=\"float: right;\"/>\n",
    "\n",
    "***\n",
    "\n",
    "<font color=#259b4c>\n",
    "    Entrena la red anterior durante más épocas. ¿Cuál es el mejor acierto en test que puedes obtener?\n",
    "</font>\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "name": "deeplearning_mnist_cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
