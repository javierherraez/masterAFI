{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "# Lab assignment: analyzing the Titanic with decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "<img src=\"img/titanic.jpg\" style=\"width:640px;height:406px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "In this assignment we will learn how to use decision trees for classification problems. In particular, we will make use of the reference implementation in scikit-learn, and we will seek explainability on the historic accident of the Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "## Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "Throughout this notebook you will find empty cells that you will need to fill with your own code. Follow the instructions in the notebook and pay special attention to the following symbols.\n",
    "\n",
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">You will need to solve a question by writing your own code or answer in the cell immediately below, or in a different file as instructed. Both correctness of the solution and code quality will be taken into account for marking.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">This is a hint or useful observation that can help you solve this assignment. You are not expected to write any solution, but you should pay attention to them to understand the assignment.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">This is an advanced and voluntary excercise that can help you gain a deeper knowledge into the topic. This exercise won't be taken into account towards marking, but you are encouraged to undertake it. Good luck!</td></tr>\n",
    "</table>\n",
    "\n",
    "To avoid missing packages and compatibility issues you should run this notebook under one of the [recommended Ensembles environment files](https://github.com/albarji/teaching-environments-ensembles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, if you need any help on the usage of a Python function you can place the writing cursor over its name and press Shift+Tab to produce a pop-out with related documentation. This will only work inside code cells. \n",
    "\n",
    "Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's fix a random seed so all results are reproducible in different runs of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will embed any plots into the notebook instead of generating a new window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment we will use the **titanic** dataset. This dataset is made of information about the passengers of the famous Titanic ship, and whether they where lucky enough to survive its tragedy or not. We will use these data for building a decision tree that will be able to predict the survival of a Titanic passenger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    " The titanic data is contained in the file <b>titanic.csv</b>. Take a look at the file format, and write the appropriate code to load all of it into a Pandas DataFrame named <b>data</b>.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have loaded the data properly, the following cell should output a table with the first 5 rows of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the features included in the dataset are of no relevance for the survival probability. For instance, the **PassengerId** is just a unique identifier that does not provide of meaningful information about the passenger; thus we would be better off removing it. The same happens with the **Ticket** number. We will also remove the **Name**: although the surname might me useful for identifying relatives aboard the ship, for simplicity we will ignore this feature. Finally, the **Cabin** will also be removed, as it has too many possible values and will introduce too much noise in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "     Create a new DataFrame <b>selecteddata</b> as a copy of the original DataFrame but where the PassengerId, Ticket and Name columns have been removed.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <table>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">The <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html\">drop</a> method from a Pandas Dataframe might help you</td></tr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If correctly done, the following should show the first 5 rows of data without neither the removed columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selecteddata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codifying categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Trees of scikit-learn only accept numerical features. Hence, columns such as **Sex** and **Embarked** should be recoded using a numerical format. We will make use of the <a href=http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html>**get_dummies**</a> method from pandas to do so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "     Create a new DataFrame <b>numericaldata</b> with the data after the application of the get_dummies method.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now see that the original columns have been replaced by dummy one-hot-encoded columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericaldata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is full of missing values, so we will need to address those before moving on. For categorical features the get_dummies procedure above already takes care of the missing values, by means of setting all dummies to zero whenever a missing value is found. But for the remaining numerical features we will need to apply an imputation method explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "     Create a new DataFrame <b>imputeddata</b> with a version of the data above where the missing values have been replaced by the mean value of their column.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>\n",
    "     The <b>fillna</b> and <b>mean</b> functions from a DataFrame object can help you in this task.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If done correctly, we should have zero NaN values over the whole DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(imputeddata.isnull().sum().sum() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now extract the column that represents the class we want to predict (*Survived*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    " Create DataFrames X, Y. The X DataFrame should contain only the explanatory variables, while the Y DataFrame must contain only the target variable <b>Survived</b>.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check we have done this correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows we will use a training/test splitting of the data. We will perform that splitting now, making use of the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">train_test_split</a> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.33, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the call above, we have splitted the inputs `X` and outputs `Y` into two datasets, `(Xtrain, Ytrain)` and `(Xtest, Ytest)`. The `test_size` parameter specifies that a third of the data will be used as the test set. The `stratify` parameter is also relevant: it ensures that the same proportion of surviving and deceased passengers are present in both train and test datasets, by following the class values present in `Y`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn, the machine learning library for Python, a Decision Tree for classification can be created through the DecisionTreeClassifier class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now let's create a simple Decision Tree letting scikit-learn choose all the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisiontree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the tree is created, we can now train it on our training data, using the function **fit**. But let us first create a toy dataset to show how the whole procedure works, before using the Titanic data we prepared above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtoy = pd.DataFrame(data=[[0, 0], [1, 1]], columns=[\"Number of Jumbos\", \"Procrastination ratio\"])\n",
    "ytoy = pd.DataFrame(data=[0, 1], columns=[\"Class\"])\n",
    "display(Xtoy)\n",
    "display(ytoy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit the tree to this toy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisiontree.fit(Xtoy, ytoy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can analyze the details of the model parameters with the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisiontree.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, we can see that the **Gini** splitting criterion is being used.\n",
    "\n",
    "Also, using the `classes_` attribute we can check the identifiers of classes this tree can predict. We will come back to this in a while when visualizing the tree structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisiontree.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the tree is trained we can use it to generate predictions over data. Reusing the same toy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisiontree.predict(Xtoy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare these predictions agains the ytoy labels we can see that the tree has been able to correctly predict the class labels for the data. We can also compute a **score** for the tree based on the performance over these data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisiontree.score(Xtoy, ytoy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification models of scikit-learn (such as this tree) the score method returns the accuracy, that is, the fraction of the test data the classifier can label correctly. We obtain a 100% acccuracy! Not such a remarkable feat though, if we take into account we are predicting for a toy dataset, which furthermore was also used for training. But it has served us to portray the basic functions of a Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further analyze the workings of the tree we can create a visualization of it. Note we can provide the visualization function with the names of the features and the classes to obtain a more understandable representation. The class names must be provided as a list with one name per class, and they should follow the order of the classes in the `classes_` attribute we printed a few cells above. We can also configure the size of the plot using the *figsize* parameters we provide to the **plt.figure** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_tree(\n",
    "    decisiontree,  # The tree we want to plot\n",
    "    feature_names=Xtoy.columns,  # Take the feature names from the column names in the data\n",
    "    class_names=[\"Negative\", \"Positive\"],  # 0=\"Negative\", 1=\"Positive\"\n",
    "    filled=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the tree is made up of a root node, where the split is made in one of the variables at value 0.5. The child node at the left side contains all data points that answer **yes** to the question used for splitting, while the right-side child contains all data points that answer **no** to that question. Before this split the Gini impurity is 0.5, as we have one pattern from each class. After the split we obtain two leaf nodes with 0 impurity, each of them containing a single pattern from either class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to obtain a text-based explanation of the tree using the **export_text** function. This can become handy when analyzing very large trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "\n",
    "print(export_text(decisiontree, feature_names=list(Xtoy.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Titanic (and why Leonardo DiCaprio [SPOILER])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now make use of a Decision Tree to obtain a classifier of survivors of the Titanic, and also to learn something about the kind of people who survived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Titanic Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    " Create a new Decision Tree named <b>titanictree</b> and use the training subset you prepared above to fit this tree. Use the default tree parameters.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    " Now create a plot of the tree, replicating the steps above. Can you spot anything interesting? Do you think this representation of the model is intuitive?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    " Take a look at the dataset README.md to check which class corresponds to Deceased and which to Survived, and also check the classes_ attribute in the fitted tree to assign names properly.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    " Is the plot too small to read? Try increasing the figsize values and double-click in the plot to zoom in.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default classification tree will split the data into more and more nodes until no improvement in impurity can be gained. This is the reason we have obtained a very large tree. But how practical is this tree? Let's measure its performance over the test set. We can do this using the **score** function of the titanictree, following the standard scikit-learn interfaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "     Measure the score of the tree over the <b>test set</b>. Do you think it is any good?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining the tree, step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree we built above was too large for interpretation. Fortunately we can control the size of the tree, by specifying the **max_depth** parameter when we create the DecisionTreeClassifier object. We can exploit this to build smaller trees that have an easier interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    " Build a tree with <b>max_depth=1</b>, and train it on the Titanic data. Then print the accuracy of that tree on the test set, and plot the tree as well. Which explanatory variable has been selected for the first (and only) split of the tree? Does this make sense?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    " Build a tree with <b>max_depth=2</b>, and train it on the Titanic data.  Then print the accuracy of that tree on the test set, and plot the tree as well. Which other features are relevant for explaining the probability of survival of passengers? Do these features make sense?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    " Build yet another tree with <b>max_depth=3</b>, and train it on the Titanic data.  Then print the accuracy of that tree on the test set, and plot the tree as well. Does any other relevant feature appear? Can you spot any sign of overfitting?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the tree parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-pruning the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees are prone to overfitting, and so we must use some kind of **pruning** to generate trees that have good generalization properties. scikit-learn implements several **pre-pruning** mechanisms, which stop the splitting procedure of the tree after some conditions are met:\n",
    "\n",
    "* **max_depth**: maximum depth at which the tree can continue creating splits.\n",
    "* **min_samples_split**: the minimum number of samples required to split an internal node.\n",
    "* **min_samples_leaf**: the minimum number of samples required for a leaf node. A split point at any depth will only be considered if it generates at least min_samples_leaf training samples in each of the left and right children.\n",
    "* **min_impurity_decrease**: a node will be split only if the split induces a decrease of the impurity greater than or equal to this value.\n",
    "\n",
    "(Other alternative pre-pruning strategies are possible: [seed the docs](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier))\n",
    "\n",
    "These parameters are usually set through an independent validation set or some kind of cross-validation procedure. Here we will use a cross-validation strategy over the training set to test a range of different pre-pruning strategies. We will do so using the [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class will take a dictionary of parameters, with the values we want to try for each parameter. For this case, we can use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [1, 2, 3, 4],\n",
    "    \"min_samples_split\": [ 2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [2, 5, 10, 20],\n",
    "    \"min_impurity_decrease\": [1e-3, 1e-2, 1e-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can build a GridSearchCV by specifying the model we want to optimize, and the dictionary of parameters to test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treesearch = GridSearchCV(\n",
    "    estimator = DecisionTreeClassifier(), \n",
    "    param_grid = param_grid,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A GridSearchCV behaves in the same way as any other model in scikit-learn (including a simple tree). We can `fit` it over the training data and then compute its `score` over the test data. However, when using `fit`, the GridSearchCV will estimate the performance of the decision tree for each possible combination of the parameter values we have provided in the dictionary. This estimation is done by running a 5-fold cross validation procedure. Once all possible combinations are tested, the decision tree is trained using the whole training data and the parameters that produced the best score in the cross validation.\n",
    "\n",
    "All of this is done automatically, but it is expensive, as it requires training a large number of models: 5 for each possible combination of parameters. To accelerate this procedure we can use the `n_jobs` parameter, which tells scikit-learn it can use as many parallel threads for training models. When specifying a value of `-1`, all processors available in your machine are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treesearch.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the GridSearchCV is trained, we can check which parameter values were chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treesearch.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    " Now print the accuracy of the best pruned tree over the test set, and also plot such tree. Answer the following questions: is the tree interpretable? Does any non-relevant variable appear in the tree? Do you think some kind of post-pruning strategy could reduce further the size of the tree without damaging performance?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-pruning the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach to prevent overfitting is to allow the tree to grow maximally during training, then **prune** the parts of the tree that worsen the generalization error. A particularly popular method of doing this is called **Cost-complexity pruning**, and is implemented in the Decision Trees as the **ccp_alpha** ($\\alpha$) parameter. For $\\alpha=0$ no post-pruning will be performed on the tree. The larger $\\alpha$ becomes, the more aggresive pruning we will perform. For example, let's build a tree over the Titanic data with $\\alpha=0.02$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prunedtree = DecisionTreeClassifier(ccp_alpha=0.02)\n",
    "prunedtree.fit(Xtrain, Ytrain)\n",
    "print(\"Tree accuracy is %f\" % prunedtree.score(Xtest, Ytest))\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_tree(prunedtree, feature_names=Xtrain.columns, class_names=[\"Deceased\", \"Survived\"], filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have not limited the tree growth in any way, the post-pruning step produces a smaller tree that is able to perform well on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An advantage of this pruning strategy is that we can compute the whole **regularization path** for all possible $\\alpha$ values. This allows for a model selection strategy different from the usual GridSearchCV, but for which we will need to keep aside a part of the training data as a separate validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    " Create DataFrames <b>Xsubtrain</b>, <b>Ysubtrain</b>, <b>Xval</b> and <b>Yval</b>, containing approximately two thirds and one third of the training data, respectively. Make sure this split is stratified.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    " You can use the train_test_split method for this, as you did before to split between the train and test datasets.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the regularization path making use of the **cost_complexity_pruning_path** method. Note how this is a method from DecisionTreeClassifier, but we don't need to fit the tree to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = DecisionTreeClassifier().cost_complexity_pruning_path(Xsubtrain, Ysubtrain)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method returns a dictionary with a list of all the $\\alpha$ values at which a branch of the tree is pruned off, as well as a parallel list with the impurities attained by the tree at such level of pruning. As $\\alpha$ grows, more pruning is performed, producing a smaller tree with larger impurity. We can confirm this by plotting the values of the regularization path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "ax.plot(path[\"ccp_alphas\"], path[\"impurities\"], marker='o', drawstyle=\"steps-post\")\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"total impurity of leaves\")\n",
    "ax.set_title(\"Total Impurity vs post-pruning alpha for training set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train a tree for each one of the different $\\alpha$ values in the regularization path, thus obtaining all possible pruned trees for this training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_trees = [\n",
    "    DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha).fit(Xsubtrain, Ysubtrain)\n",
    "    for ccp_alpha in path[\"ccp_alphas\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The larger the $\\alpha$ value the more aggresive pruning the tree has been subject to. We can check this by creating a plot showing $\\alpha$ vs number of tree nodes or tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_counts = [clf.tree_.node_count for clf in path_trees]\n",
    "depth = [clf.tree_.max_depth for clf in path_trees]\n",
    "fig, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "ax[0].plot(path[\"ccp_alphas\"], node_counts, marker='o', drawstyle=\"steps-post\")\n",
    "ax[0].set_xlabel(\"alpha\")\n",
    "ax[0].set_ylabel(\"number of nodes\")\n",
    "ax[0].set_title(\"Number of nodes vs alpha\")\n",
    "ax[1].plot(path[\"ccp_alphas\"], depth, marker='o', drawstyle=\"steps-post\")\n",
    "ax[1].set_xlabel(\"alpha\")\n",
    "ax[1].set_ylabel(\"depth of tree\")\n",
    "ax[1].set_title(\"Depth vs alpha\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the whole point of keeping a separate validation dataset is to measure the generalization ability of each tree in the regularization path. We can do that as follows, comparing performance in the training subdataset and the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_performances = [tree.score(Xsubtrain, Ysubtrain) for tree in path_trees]\n",
    "val_performances = [tree.score(Xval, Yval) for tree in path_trees]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
    "ax.plot(path[\"ccp_alphas\"], train_performances, marker='o', label=\"train\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.plot(path[\"ccp_alphas\"], val_performances, marker='o', label=\"validation\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, for small $\\alpha$ values overfitting happens, resulting in almost perfect accuracy in the training data but poor performance on the validation data. Conversely, if $\\alpha$ is too large the performance in both training and validation data is low, as the tree is too small to be a meaningful model: we are suffering underfitting. The best choice for our production model would be the tree with highest validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestscore_index = np.argmax(val_performances)\n",
    "besttree = path_trees[bestscore_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot this tree and check its score over the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tree accuracy is %f\" % besttree.score(Xtest, Ytest))\n",
    "print(besttree)\n",
    "plt.figure(figsize=(15,15))\n",
    "plot_tree(besttree, feature_names=Xtrain.columns, class_names=[\"Deceased\", \"Survived\"], filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if the training dataset is small we can still perform the usual GridSearch strategy to avoid sacrificing part of the data as validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    " Run a GridSearchCV crossvalidation to find the best post-pruned tree over the training data, by testing different values for the $\\alpha$ parameter. Note regularization parameters such as $\\alpha$ are better tuned by selecting values in a logarithmic scale: 0.01, 0.02, 0.05, 0.1, ...\n",
    " Once the best tree hast been found, compute its score over the test set and visualize it.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus round: trying different impurity functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    " Repeat the GridSearchCV procedure, either with pre-pruning, post-pruning or both, but now also exploring other impurity functions (check the <a href=http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html>docs</a>). Can you improve on this dataset over using the Gini impurity?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
