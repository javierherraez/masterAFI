---
title: 'Práctica - Análisis de Redes Sociales - MDSF'
author: 'Javier Herráez Albarrán'
output:
html_document:
df_print: paged
---

Este R Markdown recoge el enunciado de la práctica de la asignatura de redes sociales.

El objetivo es analizar un grafo, que se provee como fichero en el mismo paquete que este enunciado. En este fichero, encontramos solamente dos columnas, correspondiente a una interacción entre dos nodos de la red. Esta red está formada por distintos individuos que tienen contactos cara a cara durante un período de tiempo.

A continuación, dividimos la práctica en apartados, con una breve descripción de qué debe contener cada chunk de código donde el alumno desarrollará su respuesta así como las explicaciones que considere oportunas. Por favor, razona todas tus soluciones y escribe las explicaciones en azul.

Junto al título de cada apartado se encuentra la puntuación del mismo (pueden obtenerse hasta 10,5 puntos, aunque solamente se evaluará del 0 al 10).

## Carga de datos y comprobaciones iniciales (0,5 puntos)

En este apartado, se pide:

* Cargar el fichero adjunto en la práctica.
* Convertirlo en un objeto grafo de IGraph. Se cargará como un grafo NO dirigido.
* Comprobar que, efectivamente, tiene el número de nodos y enlaces correcto.
* Simplificar: eliminar bucles y agregar enlaces múltiples, contando cuántas veces aparece un enlace y almacenándolo como un peso de la red resultante.

```{r global_options, include=T, echo = F}
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
```

### Cargar el fichero adjunto en la práctica.

```{r}
library(igraph)

rm(list = ls())

setwd('C:/Users/Javier/Documents/masterAFI/18. Analisis de Grafos/01. Redes sociales/practica/')
dd <- read.csv('red_contactos.csv', sep = ';')
```

### Convertirlo en un objeto grafo de IGraph.

```{r}
gg <- graph.data.frame(dd, directed = FALSE)
summary(gg)
```

### Comprobar que, efectivamente, tiene el número de nodos y enlaces correcto.

```{r}
vcount(gg)
ecount(gg)
```

### Simplificar: eliminar bucles y agregar enlaces múltiples

```{r}
gg2 <- simplify(gg, remove.multiple = TRUE, remove.loops = TRUE)

# para cada enlace, calculamos cuantos caminos cortos hay entre sus vértices 
# el camino mínimo será igual al enlace, por lo tanto, la cantidad será igual al número de enlaces múltiples
# esta cantidad, lo añadimos como peso

E(gg2)$weight = sapply(E(gg2), function(e) {
  length(all_shortest_paths(gg, from = ends(gg2, e)[1], to = ends(gg2, e)[2])$res) } )


summary(gg2)
```

```{r}
hist(E(gg2)$weight, breaks = 30)
```

## Selección de la componente conexa mayor (0,5 puntos)

En este apartado, se pide realizar los pasos adecuados para generar un nuevo objeto grafo, que sea conexo, y que involucre a todos los nodos y enlaces de la componente conexa mayor del grafo original.

Comprobamos que no sea conexo:

```{r}
is.connected(gg2)
```

Visualizamos los tamaños de las distintas componentes conexas:

```{r}
ccs <- components(gg2)
ccs$csize
```
Vemos que hay 3 componentes conexas, una de ellas acumula prácticamente todos los puntos. Nos quedamos con ella:

```{r}
id_compmayor <- which.max(ccs$csize)

vids <- ccs$membership == id_compmayor
vids <- which(ccs$membership == id_compmayor)

gg3 <- induced_subgraph(gg2, vids = vids )

summary(gg3)
```


## Análisis descriptivo de la componente conexa mayor (2,5 puntos)

En este apartado, se pide analizar descriptivamente el grafo usando los conceptos que hemos visto durante las clases de teoría:

* Grado medio
* Distancia media
* Diámetro
* Distribución de grados y ajuste a una Power-Law
* Clustering
* Entropía de los nodos
* Centralidad de los nodos y comparación con métricas de grado y clustering

### Grado medio

```{r}
mean(degree(gg3))
hist(degree(gg3), breaks = 20)
```

### Distancia media

```{r}
average.path.length(gg3)
```

### Diámetro

```{r}
diameter(gg3)
```

### Distribución de grados y ajuste a una Power-Law

Podemos empezar por ver la densidad:

```{r}
graph.density(gg3)
```
A continuación, ajustamos una Power Law:

```{r}
deg_dist <- degree_distribution(gg3)
fit <- fit_power_law(deg_dist)
fit
```

```{r}
plot(deg_dist + 0.0001, log = 'xy', xlab = 'Node Degree', ylab = 'Probability')
lines(seq(deg_dist), seq(deg_dist)^-fit$alpha, col='red')
```

Tanto con el p-value como con el plot, podemos ver que nuestros datos no se ajustan a una Power Law.

Podemos tratar de ver que pasaría si eliminamos aquellos nodos con los que obteníamos un valor 0 en la función de distribución:

```{r}
gg_prueba <- induced_subgraph(gg3, vids = V(gg3)[deg_dist > 0])
deg_dist_prueba <- degree_distribution(gg_prueba)
fit_prueba <- fit_power_law(deg_dist_prueba)
fit_prueba

plot(deg_dist_prueba  + 0.0001, log = 'xy', xlab = 'Node Degree', ylab = 'Probability')
lines(seq(deg_dist_prueba), seq(deg_dist_prueba)^-fit_prueba$alpha, col='red')
```

Con el nuevo grafo que hemos creado parece que sí que tendríamos unos datos que se pueden ajustar a una Power Lab.

### Clustering

Podemos observar el número de triángulos por nodo:

```{r}
triangulos <- count_triangles(gg3)
mean(triangulos)
hist(triangulos, breaks = 30)
```

### Entropía de Shannon de los nodos 

```{r}
hist(diversity(gg3), breaks = 20, main = '', xlab = 'Diversity')
```

### Centralidad de los nodos y comparación con métricas de grado y clustering

Vemos las distintas centralidades, hacemos histogramas de ellas y observamos como se correlacionan:

```{r}
Degree <- degree(gg3)
Eig <- evcent(gg3)$vector
Closeness <- closeness(gg3)
Betweenness <- betweenness(gg3)

par(mfrow=c(2,2))
for (centrality in c('Degree', 'Eig', 'Closeness', 'Betweenness')){
  hist(get(centrality), breaks = 30, xlab = centrality, main = '')
}

centralities <- cbind(Degree, Eig, Closeness, Betweenness, triangulos)
round(cor(centralities), 2)
```

Podemos observar como las centralidades por grado, cercanía y betweeness se parecen bastante entre ellas, además de con el número de triángulos de cada nodo. Sin embargo, parece que Closeness es la que más difiere de las demás.

## Análisis de comunidades de la componente conexa mayor (1,5 puntos)

En este apartado, se pide aplicar dos algoritmos de detección de comunidades, compararlos y seleccionar cuál es, en tu opinión, el que da una mejor respuesta. Razona tu selección.

Usaremos los algoritmos de Infomap y de Walktrap para detectar comunidades, calculamos las modularidades para cada uno y comparamos los resultados de los algoritmos:

```{r}
comms_infomap <- infomap.community(gg3)
comms_walktrap <- walktrap.community(gg3)

modularity(comms_infomap)
modularity(comms_walktrap)

compare(comms_infomap, comms_walktrap, method='nmi')
```

Vemos que la función compare nos devuelve un valor de 0.81, es decir, los algoritmos nos devuelven resultados más o menos parecidos. Para elegir uno de ellos, veremos como éstos dividen a sus comunidades:

```{r}
table(comms_infomap$membership)
table(comms_walktrap$membership)
```

Vemos que el algoritmo de Infomap divide comunidades de una forma más uniforme, mientras que, el algoritmo Walktrap nos devuelve bastantes comunidades formadas por un solo miembro. Con estos resultados, decidimos quedarnos con Infomap como algoritmo de detección de comunidades.

## Visualización del grafo por comunidades de la componente conexa mayor (1,5 puntos)

En este apartado, se pide visualizar el grafo coloreando cada nodo en función de la comunidad a la que pertenezca, según tu elección del apartado anterior.

```{r, fig.width=30, fig.height=30}
wws <- ifelse(crossing(comms_infomap, gg3), 1, 500)
ll <- layout_with_fr(gg3, weights=wws)

palcol <- rainbow(n=max(comms_infomap$membership))

plot(gg3,
     layout = ll,
     vertex.label='',
     vertex.size=log(degree(gg3)),
     vertex.color=palcol[comms_infomap$membership])
```


## Difundiendo un rumor (o un virus) en la componente conexa mayor (4 puntos)

Este apartado es el que más peso en la práctica tiene. Vamos a implementar un modelo epidemiológico sobre el grafo que, típicamente, se utiliza para simular escenarios de difusión de enfermedades pero también en contextos como la distribución de rumores e información. Vamos a implementar un modelo SIR que se caracteriza por tener los siguientes parámetros:

* Número de nodos iniciales infectados en el momento t=0 (N).
* Beta: probabilidad de contagio de un nodo infectado (I) a un nodo susceptible de serlo (S)
* Gamma: probabilidad de que un nodo infectado (I) se recupere en momenteo actual (R). Los nodos en estado (R) no son susceptibles y permanecen en este estado infinitamente.

Se pide desarrollar una función que tenga como parámetros los tres valores anteriores y un cuarto que sea un grafo que, en nuestro caso, será la componente conexa mayor del grafo original de esta práctica. Dicha función simulará el proceso SIR:

* En t=0, se seleccionan N nodos al azar, que pasarán a estado infectado.
* En t=1, se podrán contagiar con probabilidad Beta nodos que tienen un vecino infectado; OJO: si un nodo en estado S tiene varios vecinos en estado I tiene más probabilidad de infectarse ya que cada vecino tendrá un intento de infectarle.
* Se repite el paso anterior sucesivamente, hasta que no vemos infectados nuevos durante, al menos, 3 iteraciones.

Se pide ejecutar una simulación para tres o cuatro valores del parámetro beta (N y gamma pueden ser fijos en estas simulaciones) de este proceso de manera que se pueda visualizar:

* La curva de nuevos infectados en escala logarítmica para cada caso.
* El grafo que surge de la cascada de contagios: es decir, dos nodos están enlazados ahora si uno ha contagiado al otro. Como es lógico, tanto los nodos como los enlaces de este nuevo grafo son un subconjunto del grafo original.

En este primer bloque de código, vamos a definir las siguientes funciones:

* generate_sir: recibe N, beta, gamma y un grafo como parámetros, y simula un proceso SIR. Nos devolverá 6 objetos:
  + contagiados: lista con el número de nodos que se encuentran contagiados cada día.
  + susceptibles: lista con el número de nodos que son susceptibles cada día.
  + recuperados: lista con el número de nodos que se encuentran recuperados cada día.
  + nuevos_contagios: lista con el número de contagiados nuevos de cada día.
  + iteraciones: número de iteraciones hasta que no vemos infectados nuevos durante, al menos, 3 iteraciones.
  + grafos: lista con el grafo resultante de cada día.
* plot_evolution: genera un plot que muestra la evolución de elementos infectados, susceptibles y recuperados.
* plot_new_infections: genera un plot con la evolución de nuevos infectados en escala logarítmica.
* plot_infection_graph: genera un plot con el grafo pasado por parámetro con colores según el estado del elemento y según los enlaces de infección.
* create_gif: genera un gif a partir de una lista de grafos.

```{r}
generate_sir <- function(N = 5, beta = 0.1, gamma = 0.1, graph){
  graph <- set_vertex_attr(graph, 'label', value = 'S')
  graph <- set_edge_attr(graph, 'label', value = '')
  
  sample_index <- sample(1:vcount(graph), N)
  graph <- set_vertex_attr(graph, 'label', index = sample_index, value = 'I')
  
  n_contagiados = N
  n_susceptibles = vcount(graph) - N
  n_recuperados = 0
  iteraciones_sin_contagios = 0
  iteracion= 1
  
  lista_contagiados = c(n_contagiados)
  lista_susceptibles = c(n_susceptibles)
  lista_recuperados = c(n_recuperados)
  lista_nuevos_contagios = c(n_contagiados)
  lista_grafo = list(graph)
  
  while (iteraciones_sin_contagios < 3){
    n_nuevos_contagios = 0
    initial_graph <- graph
    
    for (v in V(initial_graph)){
      state <- V(initial_graph)[v]$label
      
      if (state == 'I'){
        if (rbinom(n=1, size=1, prob = gamma) == 1){
          V(graph)[v]$label <- 'R'
          n_recuperados = n_recuperados + 1
          n_contagiados = n_contagiados - 1
        }
      }
      if (state == 'S'){
        for (neighbor in neighbors(initial_graph, v)){
          if ((V(initial_graph)[neighbor]$label == 'I') && (rbinom(n=1, size=1, prob = beta) == 1)){
            V(graph)[v]$label <- 'I'
            E(graph)[v %--% neighbor]$label <- 'I'
            n_contagiados = n_contagiados + 1
            n_nuevos_contagios = n_nuevos_contagios + 1
            n_susceptibles = n_susceptibles - 1
            break
          }
        }
      }
    }
    if (n_nuevos_contagios == 0){
      iteraciones_sin_contagios = iteraciones_sin_contagios + 1
    } else {
      iteraciones_sin_contagios = 0
    }
    iteracion = iteracion + 1
    lista_contagiados = c(lista_contagiados, n_contagiados)
    lista_susceptibles = c(lista_susceptibles, n_susceptibles)
    lista_recuperados = c(lista_recuperados, n_recuperados)
    lista_nuevos_contagios = c(lista_nuevos_contagios, n_nuevos_contagios)
    lista_grafo[[iteracion]] = graph
  }
  
  return (list('contagiados' = lista_contagiados,
               'susceptibles' = lista_susceptibles,
               'recuperados' = lista_recuperados,
               'nuevos_contagios' = lista_nuevos_contagios,
               'iteraciones' = iteracion,
               'grafos' = lista_grafo
          ))

}

plot_evolution <- function(evolution){
  plot(1:evolution$iteraciones, evolution$contagiados, 
       type = 'l', col = 'red',
       ylab = 'Nº Nodos', xlab = 'Iteraciones', 
       ylim = c(0, max(evolution$susceptibles)),
       main = 'Evolución')
  lines(1:evolution$iteraciones, evolution$recuperados, 
        type = 'l', col='green')
  lines(1:evolution$iteraciones, evolution$susceptibles, 
        type = 'l', col='blue')
  legend(evolution$iteraciones, max(evolution$susceptibles)/2, 
         legend=c('Contagiados', 'Recuperados', 'Susceptibles'),
         col=c('red', 'green', 'blue'), 
         lty=1, cex=0.8, xjust = 1)
}

plot_new_infections <- function(list_new_infections, iteraciones){
  plot(1:iteraciones, list_new_infections, 
       type = 'o', col = 'red', log = 'y', 
       ylab = 'Nº Nuevos Infectados', xlab = 'Iteraciones',
       main = 'Nuevos infectados')
}

plot_infection_graph <- function(graph, index){
  graph_colors <- ifelse(V(graph)$label == 'I', 'red',
                       ifelse(V(graph)$label == 'R', 'green', 'blue'))

  subg <- subgraph.edges(graph, E(graph)[label == 'I'])
  
  plot(subg,
       layout = ll,
       vertex.label = '',
       vertex.size = log(degree(graph)),
       edge.label = '',
       vertex.color = graph_colors,
       main = paste('Iteración', index))
  
}

create_gif <- function(list_graphs){
  img <- magick::image_graph(width = 1000, height = 1000)
  for (i in 1:length(list_graphs)){
    plot_infection_graph(list_graphs[[i]], i)
  }
  dev.off()
  animation <- magick::image_animate(img, fps = 2, optimize = TRUE)
  print(animation)
}
```

Veremos distintas ejecuciones del simulador del proceso SIR, dibujando las gráficas y los GIF correspondientes a cada una de ellas. 

Nuestras distintas ejecuciones tendrán como parámetros los mismos valores para gamma (probabilidad de recuperación; gamma = 0.1), N (número de nodos iniciales infectados; N = 5) y el grafo (utilizaremos el grafo resultante de los apartados anteriores). El parámetro que vamos a ir variando será el beta.

### Beta = 0.1

```{r}
ejemplo_SIR_1 <- generate_sir(graph = gg3, beta = 0.1)

plot_evolution(ejemplo_SIR_1)
```

```{r}
plot_new_infections(ejemplo_SIR_1$nuevos_contagios, ejemplo_SIR_1$iteraciones)
```

```{r, fig.width=30, fig.height=30}
create_gif(ejemplo_SIR_1$grafos)
```

### Beta = 0.05

```{r}
ejemplo_SIR_2 <- generate_sir(graph = gg3, beta = 0.05)

plot_evolution(ejemplo_SIR_2)
```

```{r}
plot_new_infections(ejemplo_SIR_2$nuevos_contagios, ejemplo_SIR_2$iteraciones)
```

```{r, fig.width=30, fig.height=30}
create_gif(ejemplo_SIR_2$grafos)
```

### Beta = 0.01

```{r}
ejemplo_SIR_3 <- generate_sir(graph = gg3, beta = 0.01)

plot_evolution(ejemplo_SIR_3)
```

```{r}
plot_new_infections(ejemplo_SIR_3$nuevos_contagios, ejemplo_SIR_3$iteraciones)
```

```{r, fig.width=30, fig.height=30}
create_gif(ejemplo_SIR_3$grafos)
```
