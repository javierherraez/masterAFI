?geom_bar
# Categorical vs categorical
Arrests %>%
ggplot(aes(x = released, fill = colour)) +
geom_bar(position = 1)
# Categorical vs categorical
Arrests %>%
ggplot(aes(x = released, fill = colour)) +
geom_bar(position = "stack")
# Categorical vs categorical
Arrests %>%
ggplot(aes(x = released, fill = colour)) +
geom_bar(position = "fill")
# Categorical vs categorical
Arrests %>%
ggplot(aes(x = colour, fill = released)) +
geom_bar(position = "fill")
# Categorical vs categorical
Arrests %>%
ggplot(aes(x= released, fill = sex)) + geom_bar() +
labs(title = "Released by sex", x = "", y = "", col = "")
# Categorical vs categorical
Arrests %>%
ggplot(aes(x= released, fill = sex)) + geom_bar(position = "fill") +
labs(title = "Released by sex", x = "", y = "", col = "")
# Categorical vs categorical
Arrests %>%
ggplot(aes(x = colour, fill = released)) +
geom_bar(position = "fill")
# Categorical vs categorical
Arrests %>%
ggplot(aes(x= released, fill = sex, col = race)) + geom_bar(position = "fill") +
labs(title = "Released by sex", x = "", y = "", col = "")
# Categorical vs categorical
Arrests %>%
ggplot(aes(x= released, fill = sex, col = colour)) + geom_bar(position = "fill") +
labs(title = "Released by sex", x = "", y = "", col = "")
# Categorical vs categorical
Arrests %>%
ggplot(aes(x= released, fill = sex)) + geom_bar(position = "fill") +
labs(title = "Released by sex", x = "", y = "", col = "")
# Categorical vs numerical
Arrests %>%
ggplot(aes(x = released, y = checks)) +
geom_boxplot(fill="lightblue") +
labs(title = "Released by previous checks", x = "", y = "", col = "")
# Log-normal distribution: transform the target with a log and then assume it is normal distributed
# (we are modeling E(log(y)) in a linear way)
log.normal.linear <- glm(log(y) ~ x, family=gaussian, data=my.data)
summary(log.normal.linear)
# GLM-normal with the log link:
# (we are assuming log(E(y)) is linear)
glm.normal.loglink = glm(y ~ x, family=gaussian(link="log"), data=my.data)
summary(glm.normal.loglink)
# Log-normal distribution: transform the target with a log and then assume it is normal distributed
# (we are modeling E(log(y)) in a linear way)
log.normal.linear <- glm(log(y) ~ x, family=gaussian, data=Arrests)
summary(log.normal.linear)
# GLM-normal with the log link:
# (we are assuming log(E(y)) is linear)
glm.normal.loglink = glm(y ~ x, family=gaussian(link="log"), data=Arrests)
summary(glm.normal.loglink)
arrests.mod <- glm(released ~ colour*age, family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released ~ , family=binomial(link="logit"), data=Arrests)
arrests.mod <- glm(released ~ , family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released ~ , family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released , family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released, family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released, family=binomial(link="logit"), data=Arrests)
arrests.mod <- glm(released ~ colour, family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- lm(released ~ , data=Arrests)
summary(arrests.mod)
lm(released ~ , data=Arrests)
lm(released, data=Arrests)
arrests.mod <- lm(released ~ -, data=Arrests)
arrests.mod <- lm(released ~ ., data=Arrests)
arrests.mod <- lm(released ~ colour, data=Arrests)
arrests.mod <- lm(released ~ age, data=Arrests)
arrests.mod <- lm(released ~ age, data=Arrests)
arrests.mod <- lm(released ~ , data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released ~ , data=Arrests)
summary(arrests.mod)
summary(arrests.mod)
arrests.mod <- glm(released ~ colour*age, family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released ~ colour + age, family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released ~ colour*age, family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released ~ ., family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released ~ colour:age, family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
*
*
arrests.mod <- glm(released ~ colour*age, family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released ~ colour*age*employed, family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released ~ colour:age, family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released ~ colour*age, family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released ~ .*., family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released ~ colour*age, family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released ~ colour*sex, family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
arrests.mod <- glm(released ~ colour*age, family=binomial(link="logit"), data=Arrests)
summary(arrests.mod)
plot(effect("colour", arrests.mod), ci.style="band", rescale.axis=FALSE, multiline=TRUE, ylab="P(released)", rug=FALSE, main="")
plot(effect("age", arrests.mod), ci.style="band", rescale.axis=FALSE, multiline=TRUE, ylab="P(released)", rug=FALSE, main="")
plot(effect("age", arrests.mod), ci.style="band", rescale.axis=FALSE, multiline=TRUE, ylab="P(released)", rug=FALSE, main="")
plot(effect("colour:age", arrests.mod), ci.style="band", rescale.axis=FALSE, multiline=TRUE, ylab="P(released)", rug=FALSE, main="")
summary(arrests.mod)
plot(effect("colour", arrests.mod), ci.style="band", rescale.axis=FALSE, multiline=TRUE, ylab="P(released)", rug=FALSE, main="")
plot(effect("age", arrests.mod), ci.style="band", rescale.axis=FALSE, multiline=TRUE, ylab="P(released)", rug=FALSE, main="")
plot(effect("colour:age", arrests.mod), ci.style="band", rescale.axis=FALSE, multiline=TRUE, ylab="P(released)", rug=FALSE, main="")
min(Arrests$age)
max(Arrests$age)
plot(effect("age", arrests.mod), ci.style="band", rescale.axis=FALSE, multiline=TRUE, ylab="P(released)", rug=FALSE, main="")
plot(effect("colour:age", arrests.mod), ci.style="band", rescale.axis=FALSE, multiline=TRUE, ylab="P(released)", rug=FALSE, main="")
require("knitr")
opts_knit$set(root.dir = "C:/Users/jherraez/Documents/ASIGNATURAS MASTER/09. Aprendizaje no supervisado/01. Clustering jerárquico y no jerárquico/")
setwd("C:/Users/jherraez/Documents/ASIGNATURAS MASTER/09. Aprendizaje no supervisado/01. Clustering jerárquico y no jerárquico/")
####################
# Lectura de datos #
####################
datosBanca <- read.csv("Data/datosBanca.csv", header = TRUE, sep=",")
summary(datosBanca)
# Estandarización mediante discretización
# install.packages("nima")
library(nima)
datosBanca$checkingAccount_CAT<-discrete_by_quantile(datosBanca$checkingAccount)/4
datosBanca$deposit_CAT<-discrete_by_quantile(datosBanca$deposit)/4
datosBanca$shareOfStock_CAT<-discrete_by_quantile(datosBanca$shareOfStock)/4
datosBanca$pensionPlan_CAT<-discrete_by_quantile(datosBanca$pensionPlan)/4
#datosBanca$mortgage_CAT<-discrete_by_quantile(datosBanca$mortgage)/4
# Como da un error, la asignamos con IF
summary(datosBanca$mortgage)
datosBanca$mortgage_CAT<-datosBanca$mortgage
datosBanca$mortgage_CAT <- ifelse(datosBanca$mortgage <= 0, 1, datosBanca$mortgage_CAT)
datosBanca$mortgage_CAT <- ifelse(0<datosBanca$mortgage & datosBanca$mortgage<= 44752, 2, datosBanca$mortgage_CAT)
datosBanca$mortgage_CAT <- ifelse(44752<datosBanca$mortgage & datosBanca$mortgage<= 125483, 3, datosBanca$mortgage_CAT)
datosBanca$mortgage_CAT <- ifelse(125483<datosBanca$mortgage, 4, datosBanca$mortgage_CAT)
datosBanca$mortgage_CAT <- datosBanca$mortgage_CAT/4
summary(datosBanca$mortgage_CAT)
datosBanca$loan_CAT<-discrete_by_quantile(datosBanca$loan)/4
datosBanca$cards_CAT<-discrete_by_quantile(datosBanca$cards)/4
datosBanca$insurance_CAT<-discrete_by_quantile(datosBanca$insurance)/4
datosBanca$billPayment_CAT<-discrete_by_quantile(datosBanca$billPayment)/4
# La domiciliación de nómina es binaria y no es preciso estandarizarla
# Importante hacerla numérica porque si no, la considera integer y su AVERAGE vía SQL devuelve 0
datosBanca$salary_CAT<-as.numeric(datosBanca$salary)
summary(datosBanca)
# Cambiar missings por 0 #
datosBanca$checkingAccount_CAT[is.na(datosBanca$checkingAccount_CAT)]<-0
datosBanca$deposit_CAT[is.na(datosBanca$deposit_CAT)]<-0
datosBanca$shareOfStock_CAT[is.na(datosBanca$shareOfStock_CAT)]<-0
datosBanca$pensionPlan_CAT[is.na(datosBanca$pensionPlan_CAT)]<-0
datosBanca$mortgage_CAT[is.na(datosBanca$mortgage_CAT)]<-0
datosBanca$loan_CAT[is.na(datosBanca$loan_CAT)]<-0
datosBanca$cards_CAT[is.na(datosBanca$cards_CAT)]<-0
datosBanca$insurance_CAT[is.na(datosBanca$insurance_CAT)]<-0
datosBanca$billPayment_CAT[is.na(datosBanca$billPayment_CAT)]<-0
# install.packages("sqldf")
library(sqldf)
centroideTotalCartera <-  sqldf("Select
avg(checkingAccount_CAT) as checkingAccount_CAT,
avg(deposit_CAT) as deposit_CAT,
avg(shareOfStock_CAT) as shareOfStock_CAT,
avg(pensionPlan_CAT) as pensionPlan_CAT,
avg(mortgage_CAT) as mortgage_CAT,
avg(loan_CAT) as loan_CAT,
avg(cards_CAT) as cards_CAT,
avg(insurance_CAT) as insurance_CAT,
avg(billPayment_CAT) as billPayment_CAT,
avg(salary_CAT) as salary_CAT
from datosBanca")
clientesNominados <- subset(datosBanca,datosBanca$salary==1)
centroideNominados <-  sqldf("Select
avg(checkingAccount_CAT) as checkingAccount_CAT,
avg(deposit_CAT) as deposit_CAT,
avg(shareOfStock_CAT) as shareOfStock_CAT,
avg(pensionPlan_CAT) as pensionPlan_CAT,
avg(mortgage_CAT) as mortgage_CAT,
avg(loan_CAT) as loan_CAT,
avg(cards_CAT) as cards_CAT,
avg(insurance_CAT) as insurance_CAT,
avg(billPayment_CAT) as billPayment_CAT,
avg(salary_CAT) as salary_CAT
from clientesNominados")
clientesHipotecados <- subset(datosBanca,datosBanca$mortgage_CAT>0)
centroideHipotecados <-  sqldf("Select
avg(checkingAccount_CAT) as checkingAccount_CAT,
avg(deposit_CAT) as deposit_CAT,
avg(shareOfStock_CAT) as shareOfStock_CAT,
avg(pensionPlan_CAT) as pensionPlan_CAT,
avg(mortgage_CAT) as mortgage_CAT,
avg(loan_CAT) as loan_CAT,
avg(cards_CAT) as cards_CAT,
avg(insurance_CAT) as insurance_CAT,
avg(billPayment_CAT) as billPayment_CAT,
avg(salary_CAT) as salary_CAT
from clientesHipotecados")
clientesInversores <- subset(datosBanca,datosBanca$shareOfStock_CAT>0)
centroideInversores <-  sqldf("Select
avg(checkingAccount_CAT) as checkingAccount_CAT,
avg(deposit_CAT) as deposit_CAT,
avg(shareOfStock_CAT) as shareOfStock_CAT,
avg(pensionPlan_CAT) as pensionPlan_CAT,
avg(mortgage_CAT) as mortgage_CAT,
avg(loan_CAT) as loan_CAT,
avg(cards_CAT) as cards_CAT,
avg(insurance_CAT) as insurance_CAT,
avg(billPayment_CAT) as billPayment_CAT,
avg(salary_CAT) as salary_CAT
from clientesInversores")
centroides<-rbind(centroideTotalCartera,centroideNominados,centroideHipotecados,centroideInversores)
# Adjuntamos los límites del gráfico de radar (0 y 1)
# Esto es necesario para utilizar la función gráfica de rádar
# También adjuntamos el comportamiento medio de la cartera
# para poder comparar cada centroide con la media total
# install.packages("fmsb")
library(fmsb)
centroidesParaRadar<-rbind(
rep(1,10) ,
rep(0,10) ,
centroides)
colors_border=c( rgb(0.2,0.5,0.5,0.9), rgb(0.8,0.2,0.5,0.9) , rgb(0.7,0.5,0.1,0.9) )
colors_in=c( rgb(0.2,0.5,0.5,0.4), rgb(0.8,0.2,0.5,0.4) , rgb(0.7,0.5,0.1,0.4) )
for (i in 4:nrow(centroidesParaRadar)-3)
{
radarchart( as.data.frame(centroidesParaRadar[c(1:3,3+i),])  , axistype=1 ,
#custom polygon
pcol=colors_border , pfcol=colors_in , plwd=4 , plty=1,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", caxislabels=seq(0,1,5), cglwd=0.8,
#custom labels
vlcex=0.8
)
}
View(datosBanca)
datosBanca$mortgage_CAT<-discrete_by_quantile(datosBanca$mortgage)/4
cor(datosBanca[, 12:21], method = "spearman") # mejor que la correlación normal
View(centroides)
View(centroidesParaRadar)
setwd("masterAFI/10. Regresion Avanzada/02. Regresión avanzada/Lab 3 Credit Scoring/")
library(tidyverse)
library(skimr)
library(mice)
library(VIM)
library(GGally)
library(MASS)
library(glmnet)
library(e1071)
library(rpart)
library(pROC)
library(class)
library(randomForest)
library(caret)
dataCredit<-read.csv("credit-scoring.csv", header = TRUE, sep = ",")
glimpse(dataCredit)
dataCredit <- dataCredit[,-1]
names(dataCredit)[1] = "Creditability"
dataCredit$Creditability = as.factor(dataCredit$Creditability)
levels(dataCredit$Creditability)=c("Good", "Bad")
in_train <- createDataPartition(dataCredit$Creditability, p = 0.2, list = FALSE)  # 20% for training
training <- dataCredit[ in_train,]
testing <- dataCredit[-in_train,]
nrow(training)
nrow(testing)
table(training$Creditability)/length(training$Creditability)
summary(training)
exp(-0.3)
exp(0.3)
# Chunk 1: global_options
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
# Chunk 2
htmltools::img(src = knitr::image_uri(file.path("AfiLogo.jpg")),
alt = 'logo',
style = 'position:absolute; top:0; right:0; padding:10px;',
width="173",
height="77")
# Chunk 3
library(tidyverse)
library(skimr)
library(mice)
library(VIM)
library(GGally)
library(MASS)
library(glmnet)
library(e1071)
library(rpart)
library(pROC)
library(class)
library(randomForest)
library(caret)
# Chunk 4
dataCredit<-read.csv("credit-scoring.csv", header = TRUE, sep = ",")
glimpse(dataCredit)
# Chunk 5
dataCredit <- dataCredit[,-1]
names(dataCredit)[1] = "Creditability"
dataCredit$Creditability = as.factor(dataCredit$Creditability)
levels(dataCredit$Creditability)=c("Good", "Bad")
# Chunk 6
in_train <- createDataPartition(dataCredit$Creditability, p = 0.2, list = FALSE)  # 20% for training
training <- dataCredit[ in_train,]
testing <- dataCredit[-in_train,]
nrow(training)
nrow(testing)
table(training$Creditability)/length(training$Creditability)
# Chunk 7
summary(training)
# Chunk 8
# Insert your code here
# Chunk 9
table(training$NumberOfTime30.59DaysPastDueNotWorse)
table(training$NumberOfTime60.89DaysPastDueNotWorse)
table(training$NumberOfTimes90DaysLate)
# Chunk 10
training$NumberOfTime30.59DaysPastDueNotWorse[training$NumberOfTime30.59DaysPastDueNotWorse==96] <- 0
training$NumberOfTime30.59DaysPastDueNotWorse[training$NumberOfTime30.59DaysPastDueNotWorse==98] <- 0
training$NumberOfTime60.89DaysPastDueNotWorse[training$NumberOfTime60.89DaysPastDueNotWorse==96] <- 0
training$NumberOfTime60.89DaysPastDueNotWorse[training$NumberOfTime60.89DaysPastDueNotWorse==98] <- 0
training$NumberOfTimes90DaysLate[training$NumberOfTimes90DaysLate==96] <- 0
training$NumberOfTimes90DaysLate[training$NumberOfTimes90DaysLate==98] <- 0
testing$NumberOfTime30.59DaysPastDueNotWorse[testing$NumberOfTime30.59DaysPastDueNotWorse==96] <- 0
testing$NumberOfTime30.59DaysPastDueNotWorse[testing$NumberOfTime30.59DaysPastDueNotWorse==98] <- 0
testing$NumberOfTime60.89DaysPastDueNotWorse[testing$NumberOfTime60.89DaysPastDueNotWorse==96] <- 0
testing$NumberOfTime60.89DaysPastDueNotWorse[testing$NumberOfTime60.89DaysPastDueNotWorse==98] <- 0
testing$NumberOfTimes90DaysLate[testing$NumberOfTimes90DaysLate==96] <- 0
testing$NumberOfTimes90DaysLate[testing$NumberOfTimes90DaysLate==98] <- 0
# Chunk 11
if(sum(training$NumberRealEstateLoansOrLines==54)>0){
training<-training[-(which(training$NumberRealEstateLoansOrLines==54)),]
}
# Chunk 12
# Insert your code here
# Chunk 14
# Replace NA in NumberOfDependents with 0
training$NumberOfDependents[is.na(training$NumberOfDependents)] <- 0
testing$NumberOfDependents[is.na(testing$NumberOfDependents)] <- 0
# Imputation with median
training$MonthlyIncome = ifelse(is.na(training$MonthlyIncome), median(training$MonthlyIncome, na.rm=TRUE), training$MonthlyIncome)
# note we impute NA in testing with info from training
testing$MonthlyIncome = ifelse(is.na(testing$MonthlyIncome), median(training$MonthlyIncome, na.rm=TRUE), testing$MonthlyIncome)
# Chunk 16
ggcorr(training[,-1], label = T)
# Chunk 17
logit.model <- glm(Creditability ~ ., family=binomial(link='logit'), data=training)
summary(logit.model)
# Chunk 18
exp(coef(logit.model))
# Chunk 19
probability <- predict(logit.model,newdata=testing, type='response')
head(probability)
prediction <- as.factor(ifelse(probability > 0.5,"Bad","Good"))
head(prediction)
# Type your code here for the confusion matrix
confusionMatrix(prediction, testing$Creditability)
table(prediction)
table(prediction)/table(testing$Creditability)
table(prediction/testing$Creditability)
table(paste(prediction, testing$Creditability))
# Type your code here for the confusion matrix
confusionMatrix(prediction, testing$Creditability)
table(paste(prediction, testing$Creditability))
(111162 + 1141)/sum(table(paste(prediction, testing$Creditability)))
sum(table(paste(prediction, testing$Creditability)))
sum(table(paste(prediction, testing$Creditability))) * 0.93
table(testing$Creditability)
probability <- predict(logit.model,newdata=testing, type='response')
head(probability)
prediction <- as.factor(ifelse(probability > 0.7,"Bad","Good"))
head(prediction)
table(paste(prediction, testing$Creditability))
probability <- predict(logit.model,newdata=testing, type='response')
head(probability)
prediction <- as.factor(ifelse(probability > 0.5,"Bad","Good"))
head(prediction)
table(paste(prediction, testing$Creditability))
table(paste("P", prediction, testing$Creditability))
table(paste("P", prediction, "T", testing$Creditability))
reshape?
prediction <- as.factor(ifelse(probability > 0.5,"Bad","Good"))
table(paste("P", prediction, "T", testing$Creditability))
probability <- predict(logit.model,newdata=testing, type='response')
head(probability)
prediction <- as.factor(ifelse(probability > 0.3,"Bad","Good"))
head(prediction)
table(paste("P", prediction, "T", testing$Creditability))
# Type your code here for the confusion matrix
confusionMatrix(prediction, testing$Creditability)
probability <- predict(logit.model,newdata=testing, type='response')
head(probability)
prediction <- as.factor(ifelse(probability > 0.3,"Bad","Good"))
head(prediction)
# Type your code here for the confusion matrix
confusionMatrix(prediction, testing$Creditability)
probability <- predict(logit.model,newdata=testing, type='response')
head(probability)
prediction <- as.factor(ifelse(probability > 0.5,"Bad","Good"))
head(prediction)
# Type your code here for the confusion matrix
confusionMatrix(prediction, testing$Creditability)
logit.model <- glmnet(as.matrix(training[,-1]),training$Creditability, family=c("binomial"), alpha=0, lambda=0.01)
probability <- predict(logit.model,as.matrix(testing[,-1]), type='response')
prediction <- as.factor(ifelse(probability > 0.5,"Bad","Good"))
confusionMatrix(prediction, testing$Creditability)
model <- glm(Creditability ~ ., family=binomial(link='logit'), data=training)
probability = predict(model, testing)
roc.lda <- roc(testing$Creditability,probability)
auc(roc.lda)
plot.roc(testing$Creditability, probability,col="darkblue", print.auc = TRUE,  auc.polygon=TRUE, grid=c(0.1, 0.2),
grid.col=c("green", "red"), max.auc.polygon=TRUE,
auc.polygon.col="lightblue", print.thres=TRUE)
probability = predict(model, testing, type = 'response')
roc.lda <- roc(testing$Creditability,probability)
auc(roc.lda)
plot.roc(testing$Creditability, probability,col="darkblue", print.auc = TRUE,  auc.polygon=TRUE, grid=c(0.1, 0.2),
grid.col=c("green", "red"), max.auc.polygon=TRUE,
auc.polygon.col="lightblue", print.thres=TRUE)
profit.unit <- c(0.12, -0.01, -1.0, 0.0)
threshold = 0.5
Cred.pred = rep("Good", nrow(testing))
Cred.pred[which(probability > threshold)] = "Bad"
CM = confusionMatrix(factor(Cred.pred), testing$Creditability)$table
profit.applicant <- sum(profit.unit*CM)/sum(CM)
profit.applicant
profit.applicant*15000*10000
profit.i = matrix(NA, nrow = 50, ncol = 10)
# 50 replicates for training/testing sets for each of the 10 values of threshold
j <- 0
for (threshold in seq(0.05,0.5,0.05)){
#for (p1 in c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.75, 0.8, 0.9)){
j <- j + 1
cat(j)
for(i in 1:50){
# partition data intro training (40%) and testing sets (60%)
d <- createDataPartition(training$Creditability, p = 0.4, list = FALSE)
# select training sample
train<-training[d,]
test <-training[-d,]
full.model = glm(Creditability ~ ., family=binomial(link='logit'), data=train)
# probabilities
probability = predict(full.model, test, type="response")
# Predictions with a given threshold
Cred.pred = rep("Good", nrow(test))
Cred.pred[which(probability > threshold)] = "Bad"
CM = confusionMatrix(factor(Cred.pred), test$Creditability)$table
profit.applicant <- sum(profit.unit*CM)/sum(CM)
profit.i[i,j] <- profit.applicant
}
}
boxplot(profit.i, main = "Hyper-parameter selection",
ylab = "unit profit",
xlab = "threshold",names = seq(0.05,0.5,0.05),col="royalblue2")
CM
profit.i
profit
profit.i
profit.1
profit.i = matrix(NA, nrow = 50, ncol = 6)
# 50 replicates for training/testing sets for each of the 10 values of threshold
j <- 0
for (threshold in seq(0.05,0.15,0.02)){
#for (p1 in c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.75, 0.8, 0.9)){
j <- j + 1
cat(j)
for(i in 1:50){
# partition data intro training (40%) and testing sets (60%)
d <- createDataPartition(training$Creditability, p = 0.4, list = FALSE)
# select training sample
train<-training[d,]
test <-training[-d,]
full.model = glm(Creditability ~ ., family=binomial(link='logit'), data=train)
# probabilities
probability = predict(full.model, test, type="response")
# Predictions with a given threshold
Cred.pred = rep("Good", nrow(test))
Cred.pred[which(probability > threshold)] = "Bad"
CM = confusionMatrix(factor(Cred.pred), test$Creditability)$table
profit.applicant <- sum(profit.unit*CM)/sum(CM)
profit.i[i,j] <- profit.applicant
}
}
boxplot(profit.i, main = "Hyper-parameter selection",
ylab = "unit profit",
xlab = "threshold",names = seq(0.05,0.5,0.05),col="royalblue2")
boxplot(profit.i, main = "Hyper-parameter selection",
ylab = "unit profit",
xlab = "threshold",names = seq(0.05,0.15,0.02),col="royalblue2")
apply(profit.i, 2, median)
final.model = glm(Creditability ~ ., family=binomial(link='logit'), data=training)
probability = predict(final.model, newdata=testing, type="response")
threshold = 0.1
Cred.pred = rep("Good", nrow(testing))
Cred.pred[which(probability > threshold)] = "Bad"
CM = confusionMatrix(factor(Cred.pred), testing$Creditability)$table
profit.applicant <- sum(profit.unit*CM)/sum(CM)
profit.applicant
profit.applicant*15000*10000
