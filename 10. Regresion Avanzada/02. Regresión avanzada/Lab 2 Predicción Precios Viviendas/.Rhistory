setwd("C:/Users/jherraez/Documents/ASIGNATURAS MASTER/09. Aprendizaje no supervisado/01. Clustering jerárquico y no jerárquico/")
####################
# Lectura de datos #
####################
datosBanca <- read.csv("Data/datosBanca.csv", header = TRUE, sep=",")
summary(datosBanca)
# Estandarización mediante discretización
# install.packages("nima")
library(nima)
datosBanca$checkingAccount_CAT<-discrete_by_quantile(datosBanca$checkingAccount)/4
datosBanca$deposit_CAT<-discrete_by_quantile(datosBanca$deposit)/4
datosBanca$shareOfStock_CAT<-discrete_by_quantile(datosBanca$shareOfStock)/4
datosBanca$pensionPlan_CAT<-discrete_by_quantile(datosBanca$pensionPlan)/4
#datosBanca$mortgage_CAT<-discrete_by_quantile(datosBanca$mortgage)/4
# Como da un error, la asignamos con IF
summary(datosBanca$mortgage)
datosBanca$mortgage_CAT<-datosBanca$mortgage
datosBanca$mortgage_CAT <- ifelse(datosBanca$mortgage <= 0, 1, datosBanca$mortgage_CAT)
datosBanca$mortgage_CAT <- ifelse(0<datosBanca$mortgage & datosBanca$mortgage<= 44752, 2, datosBanca$mortgage_CAT)
datosBanca$mortgage_CAT <- ifelse(44752<datosBanca$mortgage & datosBanca$mortgage<= 125483, 3, datosBanca$mortgage_CAT)
datosBanca$mortgage_CAT <- ifelse(125483<datosBanca$mortgage, 4, datosBanca$mortgage_CAT)
datosBanca$mortgage_CAT <- datosBanca$mortgage_CAT/4
summary(datosBanca$mortgage_CAT)
datosBanca$loan_CAT<-discrete_by_quantile(datosBanca$loan)/4
datosBanca$cards_CAT<-discrete_by_quantile(datosBanca$cards)/4
datosBanca$insurance_CAT<-discrete_by_quantile(datosBanca$insurance)/4
datosBanca$billPayment_CAT<-discrete_by_quantile(datosBanca$billPayment)/4
# La domiciliación de nómina es binaria y no es preciso estandarizarla
# Importante hacerla numérica porque si no, la considera integer y su AVERAGE vía SQL devuelve 0
datosBanca$salary_CAT<-as.numeric(datosBanca$salary)
summary(datosBanca)
# Cambiar missings por 0 #
datosBanca$checkingAccount_CAT[is.na(datosBanca$checkingAccount_CAT)]<-0
datosBanca$deposit_CAT[is.na(datosBanca$deposit_CAT)]<-0
datosBanca$shareOfStock_CAT[is.na(datosBanca$shareOfStock_CAT)]<-0
datosBanca$pensionPlan_CAT[is.na(datosBanca$pensionPlan_CAT)]<-0
datosBanca$mortgage_CAT[is.na(datosBanca$mortgage_CAT)]<-0
datosBanca$loan_CAT[is.na(datosBanca$loan_CAT)]<-0
datosBanca$cards_CAT[is.na(datosBanca$cards_CAT)]<-0
datosBanca$insurance_CAT[is.na(datosBanca$insurance_CAT)]<-0
datosBanca$billPayment_CAT[is.na(datosBanca$billPayment_CAT)]<-0
# install.packages("sqldf")
library(sqldf)
centroideTotalCartera <-  sqldf("Select
avg(checkingAccount_CAT) as checkingAccount_CAT,
avg(deposit_CAT) as deposit_CAT,
avg(shareOfStock_CAT) as shareOfStock_CAT,
avg(pensionPlan_CAT) as pensionPlan_CAT,
avg(mortgage_CAT) as mortgage_CAT,
avg(loan_CAT) as loan_CAT,
avg(cards_CAT) as cards_CAT,
avg(insurance_CAT) as insurance_CAT,
avg(billPayment_CAT) as billPayment_CAT,
avg(salary_CAT) as salary_CAT
from datosBanca")
clientesNominados <- subset(datosBanca,datosBanca$salary==1)
centroideNominados <-  sqldf("Select
avg(checkingAccount_CAT) as checkingAccount_CAT,
avg(deposit_CAT) as deposit_CAT,
avg(shareOfStock_CAT) as shareOfStock_CAT,
avg(pensionPlan_CAT) as pensionPlan_CAT,
avg(mortgage_CAT) as mortgage_CAT,
avg(loan_CAT) as loan_CAT,
avg(cards_CAT) as cards_CAT,
avg(insurance_CAT) as insurance_CAT,
avg(billPayment_CAT) as billPayment_CAT,
avg(salary_CAT) as salary_CAT
from clientesNominados")
clientesHipotecados <- subset(datosBanca,datosBanca$mortgage_CAT>0)
centroideHipotecados <-  sqldf("Select
avg(checkingAccount_CAT) as checkingAccount_CAT,
avg(deposit_CAT) as deposit_CAT,
avg(shareOfStock_CAT) as shareOfStock_CAT,
avg(pensionPlan_CAT) as pensionPlan_CAT,
avg(mortgage_CAT) as mortgage_CAT,
avg(loan_CAT) as loan_CAT,
avg(cards_CAT) as cards_CAT,
avg(insurance_CAT) as insurance_CAT,
avg(billPayment_CAT) as billPayment_CAT,
avg(salary_CAT) as salary_CAT
from clientesHipotecados")
clientesInversores <- subset(datosBanca,datosBanca$shareOfStock_CAT>0)
centroideInversores <-  sqldf("Select
avg(checkingAccount_CAT) as checkingAccount_CAT,
avg(deposit_CAT) as deposit_CAT,
avg(shareOfStock_CAT) as shareOfStock_CAT,
avg(pensionPlan_CAT) as pensionPlan_CAT,
avg(mortgage_CAT) as mortgage_CAT,
avg(loan_CAT) as loan_CAT,
avg(cards_CAT) as cards_CAT,
avg(insurance_CAT) as insurance_CAT,
avg(billPayment_CAT) as billPayment_CAT,
avg(salary_CAT) as salary_CAT
from clientesInversores")
centroides<-rbind(centroideTotalCartera,centroideNominados,centroideHipotecados,centroideInversores)
# Adjuntamos los límites del gráfico de radar (0 y 1)
# Esto es necesario para utilizar la función gráfica de rádar
# También adjuntamos el comportamiento medio de la cartera
# para poder comparar cada centroide con la media total
# install.packages("fmsb")
library(fmsb)
centroidesParaRadar<-rbind(
rep(1,10) ,
rep(0,10) ,
centroides)
colors_border=c( rgb(0.2,0.5,0.5,0.9), rgb(0.8,0.2,0.5,0.9) , rgb(0.7,0.5,0.1,0.9) )
colors_in=c( rgb(0.2,0.5,0.5,0.4), rgb(0.8,0.2,0.5,0.4) , rgb(0.7,0.5,0.1,0.4) )
for (i in 4:nrow(centroidesParaRadar)-3)
{
radarchart( as.data.frame(centroidesParaRadar[c(1:3,3+i),])  , axistype=1 ,
#custom polygon
pcol=colors_border , pfcol=colors_in , plwd=4 , plty=1,
#custom the grid
cglcol="grey", cglty=1, axislabcol="grey", caxislabels=seq(0,1,5), cglwd=0.8,
#custom labels
vlcex=0.8
)
}
View(datosBanca)
datosBanca$mortgage_CAT<-discrete_by_quantile(datosBanca$mortgage)/4
cor(datosBanca[, 12:21], method = "spearman") # mejor que la correlación normal
View(centroides)
View(centroidesParaRadar)
ls()
setwd("masterAFI/10. Regresion Avanzada/02. Regresión avanzada/Lab 2 Predicción Precios Viviendas/")
# Chunk 1: global_options
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
# Chunk 2
htmltools::img(src = knitr::image_uri(file.path("AfiLogo.jpg")),
alt = 'logo',
style = 'position:absolute; top:0; right:0; padding:10px;',
width="173",
height="77")
# Chunk 3
# delete everything
rm(list=ls())
library(leaflet)
library(tidyverse)
library(MASS)
library(caret)
# Chunk 4
data(Sacramento)
# Chunk 5
names(Sacramento)
dim(Sacramento)
str(Sacramento)
summary(Sacramento)
# Chunk 6
in_train <- createDataPartition(log(Sacramento$price), p = 0.75, list = FALSE)  # 75% for training
training <- Sacramento[ in_train,]
testing <- Sacramento[-in_train,]
nrow(training)
nrow(testing)
# Chunk 7
color_pal <- colorNumeric(palette = "RdYlBu", domain = training$price, reverse=T)
map = leaflet(training) %>%
addProviderTiles(providers$CartoDB.Positron) %>%
setView(lng=median(training$longitude), lat=median(training$latitude), zoom = 9) %>%
# Marcas mediante circulos
addCircles(lng = ~longitude,
lat = ~latitude,
radius = ~sqrt(sqft)*2,
color = ~color_pal(price)) %>%
addLabelOnlyMarkers(
lng = median(training$longitude)-.6, lat = median(training$latitude)+.3,
label = "Price and size",
labelOptions = labelOptions(textsize = "20px",noHide = T, textOnly = T))
map %>% addLegend(position="bottomleft", pal = color_pal, values = ~price, bins=4)
# Chunk 8
training %>% ggplot(aes(x=price)) + geom_density(fill="navyblue") + scale_x_log10()
# Chunk 9
training %>% ggplot(aes(x=price/sqft)) + geom_density(fill="navyblue") + scale_x_log10()
# Chunk 10
ggplot(training, aes(x=sqft, y=price)) + ylab("price") +
geom_point(alpha=0.6) + ggtitle("Price vs size of living area")
# Chunk 11
ggplot(training, aes(x=sqft, y=log(price))) + ylab("log price") + geom_point(alpha=0.6) + ggtitle("Price vs size of living area")
# Chunk 12
ggplot(training, aes(x=log(sqft), y=log(price))) + ylab("log price") + geom_point(alpha=0.6) + ggtitle("Price vs size of living area")
# Chunk 13
summary(training)
# Chunk 14
corr_price <- sort(cor(training[,c(3,4,5,7,8,9)])["price",], decreasing = T)
corr=data.frame(corr_price)
ggplot(corr,aes(x = row.names(corr), y = corr_price)) +
geom_bar(stat = "identity", fill = "lightblue") +
scale_x_discrete(limits= row.names(corr)) +
labs(x = "Predictors", y = "Price", title = "Correlations") +
theme(plot.title = element_text(hjust = 0, size = rel(1.5)),
axis.text.x = element_text(angle = 45, hjust = 1))
# Chunk 15
linFit <- lm(log(price) ~ beds + baths + log(sqft) + type + latitude*longitude, data=training)
summary(linFit)
# Chunk 16
pr.multiple = exp(predict(linFit, newdata=testing))
cor(testing$price, pr.multiple)^2
# Chunk 17
library(leaps)
exhaustive <- regsubsets(log(price) ~ beds + baths*type + log(sqft) + latitude*longitude + I(longitude^2) + I(latitude^2), data=training)
summary(exhaustive)
plot(summary(exhaustive)$bic, type = 'l')
# Chunk 18
library(olsrr)
model = log(price) ~ beds + baths*type + log(sqft) + latitude*longitude + I(longitude^2) + I(latitude^2)
linFit <- lm(model, data=training)
ols_step_all_possible(linFit) # All possible subset regressions: the number is exponential with p
ols_step_best_subset(linFit) # The best subset regression for each p: still exponential with p
# Chunk 19
ols_step_forward_p(linFit) # forward based on p-value
plot(ols_step_forward_p(linFit))
# Chunk 20
ols_step_forward_aic(linFit) # forward based on AIC
# Chunk 21
ols_step_backward_aic(linFit) # backward AIC
# Chunk 22
ols_step_both_aic(linFit) # stepwise AIC
# Chunk 23
linFit <- lm(log(price) ~ beds + baths*type + log(sqft) + type + I(longitude^2), data=training)
summary(linFit)
# Chunk 24
predictions <- exp(predict(linFit, newdata=testing))
cor(testing$price, predictions)^2
RMSE <- sqrt(mean((predictions - testing$price)^2))
RMSE
# Chunk 25
mean(training$price)
# This is equivalent to
benchFit <- lm(price ~ 1, data=training)
predictions <- predict(benchFit, newdata=testing)
cor(testing$price, predictions)^2
RMSE <- sqrt(mean((predictions - testing$price)^2))
RMSE
# Chunk 26
ctrl <- trainControl(method = "repeatedcv",
number = 5, repeats = 1)
# Chunk 27
training$bedsperbath = training$beds/training$baths
testing$bedsperbath = testing$beds/testing$baths
# Chunk 28
linFit <- lm(log(price) ~ bedsperbath*type + log(sqft) + latitude:longitude + I(latitude^2)+ I(longitude^2), data=training)
# The syntax x1:x2 tells R to include an interaction term between
# x1 and x2. The syntax x1*x2 simultaneously includes x1, x2,
# and the interaction term x1:x2 as predictors; it is a shorthand for
# x1+x2+x1:x2
summary(linFit)
# Chunk 29
ModelS = log(price) ~ beds + baths + log(sqft) + type + latitude + longitude
ModelF = log(price) ~ bedsperbath*type + log(sqft) + latitude:longitude + I(latitude^2)+ I(longitude^2)
# Chunk 30
levels(training$city) <- levels(Sacramento$city)
levels(training$zip) <- levels(Sacramento$zip)
# Chunk 31
ModelFF = log(price) ~ city + zip + bedsperbath*type + log(sqft) + latitude:longitude + I(latitude^2)+ I(longitude^2)
# Chunk 32
test_results <- data.frame(price = log(testing$price))
# Chunk 33
lm_tune <- train(ModelS, data = training,
method = "lm",
preProc=c('scale', 'center'),
trControl = ctrl)
lm_tune
# Chunk 34
test_results$lm <- predict(lm_tune, testing)
postResample(pred = test_results$lm,  obs = test_results$price)
# Chunk 35
qplot(test_results$lm, test_results$price) +
labs(title="Linear Regression Observed VS Predicted", x="Predicted", y="Observed") +
lims(x = c(10, 15), y = c(10, 15)) +
geom_abline(intercept = 0, slope = 1, colour = "blue") +
theme_bw()
# Chunk 36
alm_tune <- train(ModelFF, data = training,
method = "lm",
preProc=c('scale', 'center'),
trControl = ctrl)
# Chunk 37
test_results$alm <- predict(alm_tune, testing)
postResample(pred = test_results$alm,  obs = test_results$price)
# Chunk 38
qplot(test_results$alm, test_results$price) +
labs(title="Linear Regression Observed VS Predicted", x="Predicted", y="Observed") +
lims(x = c(10, 15), y = c(10, 15)) +
geom_abline(intercept = 0, slope = 1, colour = "blue") +
theme_bw()
# Chunk 39
for_tune <- train(ModelF, data = training,
method = "leapForward",
preProc=c('scale', 'center'),
tuneGrid = expand.grid(nvmax = 4:10),
trControl = ctrl)
for_tune
plot(for_tune)
# Chunk 40
coef(for_tune$finalModel, for_tune$bestTune$nvmax)
# Chunk 41
test_results$frw <- predict(for_tune, testing)
postResample(pred = test_results$frw,  obs = test_results$price)
# Chunk 42
qplot(test_results$frw, test_results$price) +
labs(title="Forward Regression Observed VS Predicted", x="Predicted", y="Observed") +
lims(x = c(10, 15), y = c(10, 15)) +
geom_abline(intercept = 0, slope = 1, colour = "blue") +
theme_bw()
# Chunk 43
back_tune <- train(ModelF, data = training,
method = "leapBackward",
preProc=c('scale', 'center'),
tuneGrid = expand.grid(nvmax = 4:10),
trControl = ctrl)
back_tune
plot(back_tune)
# Chunk 44
coef(back_tune$finalModel, back_tune$bestTune$nvmax)
# Chunk 45
test_results$bw <- predict(back_tune, testing)
postResample(pred = test_results$bw,  obs = test_results$price)
# Chunk 46
qplot(test_results$bw, test_results$price) +
labs(title="Backward Regression Observed VS Predicted", x="Predicted", y="Observed") +
lims(x = c(10, 15), y = c(10, 15)) +
geom_abline(intercept = 0, slope = 1, colour = "blue") +
theme_bw()
# Chunk 47
step_tune <- train(ModelF, data = training,
method = "leapSeq",
preProc=c('scale', 'center'),
tuneGrid = expand.grid(nvmax = 4:10),
trControl = ctrl)
plot(step_tune)
# which variables are selected?
coef(step_tune$finalModel, step_tune$bestTune$nvmax)
test_results$seq <- predict(step_tune, testing)
postResample(pred = test_results$seq,  obs = test_results$price)
# Chunk 48
library(glmnet)
# X matrix
X = model.matrix(ModelF, data=training)[,-1]  # skip column of ones
# y variable
y = log(training$price)
# Chunk 49
grid = seq(0, .1, length = 100)  # a 100-size grid for lambda (rho in slides)
# Chunk 50
ridge.mod = glmnet(X, y, alpha=0, lambda=grid)  # alpha=0 for ridge regression
# Chunk 51
dim(coef(ridge.mod))
coef(ridge.mod)
# Chunk 52
plot(ridge.mod, xvar="lambda")
# Chunk 53
ridge.cv = cv.glmnet(X, y, type.measure="mse", alpha=0)
plot(ridge.cv)
# Chunk 54
opt.lambda <- ridge.cv$lambda.min
opt.lambda
# Chunk 55
lambda.index <- which(ridge.cv$lambda == ridge.cv$lambda.1se)
beta.ridge <- ridge.cv$glmnet.fit$beta[, lambda.index]
beta.ridge
# Chunk 56
X.test = model.matrix(ModelF, data=testing)[,-1]  # skip column of ones
ridge.pred = predict(ridge.cv$glmnet.fit, s=opt.lambda, newx=X.test)
# Chunk 57
y.test = log(testing$price)
postResample(pred = ridge.pred,  obs = y.test)
# Chunk 58
# the grid for lambda
ridge_grid <- expand.grid(lambda = seq(0, .1, length = 100))
# train
ridge_tune <- train(ModelF, data = training,
method='ridge',
preProc=c('scale','center'),
tuneGrid = ridge_grid,
trControl=ctrl)
training %>% ggplot(aes(x=price/sqft)) + geom_density(fill="navyblue") + scale_x_log10()
training %>% ggplot(aes(x=price/sqft)) + geom_density(fill="navyblue")
cor(training)
cor(training[is.numeric()])
cor(training[is.numeric(training)])
```{r}
training[is.numeric(training)]
summary(lm(log(price) ~ ., data=training))
lm(log(price) ~ beds + baths + log(sqft) + type + latitude + longitude, data=training)
summary(lm(log(price) ~ . - city - zip, data=training))
summary(lm(price ~ . - city - zip, data=training))
summary(lm(log(price) ~ . - city - zip, data=training))
prueba = (log(price) ~ . - city - zip, data=training)
prueba = lm(log(price) ~ . - city - zip, data=training)
summary(prueba)
exp(predict(prueba, newdata=testing))
prueba = lm(log(price) ~ . - city - zip, data=training)
summary(prueba)
exp(predict(prueba, newdata=testing))
testting
testing
predict(prueba, newdata=testing)
predict(prueba, newdata=testing[,-c('city', 'zip')])
predict(prueba, newdata=testing[,-c('city', 'zip')])
testing[,-c('city', 'zip')]
testing[-c('city', 'zip')]
testing[, colnames %in% c('city', 'zip')]
testing[, colnames(testing) %in% c('city', 'zip')]
testing[, - colnames(testing) %in% c('city', 'zip')]
testing[, !colnames(testing) %in% c('city', 'zip')]
testing[, !colnames(testing) %in% c('city', 'zip')]
predict(prueba, newdata=testing[, !colnames(testing) %in% c('city', 'zip')])
linFit <- lm(log(price) ~ beds + baths + log(sqft) + type + latitude*longitude, data=training)
summary(linFit)
pr.multiple = exp(predict(linFit, newdata=testing))
cor(testing$price, pr.multiple)^2
pr.multiple = exp(predict(prueba, newdata=testing))
cor(testing$price, pr.multiple)^2
prueba
prueba <- lm(log(price) ~ beds + baths + log(sqft) + type + latitude*longitude, data=training)
pr.multiple = exp(predict(prueba, newdata=testing))
cor(testing$price, pr.multiple)^2
prueba <- lm(log(price) ~ . -city - zip, data=training)
pr.multiple = exp(predict(prueba, newdata=testing))
summary(prueba)
prueba2 <- lm(log(price) ~ beds + baths + log(sqft) + type + latitude + longitude, data=training)
summary(prueba2)
pr.multiple = exp(predict(prueba2, newdata=testing))
pr.multiple = exp(predict(prueba, newdata=testing))
prueba3 <- lm(log(price) ~ beds + baths + sqft) + type + latitude + longitude, data=training)
prueba3 <- lm(log(price) ~ beds + baths + sqft + type + latitude + longitude + bedsperbath, data=training)
pr.multiple = exp(predict(prueba3, newdata=testing))
summary(prueba3)
summary(prueba)
pr.multiple = exp(predict(prueba3, newdata=testing))
pr.multiple = exp(predict(prueba, newdata=testing))
# Chunk 1: global_options
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
# Chunk 2
htmltools::img(src = knitr::image_uri(file.path("AfiLogo.jpg")),
alt = 'logo',
style = 'position:absolute; top:0; right:0; padding:10px;',
width="173",
height="77")
# Chunk 3
# delete everything
rm(list=ls())
library(leaflet)
library(tidyverse)
library(MASS)
library(caret)
# Chunk 4
data(Sacramento)
# Chunk 5
names(Sacramento)
dim(Sacramento)
str(Sacramento)
summary(Sacramento)
# Chunk 6
in_train <- createDataPartition(log(Sacramento$price), p = 0.75, list = FALSE)  # 75% for training
training <- Sacramento[ in_train,]
testing <- Sacramento[-in_train,]
nrow(training)
nrow(testing)
# Chunk 7
color_pal <- colorNumeric(palette = "RdYlBu", domain = training$price, reverse=T)
map = leaflet(training) %>%
addProviderTiles(providers$CartoDB.Positron) %>%
setView(lng=median(training$longitude), lat=median(training$latitude), zoom = 9) %>%
# Marcas mediante circulos
addCircles(lng = ~longitude,
lat = ~latitude,
radius = ~sqrt(sqft)*2,
color = ~color_pal(price)) %>%
addLabelOnlyMarkers(
lng = median(training$longitude)-.6, lat = median(training$latitude)+.3,
label = "Price and size",
labelOptions = labelOptions(textsize = "20px",noHide = T, textOnly = T))
map %>% addLegend(position="bottomleft", pal = color_pal, values = ~price, bins=4)
# Chunk 8
training %>% ggplot(aes(x=price)) + geom_density(fill="navyblue") + scale_x_log10()
# Chunk 9
training %>% ggplot(aes(x=price/sqft)) + geom_density(fill="navyblue") + scale_x_log10()
# Chunk 10
ggplot(training, aes(x=sqft, y=price)) + ylab("price") +
geom_point(alpha=0.6) + ggtitle("Price vs size of living area")
# Chunk 11
ggplot(training, aes(x=sqft, y=log(price))) + ylab("log price") + geom_point(alpha=0.6) + ggtitle("Price vs size of living area")
# Chunk 12
ggplot(training, aes(x=log(sqft), y=log(price))) + ylab("log price") + geom_point(alpha=0.6) + ggtitle("Price vs size of living area")
# Chunk 13
summary(training)
# Chunk 14
corr_price <- sort(cor(training[,c(3,4,5,7,8,9)])["price",], decreasing = T)
corr=data.frame(corr_price)
ggplot(corr,aes(x = row.names(corr), y = corr_price)) +
geom_bar(stat = "identity", fill = "lightblue") +
scale_x_discrete(limits= row.names(corr)) +
labs(x = "Predictors", y = "Price", title = "Correlations") +
theme(plot.title = element_text(hjust = 0, size = rel(1.5)),
axis.text.x = element_text(angle = 45, hjust = 1))
# Chunk 15
linFit <- lm(log(price) ~ beds + baths + log(sqft) + type + latitude*longitude, data=training)
summary(linFit)
# Chunk 16
pr.multiple = exp(predict(linFit, newdata=testing))
cor(testing$price, pr.multiple)^2
library(leaps)
exhaustive <- regsubsets(log(price) ~ beds + baths*type + log(sqft) + latitude*longitude + I(longitude^2) + I(latitude^2), data=training)
summary(exhaustive)
plot(summary(exhaustive)$bic, type = 'l')
library(olsrr)
model = log(price) ~ beds + baths*type + log(sqft) + latitude*longitude + I(longitude^2) + I(latitude^2)
linFit <- lm(model, data=training)
ols_step_all_possible(linFit) # All possible subset regressions: the number is exponential with p
ols_step_best_subset(linFit) # The best subset regression for each p: still exponential with p
ggplot(aes(training$beds, training$baths)) + geom_point()
ggplot(training, aes(beds, baths)) + geom_point()
ggplot(training, aes(beds, baths)) + geom_jitter()
