{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d4dcd6-ac29-429d-86d0-1203db57c81c",
   "metadata": {},
   "source": [
    "# DataFrame - Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e336fff6-9927-4965-88ad-e2947a915fa4",
   "metadata": {},
   "source": [
    "## Prepare the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de784ea9-07c9-4ac4-9a4c-54ae45b2e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import findspark\n",
    "import findspark\n",
    "\n",
    "# Configure the environment\n",
    "findspark.init()\n",
    "\n",
    "# Import the Spark components required for the session creation\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Configure and create the session\n",
    "conf = SparkConf()\n",
    "conf = conf.setAppName('mds-session')\n",
    "conf = conf.setMaster('local[*]')\n",
    "spark = SparkSession.builder.config(conf = conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3200fcbf-9693-4f5b-9079-d46dd71e42a0",
   "metadata": {},
   "source": [
    "## From RDD with explicit schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d196a9b-77b6-4a84-a7ea-1ef1b09a7c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the context\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Read the file\n",
    "kickstarter = sc.textFile('./data/live.tsv')\n",
    "\n",
    "# Function used to parse and transform to Row each line\n",
    "def parseKickstarter(line):\n",
    "    fields = line.split('\\t')\n",
    "    return (fields[3], int(fields[1]))\n",
    "\n",
    "# Parse the required fields from the file\n",
    "kickstarter = kickstarter.map(parseKickstarter)\n",
    "\n",
    "# Take a glimpse of the data\n",
    "kickstarter.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1a914-89ea-4f23-b8de-ddd0eca4ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the spark objects needed\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "\n",
    "# Define the schema explicitly\n",
    "fields = []\n",
    "fields.append(StructField('country', StringType(), True))\n",
    "fields.append(StructField('amount', LongType(), False))\n",
    "schema = StructType(fields)\n",
    "\n",
    "# Create the DataFrame with an RDD and schema\n",
    "kick_df = spark.createDataFrame(kickstarter, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189e511f-74a5-40c1-8ae5-c552e1e910b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type of the results\n",
    "type(kick_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a523900-6090-4217-b91f-de2241279d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a glimpse of the DataFrame\n",
    "kick_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a572693-e54f-4a4b-8897-aa18d295f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the schema of the DataFrame\n",
    "kick_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2bbed3-70d6-49e1-b55e-19781f26b1da",
   "metadata": {},
   "source": [
    "## From Row RDD and inferring the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477d836-dcd8-4932-8841-75009e6a677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import Row\n",
    "\n",
    "# Retrieve the context\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Read the file\n",
    "kickstarter = sc.textFile('./data/live.tsv')\n",
    "\n",
    "# Function used to parse and transform to Row each line\n",
    "def parseKickstarter(line):\n",
    "    fields = line.split('\\t')\n",
    "    return Row(country = fields[3], amount = fields[1])\n",
    "\n",
    "# Parse the required fields as Row\n",
    "row_kickstarter = kickstarter.map(parseKickstarter)\n",
    "\n",
    "# Take a glimpse of the data\n",
    "row_kickstarter.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00638c31-d39d-429d-95d0-e4e88c6e4bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame without specifying schema\n",
    "kick_df = spark.createDataFrame(row_kickstarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7304fd-85a1-4837-93a6-587b341133c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type of the results\n",
    "type(kick_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56aa013-36a0-4b02-856d-79aa0bba3768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a glimpse of the DataFrame\n",
    "kick_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038bffb-f7fb-4fa1-a1e6-de99d2966d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the schema of the DataFrame\n",
    "kick_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dd4694-7ca7-4444-b075-f78922b45cba",
   "metadata": {},
   "source": [
    "## From structured data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87961fb-0e01-4d1b-a3aa-f0cf2ebcb116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file specifying format\n",
    "kick_df = spark.read.csv('./data/live.tsv')\n",
    "kick_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0742e3-a030-4ea4-ad95-760e19361d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file spcifying CSV options\n",
    "kick_df = spark.read.options(sep='\\t', header=False).csv('./data/live.tsv')\n",
    "kick_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47fa7ad-ec94-4bcd-8fc3-63a0eb81dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file specifying CSV options and asking for schema inferring\n",
    "kick_df = spark.read.options(sep='\\t', header=False, inferSchema=True).csv('./data/live.tsv')\n",
    "kick_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d927073-a923-4daf-b5ba-b75754157e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame setting column names\n",
    "kick_df = kick_df.toDF(\n",
    "    'id',\n",
    "    'amt_pledged',\n",
    "    'by',\n",
    "    'country',\n",
    "    'currency',\n",
    "    'end_time',\n",
    "    'location',\n",
    "    'percentage_funded',\n",
    "    'state',\n",
    "    'title',\n",
    "    'type',\n",
    "    'url'\n",
    ")\n",
    "kick_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff892cf-d0f9-454c-b021-76dba4be908e",
   "metadata": {},
   "source": [
    "## Close the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea6dc2c-86c3-407a-9122-ec9f40c04444",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
