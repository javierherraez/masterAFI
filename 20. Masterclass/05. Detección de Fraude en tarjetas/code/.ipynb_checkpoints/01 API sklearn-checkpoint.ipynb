{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8ae53ef3e1c826c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelizacion con sklearn para detección de fraude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c4c917954323c519",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Explorando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set() # Sobreescribe los parámetros de matplotlib\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          IDTX     BIN   CIUDAD COD_COMERCIO  COD_MONEDA  COLA  DISPOSITIVO  \\\n",
      "352806  352807  360324  17001MA    012461042         170    -1            2   \n",
      "417824  417825  455986      INT    013139530         978    -1            2   \n",
      "469847  469848  589514   5001ME    012800165         170    -1            2   \n",
      "407746  407747  589514  68307GI    012333910         170    -1            2   \n",
      "469848  469849  455986  11001BO    013029111         170    -1            2   \n",
      "\n",
      "        ENTRYMODE ESTADO             FECHATRX  ... MES      NOMBRE_CIO  PAIS  \\\n",
      "352806         51     17  2015-01-04 11:04:40  ...   1    CRA 22 17-11    CO   \n",
      "417824         51    NaN  2015-01-04 18:14:31  ...   1    HOTEL AGUMAR    ES   \n",
      "469847         51     05  2015-01-05 10:56:17  ...   1  CRA 66A 34A-25    CO   \n",
      "407746         51     68  2015-01-04 17:12:21  ...   1             NaN    CO   \n",
      "469848         12    CUN  2015-01-05 10:56:18  ...   1             NaN    CO   \n",
      "\n",
      "       PSCONDITION RESPUESTA  TERMINAL  TIPO_MENSAJE TJ_TOKEN  VALOR_TRX  \\\n",
      "352806         0.0         1  000P1166           210  2157763   42457.00   \n",
      "417824         0.0         1  13953001           210  2625579  129447.01   \n",
      "469847         0.0         1  00035354           210  3059060   76500.00   \n",
      "407746         0.0        76  00032662           210  3068686    7000.00   \n",
      "469848         8.0         1  00026698           210  2485010   37000.00   \n",
      "\n",
      "        REPORTE_DE_FRAUDE  \n",
      "352806                 NO  \n",
      "417824                 NO  \n",
      "469847                 NO  \n",
      "407746                 NO  \n",
      "469848                 NO  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 500000 entries, 352806 to 128037\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   IDTX               500000 non-null  int64  \n",
      " 1   BIN                500000 non-null  int64  \n",
      " 2   CIUDAD             470937 non-null  object \n",
      " 3   COD_COMERCIO       481270 non-null  object \n",
      " 4   COD_MONEDA         500000 non-null  int64  \n",
      " 5   COLA               500000 non-null  int64  \n",
      " 6   DISPOSITIVO        500000 non-null  int64  \n",
      " 7   ENTRYMODE          500000 non-null  int64  \n",
      " 8   ESTADO             398482 non-null  object \n",
      " 9   FECHATRX           500000 non-null  object \n",
      " 10  FIID               499953 non-null  object \n",
      " 11  MCC                499998 non-null  float64\n",
      " 12  MES                500000 non-null  int64  \n",
      " 13  NOMBRE_CIO         308781 non-null  object \n",
      " 14  PAIS               472278 non-null  object \n",
      " 15  PSCONDITION        481272 non-null  float64\n",
      " 16  RESPUESTA          500000 non-null  int64  \n",
      " 17  TERMINAL           499518 non-null  object \n",
      " 18  TIPO_MENSAJE       500000 non-null  int64  \n",
      " 19  TJ_TOKEN           500000 non-null  int64  \n",
      " 20  VALOR_TRX          500000 non-null  float64\n",
      " 21  REPORTE_DE_FRAUDE  500000 non-null  object \n",
      "dtypes: float64(3), int64(10), object(9)\n",
      "memory usage: 87.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Leemos los datos \n",
    "fraude = pd.read_csv('../data/01_datos_4_training_cut.txt', sep='|', nrows =500000)\n",
    "fraude = fraude.sample(frac=1, random_state = 1) \n",
    "\n",
    "### Exploramos\n",
    "print(fraude.head())\n",
    "print(fraude.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f14d41305e959c7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejercicio\n",
    "\n",
    "Calcular:\n",
    "\n",
    "- La proporción de transacciones fraudulentas en la base de datos y almacenarla en la variable prevalencia\n",
    "- La proporción del dinero estafado y compararla con los datos del Informe del BCE y almacenarla en la variable proporcion_dinero\n",
    "\n",
    "> ¿Qué conclusión sacamos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6e35d140f2845c99",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prevalencia' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprevalencia\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(proporcion_dinero)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prevalencia' is not defined"
     ]
    }
   ],
   "source": [
    "print(prevalencia)\n",
    "print(proporcion_dinero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c8e19c993f6e9ac0",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "assert prevalencia == sum(fraude.REPORTE_DE_FRAUDE == 'SI')/len(fraude.REPORTE_DE_FRAUDE), 'No has calculado bien la prevalencia'\n",
    "assert proporcion_dinero == sum(fraude.VALOR_TRX[fraude.REPORTE_DE_FRAUDE == 'SI'])/sum(fraude.VALOR_TRX), 'El dinero defraudado no es el correcto'\n",
    "print('Bien! Buen trabajo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1d4992530515e89f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Masajeando los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c4a284be7341de37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por nuestro conocimiento experto, sabemos que todas las columnas son __categóricas__ salvo:\n",
    "\n",
    "- IDTX (es simplemente un índice que podríamos tirar ya que pandas tiene su propio índice)\n",
    "- FechaTrx (Hora y día de la transacción)\n",
    "- Valor_TRX (esta sí es numérica)\n",
    "\n",
    "Sin embargo, muchas de ellas están codificadas con números, creando una falsa apariencia. Hay que convertirlas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd96b710549f2e78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformando las columnas a sus tipos correctos\n",
    "\n",
    "Para ello, tendremos que:\n",
    "\n",
    "1. Eliminar la columna 'IDTX'\n",
    "2. Convertir la FECHATRX a `datetime` con `pd.to_datetime`\n",
    "3. Convertir todas las columnas del dataframe a tipo `category` con el método `.astype('category')` salvo la FECHATRX y la VALOR_TRX.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fraude.drop(['IDTX'], axis = 1, inplace=True)\n",
    "fraude.FECHATRX = pd.to_datetime(fraude.FECHATRX)\n",
    "\n",
    "columnas_sin_cambios = ['IDTX', 'FECHATRX','VALOR_TRX']\n",
    "\n",
    "for columna in fraude.columns:\n",
    "    if columna not in columnas_sin_cambios:\n",
    "        fraude[columna] = fraude[columna].astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraude.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-159e4a7eaa3357db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Veamos ahora cuántos valores diferentes tienen las columnas categóricas. __¿Qué observamos?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predictores_cat = list(fraude.select_dtypes(['category']).columns)\n",
    "for columna in predictores_cat:\n",
    "    print(columna, len(fraude[columna].cat.categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fb336c4ce0769ab0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Miremos a ver cómo andamos de Nas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "nulos = fraude.isnull()\n",
    "suma_nulos = nulos.sum()\n",
    "ordenados = suma_nulos.sort_values(ascending=False)\n",
    "\n",
    "print(ordenados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a71ea88667537fc2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Salta a la vista que el número de NAs de PSCONDITION y COD_COMERCIO son casi iguales... ¿Qué puede querer decir esto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fraude.COD_COMERCIO[fraude.PSCONDITION.isnull()]))\n",
    "sum(fraude.COD_COMERCIO[fraude.PSCONDITION.isnull()].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b97c75ce7f10b716",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problemas que tenemos con estos datos:\n",
    "\n",
    "- Las NAs: hay que imputar los valores para poder usar esas observaciones en los algoritmos de aprendizaje. ¿Cómo?\n",
    "- Las variables categóricas: los algoritmos de ML en general sklearn sólo aceptan variables numéricas. Hay que convertirlas. ¿Cómo?\n",
    "    - Hay columnas con 300K categorías diferentes. Es inviable usar un one-hot-encoding para ellas\n",
    "- La única variable numérica tiene una distribución muy sesgada que se adapta mal a nuestros algoritmos\n",
    "- Y esto como mínimo... Podríamos pensar otras transformaciones de las columnas, generar nuevas columnas derivadas, etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f112e34255d27825",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "> Como podemos ver, antes de entrenar un algoritmo (¿cuál???), es necesario realizar diversas acciones de preprocesado sobre los datos. Pero para poder realmente estimar con fiabilidad el error del modelo hemos de tener mucho cuidado para que __no  haya filtraciones entre el conjunto de train y el de test__.\n",
    "\n",
    "> Las operaciones de preprocesado son un terreno abonado para que se produzcan estas filtraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cc9fa706585795b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Eso por un lado, pero...\n",
    "\n",
    "# La gran pregunta\n",
    "\n",
    "> # ¿Cómo diseño el experimento?\n",
    "\n",
    "- ¿Qué tengo que buscar?\n",
    "- ¿Cómo sé si mi clasificador es bueno o no?\n",
    "- ¿Cómo optimizo el algoritmo?\n",
    "- ¿Cómo preproceso los datos?\n",
    "- ¿Cómo sé si va a funcionar cuando le pase otros datos?\n",
    "- ¿Va a poder ser implementado en el mundo real? \n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-91cf00547dddcde1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Un poco de calentamiento\n",
    "\n",
    "Recordemos que `sklearn` __solo puede operar con arrays de numpy__. También puede operar con dataframes siempre y cuando __sean numéricos__. Cualquier operación de sklearn __devuelve siempre arrays de numpy__.\n",
    "\n",
    "sklearn además __no sabe cómo manejar los NAs ni los infs__. Hay que tener cuidado para que en nuestras columnas no aparezcan este tipo de valores\n",
    "\n",
    "Por lo tanto, si queremos entrenar un modelo sencillo con los datos de fraude, sólo podemos usar de primeras la columna VALOR_TRX. Vamos a ello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Dividamos primero en train y test para ver los ejemplos. \n",
    "# Esto no se hará así cuando estemos con un modelo real, \n",
    "# pero viene bien para ver qué está ocurriendo\n",
    "# Vamos a entrenar una regresión logística con la única variable numérica que tenemos\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn import linear_model\n",
    "\n",
    "X = fraude[['VALOR_TRX']]\n",
    "y = fraude['REPORTE_DE_FRAUDE']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "\n",
    "mod_log_1 = linear_model.LogisticRegression()\n",
    "mod_log_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3a612303f27d80b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `estimators`\n",
    "\n",
    "> Acabamos de entrenar un __estimador de sklearn__ con el método ```.fit(X, y)```. Este es uno de los dos objetos fundamentales de su API (el otro son los `transformers`)\n",
    "\n",
    "> El otro método que podemos aplicarle es el ```.predict(X)``` para que nos de los valores estimados de la ```y```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_predict = mod_log_1.predict(X_test)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3403da1fc7291e56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Veamos qué tal funciona mi modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(mod_log_1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1171322c6487eed8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Qué buen resultado!!! ... ¿O no?? Veamos si en realidad esto está haciendo algo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(pd.crosstab(y_test, y_predict, \n",
    "                  rownames=['Reales'], colnames=['Predicciones'], margins=True))\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-473ce605d4ee63e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Uno de los métodos posibles para tener en cuenta el sesgo de las variables es usar algoritmos que puedan pesar las clases. Afortunadamente, la simple regresión logística puede hacerlo pasandole el argumento `class_weight = 'balanced'`.\n",
    "### Ejercicio\n",
    "\n",
    "Entrenar un modelo de regresión logística que equilibre las clases. Mostrar los resultados del modelo sobre el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c2ffd2f462742590",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "## Entrenar un modelo de regresión logística que equilibre las clases\n",
    "\n",
    "\n",
    "### END SOLUTION\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Predecir sobre el conjunto de test\n",
    "y_predict = mod_log_2.predict(X_test)\n",
    "\n",
    "## Mostrar los restultados e INTERPRETARLOS\n",
    "print(mod_log_2.score(X_test, y_test))\n",
    "\n",
    "print(pd.crosstab(y_test, y_predict, \n",
    "                  rownames=['Reales'], colnames=['Predicciones'], margins=True))\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f8b1c095f7f6aef9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.validation import check_is_fitted\n",
    "check_is_fitted(mod_log_2)\n",
    "assert mod_log_2.get_params()['class_weight'] == 'balanced', 'No es el modelo pedido'\n",
    "print('Bien! Buen trabajo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c04ec8a72b5c4e7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Como puede verse, ahora el algoritmo ha pasado a clasificar muchísimas transacciones como fraude!\n",
    "\n",
    "> __¿Por qué? ¿Cómo decide si una transacción es fraude o no?__ \n",
    "\n",
    "> __¿Tiene sentido usar accuracy como la métrica a optimizar?__\n",
    "\n",
    "Es por la asignación de probabilidad. Ahora, ¿nos interesa ese umbral..?\n",
    "Cambiémoslo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-70ccdc08c80b34b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adaptando la función de coste a nuestro problema\n",
    "\n",
    "`sklearn` no solo permite predecir la CLASE sino también la PROBABILIDAD.\n",
    "\n",
    "Usaremos esta funcionalidad para crear una función de coste _que sea adecuada a nuestro problema (y a su futura implementación)_\n",
    "\n",
    "> No olvidemos que para _validar, seleccionar el algoritmo y estimar su error_ __tenemos que hacerlo usando una función de coste específica__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_prob = mod_log_1.predict_proba(X_test)[:,1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a206ce627b8eb739",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vamos a definir nuestro scoring rule. Tiene una interpretación bastante intuitiva: es el número de alarmas que el operador puede levantar considerando los medios que tiene disponibles para investigarlas.\n",
    "Obviamente alarmaremos las transacciones que mi algoritmo crea que son las más sospechosas (las de probabilidad más alta). Construyamos un dataframe que contenga estas probabilidades y la etiqueta de fraude de la transacción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "resultados = pd.DataFrame({'Prob':y_pred_prob, 'Label':y_test.values})\n",
    "print(resultados.head())\n",
    "print(resultados.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c37725e357d7fe39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ordenémoslo descendentemente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "resultados.sort_values('Prob', axis=0, ascending=False, inplace=True)\n",
    "resultados.reset_index(inplace=True)\n",
    "print(resultados.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d60b205b3f3a4bb6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Y fijemos un número de alarmas (por ejemplo, el 1% del total de transacciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "alarmas = int(0.01*len(y_test))\n",
    "print('Casos Analizados:{}'.format(len(y_test)))\n",
    "print('Alarmas:{}'.format(alarmas))\n",
    "print('Cazados:{}'.format(sum(resultados[0:alarmas].Label=='SI')))\n",
    "print('Fraude total en el conjunto:{}'.format(sum(resultados.Label == 'SI')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c365ed255f6decfd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Este scoring lo vamos a usar repetidas veces, así que metámoslo en una función. \n",
    "Para usar un número con una referencia directa en el problema, como número de alarmas voy a poner el número de transacciones fraudulentas en el test. Para fijar otro valor ya dependería de las necesidades y capacidad operativa del cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def score(mod, X_test, y_test, alarm = None):\n",
    "    if not alarm:\n",
    "        alarm = sum(y_test == 'SI')/len(y_test)\n",
    "    y_pred_prob = mod.predict_proba(X_test)[:,1]\n",
    "    resultados = pd.DataFrame({'Prob':y_pred_prob, 'Label':y_test.values})\n",
    "    resultados.sort_values('Prob', axis=0, ascending=False, inplace=True)\n",
    "    resultados.reset_index(inplace=True)\n",
    "    alarmas = int(alarm*len(y_test))\n",
    "    print('Casos Analizados:{}'.format(len(y_test)))\n",
    "    print('Alarmas:{}'.format(alarmas))\n",
    "    print('Cazados:{}'.format(sum(resultados[0:alarmas].Label=='SI')))\n",
    "    print('Fraude total en el conjunto:{}'.format(sum(resultados.Label == 'SI')))\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "score(mod_log_1, X_test, y_test, alarm=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fac070f4425be91a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para tratar de mejorar esto tendremos que introducir más variable e implementar de un modo riguroso __las operaciones de preprocesado__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0c90490883896487",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Preprocesando los datos\n",
    "\n",
    "La distribución de los valores de las variables predictoras puede tener una importancia crucial en el resultado de nuestro algoritmo de aprendizaje. Investiguemos un poco\n",
    "¿Cómo es la distribución de nuestra variable X?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.mean())\n",
    "print(X_train.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-98cf9d0a0496a653",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`sklearn` ofrece diversas operaciones de preprocesado que nos ayudarán a mejorar el rendimiento de los clasificadores. En la API de `sklearn` se realizan mediante los `tranformers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e39d416db1654b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `transformers`\n",
    "\n",
    "- Son objetos de `sklearn` que tienen dos métodos asociados: `fit` y `transform`\n",
    "- `fit` ajusta los parámetros con los datos que le pasemos\n",
    "- `transform` transforma los datos que le pasemos usando los parámetros obtenidos con el método `fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "escalado = StandardScaler()\n",
    "escalado.fit(X_train)\n",
    "transformado = escalado.transform(X_train)\n",
    "\n",
    "print(transformado.mean())\n",
    "print(transformado.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(escalado.mean_)\n",
    "print(escalado.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6d922c9740f65ad3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El problema principal con la variable VALOR_TRX no era su escala sino el _sesgo_ que tiene.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(X_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-90a219173d633359",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Se puede arreglar con la transformación de BoxCox. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import scipy as sc\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "X_bc, param = boxcox((np.array(X)+1).flatten())\n",
    "\n",
    "sns.distplot(X_bc)\n",
    "plt.show()\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6326930e7d1eb5ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- El objeto boxcox devuelve dos elementos: los datos transformados y el parámetro de la transformación utilizado\n",
    "- Añadimos el +1 para evitar el cero, que no puede ser transformado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b7270328619a4927",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las últimas versiones de `sklearn` ya llevan implementada esta transformación en el transformer `PowerTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "PT = PowerTransformer(method='yeo-johnson')\n",
    "PT.fit(X_train)\n",
    "transformado = PT.transform(X_train)\n",
    "\n",
    "sns.distplot(transformado)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-de68cf1e4c3d742b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# La API de sklearn\n",
    "\n",
    "Podemos interpretar un modelo de sklearn como compuesto por _transformaciones de los datos_ en serie o en paralelo que desembocan en un _algoritmo de aprendizaje automático_. \n",
    "\n",
    "- Los _transformers_ se entrenan con el método `.fit` y transforman los datos con el método `.transform`\n",
    "- Los _estimators_ se entrenan con el método `.fit` y predicen con el método `.predict`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-35c172455fbdc686",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El problema que nos vamos a encontrar ahora es que las transformaciones que apliquemos en el conjunto de train tienen que ser realizadas separadamente de las del conjunto de test, y en este último, deben ser replicadas __con los mismos parámetros__ que los obtenidos en el train. \n",
    "\n",
    "> ¿Por qué? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1e55e79dfa0f3694",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Así mismo, cualquier operación de preprocesado que apliquemos tiene que ser validada para ver si hace mejorar el algoritmo. Esto supondría realizar una validación cruzada con las operaciones/sin ellas\n",
    "\n",
    "> ¿Cómo hacemos esto?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-df5628ab66ff6e77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "Y hemos visto que hay que hacer, sólo para una columna, ya dos operaciones de preprocesado (BoxCox y Scaler)... ¡Y aún nos quedan un montón de columnas!\n",
    "\n",
    "> ¿Cómo se puede hacer esto ordenadamente, controlando los errores y evitando que se filtre información entre el conjunto de train y el de test?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d05776c1b799b9a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# __USANDO TUBERÍAS (PIPES)__\n",
    " \n",
    "\n",
    "Es una manera de encadenar una serie de transformers con un algoritmo de modo que actúe como \"uno solo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-782041afef55a1d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/mario_bros.jpg\" width=\"900px;\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Definimos por dónde van a pasar los datos\n",
    "\n",
    "steps = [('Imputador', SimpleImputer(strategy='median')),\n",
    "         ('BoxCox',  PowerTransformer(method='yeo-johnson')),\n",
    "         ('Escalador', StandardScaler()),\n",
    "         ('predictor', linear_model.LogisticRegression(class_weight = 'balanced'))]\n",
    "\n",
    "# Montamos la cañería\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "# Y la entrenamos!!!\n",
    "pipe.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Lo maravilloso de la idea es que los transformers guardan _los parámetros aprendidos con los datos de train y los aplican tal cual a los de test_ , evitando así posibles filtraciones que nos llevarían al overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_predict = pipe.predict(X_test)\n",
    "\n",
    "print(pipe.score(X_test, y_test))\n",
    "\n",
    "print(pd.crosstab(y_test, y_predict, \n",
    "                  rownames=['Reales'], colnames=['Predicciones'], margins=True))\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "score(pipe, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "score(pipe, X_test, y_test, alarm=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2e6529071cc2e960",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__PREGUNTA: ¿Por qué obtenemos lo mismo que antes de aplicar el BoxCox con nuestra métrica pero sin embargo la matriz de confusión o el accuracy ha cambiado considerablemente?__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7561438b7b1ab1ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Probemos con otro algoritmo\n",
    "\n",
    "Veamos ahora por qué la API de sklearn es una auténtica maravilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Definimos por dónde van a pasar los datos\n",
    "\n",
    "steps = [('Imputador', SimpleImputer(strategy='median')),\n",
    "         ('BoxCox',  PowerTransformer(method='yeo-johnson')),\n",
    "         ('Escalador', StandardScaler()),\n",
    "         ('predictor', RandomForestClassifier(n_jobs=-1))]\n",
    "\n",
    "# Montamos la cañería\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "# Y la entrenamos!!!\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "score(pipe, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "score(pipe, X_test, y_test, alarm=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-940dd4a0ee9f3ab8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejercicio:\n",
    "Probar con vuestro algoritmo de clasificación favorito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b314431cc7218ef8",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "    ### BEGIN SOLUTION\n",
    "   \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "score(pipe, X_test, y_test, alarm=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-01578f0eadb42bd1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mirando dentro de la tubería\n",
    "Aunque se comporte como un bloque, podemos ejecutar la tubería paso por paso si eso fuera necesario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tmp = steps[0][1].fit_transform(X_train)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tmp = steps[1][1].fit_transform(tmp)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-49d33e7d115c1241",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pregunta: ¿Qué hará la siguiente instrucción? ¿Hemos usado la tubería al completo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    " steps[3][1].fit(tmp, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a2c9d6e02d576be8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Metamos las variables categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-187faec7cb78fd2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para simplificar un poco, vamos por el momento a olvidarnos de las columnas más problemáticas (las categóricas con muchos valores) y vamos a centrarnos en las más \"amables\" para ilustrar los conceptos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Definimos los predictores\n",
    "predictores_num = [fraude.columns[-2]]\n",
    "predictores_cat = list(fraude.columns[i] for i in [3,4,5,6,10,13,14,15,17])\n",
    "\n",
    "# Definimos los vectores de predictores y la respuesta\n",
    "y = fraude['REPORTE_DE_FRAUDE']\n",
    "X = fraude[predictores_num + predictores_cat]\n",
    "\n",
    "X.info()\n",
    "\n",
    "# Dividimos en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cd7af74c880223f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ¿Cómo codificamos las variables categóricas?\n",
    "\n",
    "> Respuesta: no existe un método _neutro_\n",
    "\n",
    "\n",
    "Los más habituales son:\n",
    "\n",
    "- OneHotEncoder - para los predictores: crea una columna por categoría y ala codifica con 0 y 1\n",
    "- Label Binarizer – para la respuesta: crea una columna por categoría y la codifica con 0 y 1\n",
    "- OrdinalEncoder – para predictores: sustituye categorías por enteros 1,2,3,.. Impone un orden implícito\n",
    "- LabelEncoder – para la respuesta: sustituye categorías por enteros 1,2,3,,.. Impone un orden implícito\n",
    "\n",
    "> La diferencia entre _predictor_ y _respuesta_ es la _dimensión_ de la array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
    "values = np.array(data)\n",
    "print(values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoder\n",
    "\n",
    "La representación estándar para variables categóricas es la de one-hot-encoding, fácil de ver con un ejemplo. \n",
    "\n",
    "Supongamos que tenemos una variable que toma tres valores `Rojo`, `Azul`  y `Verde`. Basta pues con crear tres nuevas variables numéricas (las llamadas dummy variabels) y hacer la siguiente transformación (recordad cuando teníamos variables categóricas en la clase de regresión lineal):\n",
    "\n",
    "* `Rojo` -> (1, 0, 0).\n",
    "* `Azul` -> (0, 1, 0).\n",
    "* `Verde` -> (0, 0, 1).\n",
    "\n",
    "Mediante pandas, basta usar `get_dummies`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En `sklearn` (que es lo que nos ocupa), se hace con `OneHotEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "oh_encoded = one_hot_encoder.fit_transform(values.reshape(-1,1))\n",
    "print(oh_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, __la salida del transformer on hot encoder es una matriz dispersa__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(oh_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_encoded.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ventajas del OH-encoding\n",
    "\n",
    "- __Ventajas__: No introduce un orden en la variable; las mantiene en un espacio ortogonal\n",
    "- __Inconvenientes__: La dimensionalidad puede dispararse puesto que añadimos un predictor por cada categoría"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Cómo evitamos que la dimensión de los datos se dispare?\n",
    "\n",
    "- Realizar un PCA de las columnas one-hot\n",
    "- Usar una codificación con un orden implícito (`OrdinalEncoder`)\n",
    "- Reducir el número de categorías a las más $n$ más populares y aglomerar el resto en una única categoría\n",
    "- Usar una codificación por frecuencia\n",
    "- Usar una codificación por variable objetivo (`Target Encoding`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OrdinalEncoder \n",
    "\n",
    "Es posible representar variables categóricas asignándo un número natural a cada valor diferente mediante `OrdinalEncoder`. Sin embargo, esto puede no ser lo ideal puesto que estamos introduciendo una estructura en los datos que antes no tenían.\n",
    "Eso sí: puede ser muy adecuado para variables categóricas que tengan un orden intrínseco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "print(values)\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['cold', 'warm', 'hot']])\n",
    "values_encoded = ordinal_encoder.fit_transform(values.reshape(-1,1))\n",
    "print(values_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Ventajas__: Ocupa poca memoria\n",
    "- __Inconvenientes__ (o ventajas!!): Ordena los valores de la variable, creando una estructura que antes no había"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1cac6f7cf27e86e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ¿Y cómo preprocesamos las columnas de manera específica?\n",
    "\n",
    "> Está claro que vamos a tener que aplicar diferentes operaciones de preprocesado dependiendo del tipo de columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6f390f8f1f0de12b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En nuestro caso:\n",
    "\n",
    "- Imputar NAs (la media a la variable numérica y la moda a las categóricas)\n",
    "- Transformar y estandarizar la columna numérica\n",
    "- Codificar algunas de las columnas categóricas a dummies (con OneHotEncoder)\n",
    "- Codificar otras columnas categóricas de otra manera\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-33be4aec94533a86",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Alt Text](https://i2.wp.com/adhikary.net/wp-content/uploads/2019/03/Screenshot-from-2019-03-23-09-22-51.png?resize=768%2C432&ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-24ec3bd507965f3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `ColumnTransformer`\n",
    "\n",
    "Para poder tratar de diferente manera en la cañería las columnas categóricas de las numéricas, usaremos la función de sklearn `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Definimos los predictores\n",
    "# predictores_num = [fraude.columns[-2]]\n",
    "# predictores_cat = list(fraude.columns[i] for i in [4,5,6,7,11,14,15,16,18])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('BoxCox',  PowerTransformer(method='yeo-johnson')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocesado = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, predictores_num),\n",
    "        ('cat', categorical_transformer, predictores_cat)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-71d9fb9eaba820c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ensamblemos este preprocesado al algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Definimos la tubería\n",
    "\n",
    "steps = [('feat_prepro', preprocesado), \n",
    "         ('predictor', RandomForestClassifier(n_jobs=-1))]\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Estimamos el error del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_predict = pipe.predict(X_test)\n",
    "\n",
    "print(pipe.score(X_test, y_test))\n",
    "\n",
    "print(pd.crosstab(y_test, y_predict, \n",
    "                  rownames=['Reales'], colnames=['Predicciones'], margins=True))\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "score(pipe, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "score(pipe, X_test, y_test, alarm=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8cb3c2f7cd78ef09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ejercicio \n",
    "\n",
    "Ampliar la tubería anterior para que:\n",
    "- Primero extraiga las 20 primeras componentes de una descomposición en valores principales truncado ([+INFO](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html))\n",
    "- Y luego amplíe las features añadiendo términos de interacción hasta segundo\n",
    "orden ([+INFO](https://scikit-learn.org/stable/modules/preprocessing.html#generating-polynomial-features)\n",
    ")  \n",
    "- Usar un `linear_model.LogisticRegression` como clasificador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5cead4e81b2459b4",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "\n",
    "### END SOLUTION\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_2 = Pipeline(steps)\n",
    "\n",
    "pipe_2.fit(X_train, y_train)\n",
    "\n",
    "y_predict = pipe_2.predict(X_test)\n",
    "\n",
    "print(pipe_2.score(X_test, y_test))\n",
    "\n",
    "print(pd.crosstab(y_test, y_predict, \n",
    "                  rownames=['Reales'], colnames=['Predicciones'], margins=True))\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "score(pipe_2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "score(pipe_2, X_test, y_test, alarm = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ddd06051988cab59",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> Usando las operaciones de preprocesado adecuadas, podemos hacer que un algoritmo sencillo mejore claramente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-00028588554fd6b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ¿Cómo seguir mejorando a partir de aquí?\n",
    "\n",
    "- Utilizar las features que aún no hemos usado. Para ellos, habrá que buscar algún método para codificarlas.\n",
    "- Ingeniería de Features: que tendremos que integrar también en la pipeline y en el proceso de validación. \n",
    "- Ajustar los hiperparáetros del algoritmo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4b13734b000c0bf5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Necesitamos aprender a ensamblar elementos personalizados en la tubería"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
