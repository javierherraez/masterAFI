{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ecef10",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Codificación avanzada de las variables categóricas. `transformers` personalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d138f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set() # Sobreescribe los parámetros de matplotlib\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d771b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Leemos los datos \n",
    "fraude = pd.read_csv('../data/01_datos_4_training_cut.txt', sep='|', nrows= 500000)\n",
    "RS = 20200908\n",
    "fraude = fraude.sample(frac=1, random_state = 1) \n",
    "\n",
    "# Los limpiamos\n",
    "\n",
    "fraude.drop(['IDTX'], axis = 1, inplace=True)\n",
    "fraude.FECHATRX = pd.to_datetime(fraude.FECHATRX)\n",
    "\n",
    "columnas_sin_cambios = ['IDTX', 'FECHATRX','VALOR_TRX']\n",
    "\n",
    "for columna in fraude.columns:\n",
    "    if columna not in columnas_sin_cambios:\n",
    "        fraude[columna] = fraude[columna].astype('category')\n",
    "\n",
    "### Exploramos\n",
    "print(fraude.head())\n",
    "print(fraude.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4673ae",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e39d416db1654b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `transformers`\n",
    "\n",
    "Recordemos:\n",
    "- Son objetos de `sklearn` que tienen dos métodos asociados: `fit` y `transform`\n",
    "- `fit` ajusta los parámetros con los datos que le pasemos\n",
    "- `transform` transforma los datos que le pasemos usando los parámetros obtenidos con el método `fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eee0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "escalado = StandardScaler()\n",
    "escalado.fit(fraude[['VALOR_TRX']])\n",
    "transformado = escalado.transform(fraude[['VALOR_TRX']])\n",
    "\n",
    "print(transformado.mean())\n",
    "print(transformado.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0781265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "escalado = StandardScaler()\n",
    "escalado.fit(fraude[['VALOR_TRX']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd7f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(escalado.mean_)\n",
    "print(escalado.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7af490",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-755c662d1dcf8506",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Creando un transformer personalizado\n",
    "\n",
    "\n",
    "- Los transformers de sklearn son clases basadas en la clase `TransformerMixin`\n",
    "- Tienen que tener un método __init__, un método `fit` y un método `transform`\n",
    "- Heredan de `TransformerMixin` el metodo `fit_transform`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32085933",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e411d33935429d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> Si queremos usar un transformador personalizado, __tenemos que aprender a crear un objeto de la clase TransformerMixin__ para que pueda ser ensamblado de manera natural con el resto de operaciones de mi algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd25ef05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "class MiEscalador(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        ### Inicializamos los parámetros del transformer\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"X es un dataframe de pandas o una numpy array\"\"\"\n",
    "        ## Ajustamos los parámetros del transformer con los datos de entrenamiento\n",
    "        return self ## Esto siempre tiene que ser así\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        ## Transformamos de acuerdo a los parámetros aprendidos\n",
    "        return ## Aquí devolverá la numpy array transformada\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdef47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "class MiEscalador(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        ### Inicializamos los parámetros del transformer\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"X es un dataframe de pandas o una numpy array\"\"\"\n",
    "        ## Ajustamos los parámetros del transformer con los datos de entrenamiento\n",
    "        self.mean = np.mean(X)\n",
    "        self.std = np.std(X)\n",
    "        return self ## Esto siempre tiene que ser así\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        ## Transformamos de acuerdo a los parámetros aprendidos\n",
    "        return (X-self.mean)/self.std ## Aquí devolverá la numpy array transformada\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f7cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador = MiEscalador()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d77bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.array([1,2,3,4,3,2,4,5])\n",
    "np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2720ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador.fit_transform(fraude[['VALOR_TRX']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e6c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador.mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e1955f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Frecuency coding\n",
    "\n",
    "Esta manera de codificar las variables categóricas _transforma cada categoría en la razón del número de observaciones en esa categoría al número total de observaciones_.\n",
    "\n",
    "Esto se puede hacer directamente en el dataframe... Pero eso dará problemas antes o después.\n",
    "\n",
    "La forma adecuada de hacerlo es __creando un transformer personalizado de `sklearn`__ que además podremos ensamblar en nuestras cañerías.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a13ed76",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class FreqEncoder(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        ### Inicializamos los parámetros del transformer\n",
    "        self.dicts_frecuencias = {}\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"X es un dataframe de pandas o una numpy array\"\"\"\n",
    "        ## Ajustamos los parámetros del transformer con los datos de entrenamiento\n",
    "        \n",
    "        ## Comprobamos que es una variable del tipo y dimensiones correctas\n",
    "        X = np.array(X, dtype=str)        \n",
    "                \n",
    "        for columna in range(X.shape[1]):\n",
    "            unique_elements, counts_elements = np.unique(X[:,columna], return_counts=True)\n",
    "            freqs_elements = counts_elements/counts_elements.sum()\n",
    "            dict_frecuencias = dict(zip(unique_elements, freqs_elements))\n",
    "            dict_frecuencias['UNKNOWN_CATEGORY'] = 0\n",
    "            self.dicts_frecuencias[columna] = dict_frecuencias\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        ## Transformamos de acuerdo a los parámetros aprendidos\n",
    "        #assert type(X) == pd.core.frame.DataFrame, 'Necesito un df de pandas'\n",
    "        #assert X.columns.to_list() == list(self.dicts_frecuencias.keys()), \"No coinciden las columnas\"\n",
    "        \n",
    "        X = np.array(X,dtype=object)\n",
    "\n",
    "        columnas = []\n",
    "        for indice in range(X.shape[1]):\n",
    "            columna = X[:,indice].astype(str)\n",
    "            transformada = np.where(np.in1d(columna, list(self.dicts_frecuencias[indice].keys())),\n",
    "                                    columna,\n",
    "                                    'UNKNOWN_CATEGORY')\n",
    "            transformada = np.array([self.dicts_frecuencias[indice].get(obs) for obs in transformada.flatten()])\n",
    "            #print(self.dicts_frecuencias[columna])\n",
    "            columnas.append(transformada)\n",
    "                                           \n",
    "                                           \n",
    "        return  np.array(columnas).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d41ee0c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "FE = FreqEncoder()\n",
    "df = fraude[['ENTRYMODE', 'MCC']]\n",
    "FE.fit(df[0:200])\n",
    "#FE.dicts_frecuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd29d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(df[800:810])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76531658",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "FE.transform(df[800:810])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c801c9b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Top-n encoding\n",
    "\n",
    "Consiste en reducir el número de categorias, aglomerando las menos comunes en una nueva categoría. Hay varias formas de hacer\n",
    "\n",
    "- Podemos poner un tope de categorías\n",
    "- O aglomerar las que no lleven a un umbral\n",
    "- O aglomerar por percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b44d86",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fraude.ENTRYMODE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9efd7ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fraude.ENTRYMODE.value_counts(normalize=True,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a5712d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "top_n = 3\n",
    "categorias = fraude.ENTRYMODE.value_counts(normalize=True)\n",
    "limit_freq = categorias[top_n-1]\n",
    "mask = categorias<limit_freq\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(fraude.ENTRYMODE.isin(categorias[mask].index),'Other', fraude.ENTRYMODE)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd791133",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraude.ENTRYMODE[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8013641",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f210af0e839b9364",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejercicio\n",
    "\n",
    "- Modificar el `transformer` anterior para crear un `TopNEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b898a1be",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "top_n = 3\n",
    "categorias = fraude.ENTRYMODE.value_counts(normalize=True)\n",
    "mask = categorias[:3]\n",
    "print(mask)\n",
    "excluded = categorias[3:]\n",
    "list(excluded.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9efaea",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-42a278e42e746301",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class TopNEncoder(TransformerMixin):\n",
    "    \n",
    "    def __init__(self, top_n=3):\n",
    "        ### Inicializamos los parámetros del transformer\n",
    "        self.categories_to_keep = {}\n",
    "        self.top_n = top_n\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"X es un dataframe de pandas o una numpy array\"\"\"\n",
    "        ## Ajustamos los parámetros del transformer con los datos de entrenamiento\n",
    "        \n",
    "        ## Comprobamos que es una variable del tipo y dimensiones correctas\n",
    "        X = np.array(X)  \n",
    "        \n",
    "\n",
    "        for columna in range(X.shape[1]):\n",
    "            unique_elements, counts_elements = np.unique(X[:,columna], return_counts=True)\n",
    "            cuentas = np.array(list(zip(unique_elements, counts_elements)))\n",
    "            ordenados = cuentas[cuentas[:,-1].argsort()][::-1]\n",
    "            to_keep = ordenados[0:self.top_n,0]\n",
    "            self.categories_to_keep[columna] = list(to_keep)\n",
    "        return self\n",
    "        \n",
    "\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        ## Transformamos de acuerdo a los parámetros aprendidos\n",
    " \n",
    "        X = np.array(X)\n",
    "        columnas = []\n",
    "        for columna in range(X.shape[1]):\n",
    "            transformada = np.where(np.in1d(X[:,columna], list(self.categories_to_keep[columna])),\n",
    "                                    X[:,columna],\n",
    "                                    'OTHER')\n",
    "            columnas.append(transformada)\n",
    "                                           \n",
    "        return  np.array(columnas).T\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1632e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements, counts_elements = np.unique(fraude.ENTRYMODE, return_counts=True)\n",
    "cuentas = np.array(list(zip(unique_elements, counts_elements)))\n",
    "print(cuentas)\n",
    "ordenados = cuentas[cuentas[:,-1].argsort()][::-1]\n",
    "print(ordenados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33eeaf6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "FE = TopNEncoder(5)\n",
    "df = fraude[['ENTRYMODE', 'MCC']]\n",
    "FE.fit(df[0:200])\n",
    "FE.categories_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac7640e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "temp = FE.transform(df[0:20])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e9aac8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(df[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2d758f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Target encoding\n",
    "\n",
    "Probablemente la forma más potente de codificar una variable categórica puesto que toma como valores _la media  de la variable objetivo (o cualquier otra función) condicionada a esa categoría_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa57ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fraude.REPORTE_DE_FRAUDE == 'SI').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cdf395",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class TargetEncoder(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        ### Inicializamos los parámetros del transformer\n",
    "        self.dicts_frecuencias = {}\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"X es un dataframe de pandas o una numpy array\"\"\"\n",
    "        ## Ajustamos los parámetros del transformer con los datos de entrenamiento\n",
    "        \n",
    "        ## Comprobamos que es una variable del tipo y dimensiones correctas\n",
    "        \n",
    "        X = np.array(X)\n",
    "        y = (y == 'SI').astype(int)\n",
    "        y = np.array(y).reshape(-1,1)\n",
    "        \n",
    "        for indice in range(X.shape[1]):\n",
    "            df = pd.DataFrame(data=X[:,indice], columns = ['X'])\n",
    "            df['X'] = df['X'].astype(str)\n",
    "            df[['y']] = y\n",
    "            df = df.groupby(['X']).mean()\n",
    "            dict_frecuencias = dict(df['y'])\n",
    "            dict_frecuencias['UNKNOWN_CATEGORY'] = np.array(y).mean()\n",
    "            self.dicts_frecuencias[indice] = dict_frecuencias\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        ## Transformamos de acuerdo a los parámetros aprendidos\n",
    "        \n",
    "        X = np.array(X)\n",
    "        columnas = []\n",
    "        for indice in range(X.shape[1]):\n",
    "            columna = X[:,indice].astype(str)\n",
    "            transformada = np.where(np.in1d(columna, list(self.dicts_frecuencias[indice].keys())),\n",
    "                                    columna,\n",
    "                                    'UNKNOWN_CATEGORY')\n",
    "            #print(transformada)\n",
    "            transformada = np.array([self.dicts_frecuencias[indice].get(obs) for obs in transformada.flatten()])\n",
    "            #print(self.dicts_frecuencias[columna])\n",
    "            columnas.append(transformada)\n",
    "                                           \n",
    "        return  np.array(columnas).T        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b3387",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1,2,3]).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d07aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TE = TargetEncoder()\n",
    "df = fraude[['ENTRYMODE', 'MCC']]\n",
    "TE.fit(df, fraude.REPORTE_DE_FRAUDE)\n",
    "TE.dicts_frecuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TE.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e7a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49999e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Suavizando y generalizando el TargetEncoding \n",
    "\n",
    "Es muy sencillo modificar nuestro transformer para que no obtenga la media de la variable objetivo sino cualquier función que le queramos pasar (mediana, máximo, mínimo, etc...)\n",
    "Además, podemos añadir un parámetro de suavizamiento para controla el OF.\n",
    "Con este transformer tenemos un método muy potente para transformar las columnas categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44193046",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class TargetEncoder(TransformerMixin):\n",
    "    \n",
    "    def __init__(self, agg_func = np.mean, mix_param = 0.98):\n",
    "        ### Inicializamos los parámetros del transformer\n",
    "        self.dicts_frecuencias = {}\n",
    "        self.agg_func = agg_func\n",
    "        self.mix_param = mix_param\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"X es un dataframe de pandas o una numpy array\"\"\"\n",
    "        ## Ajustamos los parámetros del transformer con los datos de entrenamiento\n",
    "        \n",
    "        ## Comprobamos que es una variable del tipo y dimensiones correctas\n",
    "        \n",
    "        X = np.array(X)\n",
    "        y = (y == 'SI').astype(int)\n",
    "        y = np.array(y).reshape(-1,1)\n",
    "    \n",
    "        for indice in range(X.shape[1]):\n",
    "            df = pd.DataFrame(data=X[:,indice], columns = ['X'])\n",
    "            df['X'] = df['X'].astype(str)\n",
    "            df[['y']] = y\n",
    "            df = df.groupby(['X']).agg(self.agg_func)\n",
    "            df[['y']] = self.mix_param*df[['y']] + (1-self.mix_param)*np.array(y).mean()\n",
    "            #print(np.array(y).mean())\n",
    "            #print(df)\n",
    "            \n",
    "            dict_frecuencias = dict(df['y'])\n",
    "            dict_frecuencias['UNKNOWN_CATEGORY'] = np.array(y).mean()\n",
    "            self.dicts_frecuencias[indice] = dict_frecuencias\n",
    "        return self\n",
    "\n",
    "    \n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        ## Transformamos de acuerdo a los parámetros aprendidos\n",
    "        \n",
    "        X = np.array(X)\n",
    "        columnas = []\n",
    "        for indice in range(X.shape[1]):\n",
    "            columna = X[:,indice].astype(str)\n",
    "            transformada = np.where(np.in1d(columna, list(self.dicts_frecuencias[indice].keys())),\n",
    "                                    columna,\n",
    "                                    'UNKNOWN_CATEGORY')\n",
    "            transformada = np.array([self.dicts_frecuencias[indice].get(obs) for obs in transformada.flatten()])\n",
    "            columnas.append(transformada)\n",
    "                                           \n",
    "        return  np.array(columnas).T        \n",
    "\n",
    "                                           \n",
    "        return  np.array(columnas).T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e4430c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "TE = TargetEncoder(agg_func = np.mean, mix_param = 0.95)\n",
    "df = fraude[['ENTRYMODE', 'MCC']]\n",
    "TE.fit(df, fraude.REPORTE_DE_FRAUDE)\n",
    "TE.dicts_frecuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8313892",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "TE.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ffc001",
   "metadata": {},
   "source": [
    "## Incorporando los codificadores al algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ca9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fraude.REPORTE_DE_FRAUDE = (fraude.REPORTE_DE_FRAUDE == 'SI').astype(int)\n",
    "\n",
    "# Definimos los predictores\n",
    "predictores_num = [fraude.columns[-2]]\n",
    "predictores_dummy = list(fraude.columns[i] for i in [3,4,5,6,13,14,15,17])\n",
    "predictores_target = list(fraude.columns[i] for i in [0,1,2,7,9,10,12,16])\n",
    "\n",
    "\n",
    "# Definimos los vectores de predictores y la respuesta\n",
    "y = fraude['REPORTE_DE_FRAUDE']\n",
    "X = fraude[predictores_num + predictores_dummy + predictores_target]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('BoxCox',  PowerTransformer(method='yeo-johnson')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "target_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent', fill_value='missing')),\n",
    "    ('target_coding', TargetEncoder(mix_param = 0.95))])\n",
    "\n",
    "preprocesado = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, predictores_num),\n",
    "        ('cat', categorical_transformer, predictores_dummy),\n",
    "        ('imp', target_transformer, predictores_target)])\n",
    "\n",
    "# Definimos la tubería\n",
    "\n",
    "steps = [('feat_prepro', preprocesado), \n",
    "         ('predictor', RandomForestClassifier(n_jobs=-1))]\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "\n",
    "pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8982e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(mod, X_test, y_test, positive_class = 'SI', alarm = None):\n",
    "    if not alarm:\n",
    "        alarm = sum(y_test == positive_class)/len(y_test)\n",
    "    y_pred_prob = mod.predict_proba(X_test)[:,1]\n",
    "    resultados = pd.DataFrame({'Prob':y_pred_prob, 'Label':y_test.values})\n",
    "    resultados.sort_values('Prob', axis=0, ascending=False, inplace=True)\n",
    "    resultados.reset_index(inplace=True)\n",
    "    alarmas = int(alarm*len(y_test))\n",
    "    print('Casos Analizados:{}'.format(len(y_test)))\n",
    "    print('Alarmas:{}'.format(alarmas))\n",
    "    print('Cazados:{}'.format(sum(resultados[0:alarmas].Label==positive_class)))\n",
    "    print('Fraude total en el conjunto:{}'.format(sum(resultados.Label == positive_class)))\n",
    "    print('Recall:{}'.format(sum(resultados[0:alarmas].Label==positive_class)/sum(resultados.Label == positive_class)))\n",
    "    return\n",
    "\n",
    "\n",
    "score(pipe, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05343d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
