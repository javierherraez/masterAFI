---
title: "clusteringCrime"
output: html_document
---

```{r setup, include=FALSE, echo=FALSE}
require("knitr")

opts_knit$set(root.dir = "C:/Users/jherraez/Documents/masterAFI/09. Aprendizaje no supervisado/01. Clustering jerarquico y no jerarquico/")

setwd("C:/Users/jherraez/Documents/masterAFI/09. Aprendizaje no supervisado/01. Clustering jerarquico y no jerarquico/")

####################
# Lectura de datos #
####################

crime <- read.csv("Data/crime.csv", header = TRUE, sep="")
str(crime)

```

# Procesamiento de datos

## Imputación de missings

```{r}

summary(crime)
# No hay datos missing

prcomp(crime[,2:8])
prcomp(crime[,2:8],center=TRUE,scale=TRUE)
library(FactoMineR)
# help(PCA)
x<-PCA(crime[,2:8],scale.unit=TRUE)
x$eig
# Parece ser que es bastante mejor t-SNE que PCA por lo menos para visualizar:
# https://medium.com/analytics-vidhya/pca-vs-t-sne-17bcd882bf3d

```

## Estadarización de variables

```{r}

crime.scale <- cbind(crime$State,as.data.frame(scale(crime[,c(2:8)])))
summary(crime.scale)

# En este caso, de acuerdo al rango de variación de las variables
# continuas, si hubiera una variable binaria, se podría estandarizar
# como -1 y 1

```

## Tratamiento de outliers

```{r}

logaritmoValoresPositivos <- function(x){x <- log(x-min(x)+1)}
crime.scale.log <- as.data.frame(apply(crime.scale[,2:8], 2, logaritmoValoresPositivos))
summary(crime.scale.log)

par(mfrow=c(1,2))
hist(crime.scale$Larceny)
hist(crime.scale.log$Larceny)
# Para poner etiquetas en dendrogramas (no valdría con un cbind del State)
rownames(crime.scale.log)<-crime$State #set new row names
```

## Eliminación de redundancias

```{r}

matrizCorrelacion<-cor(crime.scale.log, method = c("pearson"))
#install.packages("corrplot")
library(corrplot)
corrplot(matrizCorrelacion, method="number", type="upper")

# RAPE Y ASSAULT son las que tienen mayor correlación
# Si se establece como umbral el valor 0.8, se podría dejar

```

# ALGORITMOS PARTICIONALES

## K-MEANS

```{r}

# install.packages("cluster")
library(cluster)

# install.packages("factoextra")
library(factoextra)

# Las funciones del paquete factoextra emplean el nombre de las filas del
# dataframe que contiene los datos como identificador de las observaciones.
# Esto permite añadir labels a los gráficos.

# fviz_nbclust automatiza la generación de un gráfico de codo a partir de k-means

fviz_nbclust(x = crime.scale.log, FUNcluster = kmeans, method = "wss", k.max = 15, 
             diss = get_dist(crime.scale.log, method = "euclidean"), nstart = 3)

# ¿k = 4?

clusterKmeans <- kmeans(x = crime.scale.log, centers = 4, nstart = 3)
clusterKmeans$centers

# fviz_cluster usa componentes principales (si p>2) para hacer la representación

fviz_cluster(object = clusterKmeans, data = crime.scale.log, show.clust.cent = TRUE,
             ellipse.type = "euclid", star.plot = TRUE, repel = TRUE) +
  labs(title = "Resultados clustering K-means") +
  theme_bw() +
  theme(legend.position = "none")

```

## PAM

```{r}

# fviz_nbclust automatiza la generación de un gráfico de codo a partir de PAM

fviz_nbclust(x = crime.scale.log, FUNcluster = pam, method = "wss", k.max = 15,
             diss = dist(crime.scale.log, method = "manhattan"))

clusterPAM <- pam(x = crime.scale.log, k = 4, metric = "manhattan")

# El objeto devuelto por pam() contiene entre además de la asignación,
# las observaciones que finalmente se han seleccionado como medoids ($medoids)
clusterPAM$medoids

# fviz_cluster usa componentes principales (si p>2) para hacer la representación

fviz_cluster(object = clusterPAM, data = crime.scale.log, show.clust.cent = TRUE,
             ellipse.type = "euclid", star.plot = TRUE, repel = TRUE) +
  labs(title = "Resultados clustering K-means") +
  theme_bw() +
  theme(legend.position = "none")

```

# FUZZ C-MEANS
```{r}

#install.packages("ppclust")
library(ppclust)

clusterFCM <- fcm(crime.scale.log, centers=4, nstart=3, m=2)

asignacionFCM<-cbind(crime.scale.log,clusterFCM$cluster)
colnames(asignacionFCM)[8] <- "cluster"

# install.packages("sqldf")
library(sqldf)

centroidesFCM <- sqldf("Select cluster, 
                        count(*) as tamanyoCluster,
                        avg(Murder) as Murder,
                        avg(Rape) as Rape,
                        avg(Robbery) as Robbery,
                        avg(Assault) as Assault,
                        avg(Burglary) as Burglary,
                        avg(Larceny) as Larceny,
                        avg(Auto_Theft) as Auto_Theft
                        from asignacionFCM
                        group by cluster")

centroidesFCM

```
# ALGORITMOS JERÁRQUICOS

```{r}

# install.packages("vegan")
library(vegan)

#install.packages("cluster")
library(cluster)

matrizDistancias <- vegdist(crime.scale.log, method = "euclidean")
clusterJerarquico <- hclust(matrizDistancias, method="ward.D2") 
graphics.off()

###################################
# Elección del número de clusters #
###################################

###################
# Con dendrograma #
###################

clusterJerarquico
plot(as.dendrogram(clusterJerarquico),  main = "Dendrograma")

rect.hclust(clusterJerarquico, k=2, border="red") 
rect.hclust(clusterJerarquico, k=3, border="blue") 
rect.hclust(clusterJerarquico, k=4, border="green") 
rect.hclust(clusterJerarquico, k=5, border="yellow") 
rect.hclust(clusterJerarquico, k=6, border="purple") 
rect.hclust(clusterJerarquico, k=7, border="gray") 
rect.hclust(clusterJerarquico, k=8, border="black") 
```
```{r}

# k = 4

# Para colorear las ramas

# install.packages("dendextend")
library(dendextend)

dend <- as.dendrogram(clusterJerarquico)
dend <- color_branches(dend, k=4) 
plot(dend)

###########################
# Con Calinski y Harabasz #
###########################

calinsky <- cascadeKM(crime.scale.log, inf.gr = 2, sup.gr = 10, criterion = "calinski")
calinsky$results

# k = 2

###########################
# Con coeficiente silueta #
###########################

asw <- numeric(nrow(crime.scale.log))
for(k in 2:(nrow(crime.scale) - 1)){
  sil <- silhouette(cutree(clusterJerarquico, k = k), matrizDistancias)
  asw[k] <- summary(sil)$avg.width}
k.best <- which.max(asw)

plot(1: nrow(crime.scale.log), asw, type="h", 
     main = "Silhouette-optimal number of clusters", 
     xlab = "k (number of groups)", ylab = "Average silhouette width")
axis(1, k.best, paste("optimum", k.best, sep = "\n"), col = "red", font = 2,
     col.axis = "red")
points(k.best, max(asw), pch = 16, col = "red", cex = 1.5)
```
```{r}

# k = 2

k <- 2
cutg <- cutree(clusterJerarquico, k = k)
sil <- silhouette(cutg, matrizDistancias)
rownames(sil) <- crime$State

plot(sil, main = "Silhouette plot", 
     cex.names = 0.8, col = 2:(k + 1), nmax = 100)
```
```{r}

# k = 4

k <- 4
cutg <- cutree(clusterJerarquico, k = k)
sil <- silhouette(cutg, matrizDistancias)
rownames(sil) <- crime$State

plot(sil, main = "Silhouette plot", 
     cex.names = 0.8, col = 2:(k + 1), nmax = 100)

```

# BIETÁPICO

```{r}

# Supongamos que se decide hacer 4 clusters
# así cogemos los clusters para k = 4


asignacionJerarquica<-cbind(crime.scale.log,
                            cutree(clusterJerarquico, k = 4))

colnames(asignacionJerarquica)[8] <- "cluster"

# Cálculo de los centroides asociados a los grupos jerárquicos

centroidesJerarquico<-  sqldf("Select cluster, 
                        count(*) as tamanyoCluster,
                        avg(Murder) as Murder,
                        avg(Rape) as Rape,
                        avg(Robbery) as Robbery,
                        avg(Assault) as Assault,
                        avg(Burglary) as Burglary,
                        avg(Larceny) as Larceny,
                        avg(Auto_Theft) as Auto_Theft
                        from asignacionJerarquica
                        group by cluster")

# Distribución porcentual de los grupos en la muestra (jerárquico)

centroidesJerarquico[2]
centroidesJerarquico[2]/sum(centroidesJerarquico[2])

# Se ejecuta el kmeans con los centroides obtenidos con el jerárquico

##################
# Método k-means #
##################

kmeans <- kmeans(crime.scale.log,centers=centroidesJerarquico[,3:9])
kmeans$centers

# Distribución porcentual de los grupos en el total de la cartera (optimización)

kmeans$size/sum(kmeans$size)

centroidesJerarquico2=rbind(centroidesJerarquico,c(5,0,0,0,0,0,0,0,0))

kmeans <- kmeans(crime.scale.log,centers=centroidesJerarquico2[,3:9])
kmeans$centers

```
# ALGORITMOS BASADOS EN DENSIDADES

## DBSCAN

```{r}

# install.packages("dbscan")
library("dbscan")

# Aunque algunos autores recomiendan tomar k>=p+1 donde p es el número 
# de variables (y en particular k=2*p, la experiencia de muestra que un valor de k entre 3 y 5 suele funcionar bien

# Esta función selecciona para cada punto, los 3 vecinos más cercanos

nn <- kNN(crime.scale.log, k=3)
head(nn$id)

# Si yo pongo k=min_points, ¿cuánto se distancian en media los vecinos?
# Calculo para cada uno de los 50 puntos, la distancia media a sus min_points vecinos y las represento en el eje X
# Primero el punto con menor distancia media, después el segundo punto, etc.

for (min_points in 3:5)
{
  kNNdistplot(crime.scale.log, k = min_points  )
}

# Para k = 3, parece que podría haber un codo alrededor de 0.6
kNNdistplot(crime.scale.log, k = 3)
abline(h=0.60, col = "red", lty=2)
clusterDBSCAN <- dbscan(crime.scale.log, eps = 0.60, minPts = 3)
clusterDBSCAN
clusterDBSCAN$cluster

# Para k = 4 y 5, parece que podría haber un codo alrededor de 0.8 o 0.75
kNNdistplot(crime.scale.log, k = 4)
abline(h=0.55, col = "red", lty=2)
clusterDBSCAN <- dbscan(crime.scale.log, eps = 0.8, minPts = 4)
clusterDBSCAN
clusterDBSCAN$cluster

kNNdistplot(crime.scale.log, k = 5)
abline(h=0.75, col = "red", lty=2)
clusterDBSCAN <- dbscan(crime.scale.log, eps = 0.75, minPts = 5)
clusterDBSCAN
clusterDBSCAN$cluster

# Nos convence 3

clusterDBSCAN <- dbscan(crime.scale.log, eps = 0.60, minPts = 3)
clusterDBSCAN
clusterDBSCAN$cluster
hullplot(crime.scale.log,clusterDBSCAN$cluster)

# Otra posibilidad es establecer una rejilla para ambas cantidades,
# hacer todos los DBSCAN y medir alguna métrica como por ejemplo el WWS

#k <- c(1:10)
#eps <- c(0.5,1,1.5,2)

#grid <- expand.grid(k = k, eps = eps)

#results <- mapply(grid$k, grid$eps, FUN = function(k, eps) {
#  dbscan <- dbscan(crime.scale.log, minPts = k, eps = eps)
#  print(dbscan)
#})

```

## GMM

```{r}

#install.packages('mixtools')
library(mixtools)

set.seed(221275)

clusterGaussianas <- normalmixEM(as.matrix(crime.scale.log), lambda = 0.5, k=2, maxit = 1000)
plot(clusterGaussianas, density=TRUE, cex.axis=1.4, cex.lab=1.4, cex.main=1.8)

# Hablando de erupciones, un ejemplo típico

library(mixtools)
data(faithful)

# Distribución del tiempo que pasa entre erupciones

hist(faithful$waiting, main="Tiempo entre erupciones del Old Faithful",
     xlab="Minutos", ylab="", cex.main=1.5, cex.lab=1.5, cex.axis=1.4, col="blue")
clusterGaussianas <- normalmixEM(faithful$waiting, lambda = 1, k=2, maxit = 30)
plot(clusterGaussianas, density=TRUE, cex.axis=1.4, cex.lab=1.4, cex.main=1.8, main2="Time between Old Faithful eruptions", xlab2="Minutes")

clusterGaussianas <- normalmixEM(faithful$waiting, lambda = 1, k=3, maxit = 30)
plot(clusterGaussianas, density=TRUE, cex.axis=1.4, cex.lab=1.4, cex.main=1.8, main2="Time between Old Faithful eruptions", xlab2="Minutes")

```

