---
title: "Case Study: Text Classification"
author: "MÃ¡ster en Data Science y Big Data en Finanzas"
date: 'AFI, 2022'
output:
  html_document: 
    css: my-theme.css
    theme: cerulean
    highlight: tango
    number_sections: no
    toc: no
    toc_depth: 1
  pdf_document:
    css: my-theme.css
    theme: cerulean
    highlight: tango
    number_sections: yes
    toc: yes
    toc_depth: 1
editor_options:
  chunk_output_type: console
---
    
```{r global_options, include=T, echo = F}
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
```

```{r, echo=FALSE}
htmltools::img(src = knitr::image_uri(file.path("AfiLogo.jpg")), 
               alt = 'logo', 
               style = 'position:absolute; top:0; right:0; padding:10px;',
               width="173",
               height="77")
```

# Building a Spam Filter

<br>

**Goal:** build a spam filter to classify incoming mail as either *spam* or *ham*

### Available Data

Dataset from the Center for Machine Learning and Intelligent Systems at the University of California, Irvine

- Source: [https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip](https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip)

This dataset consists of 5574 observations of 2 variables

The first variable is the content of the emails and the second variable the target variable

### Load useful libraries

```{r}
library(tidyverse)
library(tm)
library(wordcloud)
library(SnowballC)
library(caret)
library(e1071)
library(naivebayes)
```

# Load and explore the data set

```{r}
text <- read.delim("SMSSpamCollection.csv", sep="\t", header=F, colClasses="character", quote="")

head(text)

text = text %>% rename(type=V1, text=V2)

text$type = text$type %>% factor

prop.table(table(text$type))
```

Note most of the emails are not spam

### Descriptive analysis: the wordcloud

Global wordcloud:

```{r}
# Global wordcloud
wordcloud(text$text, max.words = 100, random.order = FALSE,
          colors=brewer.pal(8, "Dark2"))
```

Wordcloud for spam messages:

```{r}
# Wordcloud for spam messages
spam <- subset(text, type == "spam")
wordcloud(spam$text, max.words = 100, random.order = FALSE,
          colors=brewer.pal(8, "Dark2"), main = "spam")  
```

Wordcloud for ham messages:

```{r}
# Wordcloud for ham messages
ham <- subset(text, type != "spam")
wordcloud(ham$text, max.words = 100, random.order = FALSE,
          colors=brewer.pal(8, "Dark2"), main = "ham")
```

Any difference?

### The data matrix: from text to numbers

Our data matrix is going to be a **Document Term Matrix:** documents in rows, words (corpus) in columns

Each element in the matrix contains the number of times a word appear in a document

Moreover, we need some transformations: the words in lowercase, remove numbers and stops words, punctuation, etc. 

```{r}
text_corpus <- VCorpus(VectorSource(text$text))

X <- DocumentTermMatrix(text_corpus,
                        control = list(
                          tolower = TRUE,
                          removeNumbers = TRUE,
                          stopwords = TRUE,
                          removePunctuation = TRUE,
                          stemming = TRUE
                        ))

X
dim(X)

inspect(X[1:10, 1000:1010])

```

There are 5574 emails 

Dimension is too high, we need to reduce it, otherwise dataset will be too noisy

There is a word that appears 657 times (call), but most of the words appear less than once

Hence, include only words that appear at least 20 times in the dataset

Take care: this can by an hyper-parameter...

```{r}
# choose one of these two:
freq_words <- findFreqTerms(X, 20)
#X = removeSparseTerms(X, 0.999)

X = X[, freq_words]
X
```

Dimension is still high (450), this is why we will use Naive Bayes to train the tool

# Train and test split

We will train the models with 80% of the dataset and test them with the remaining 20%

```{r}
index=createDataPartition(text$type,p=0.8,list=FALSE)
X.train=X[index,]
X.test=X[-index,]
y.train=text[index,]$type
y.test=text[-index,]$type
```

# Naive-Bayes classification

### Standard version (Gaussian)

The standard naive Bayes classifier (in e1071::naiveBayes) assumes independence of the predictor variables, and Gaussian distribution (given the target class) of metric predictors.

This is the standard, assuming Gaussian distribution in predictors

```{r}
NB.fit <- naiveBayes(as.matrix(X.train), y.train, laplace = 1) # laplace controls smoothing of probabilities: it adds a small non-zero count to all the word counts to avoid zero prob
NB.pred <- predict(NB.fit, as.matrix(X.test))
```

```{r}
# Type the confusion matrix here

```


Accuracy is around 20%, very poor for this promising tool...

We can also consider probabilities as output, although they are not reliable, take care!

```{r}
NB.prob <- predict(NB.fit, as.matrix(X.test),type="raw")

head(NB.prob)
hist(NB.prob)
```

Note probabilities are extreme!

### Standard (Gaussian) with binary predictors

Let's try now the same naive Bayes, but with binary predictors (and again assuming Gaussian distribution)

```{r}
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}

X.train.bin = apply(X.train, MARGIN = 2, convert_counts)
X.test.bin = apply(X.test, MARGIN = 2, convert_counts)

NB.fit <- naiveBayes(X.train.bin, y.train, laplace = 1) # laplace controls smoothing of probabilities
NB.pred <- predict(NB.fit, X.test.bin)
```

```{r}
# Type the confusion matrix here

```

Now, accuracy in testing set is over 97%, that's a lot!

### Multinomial version

Multinomial Naive Bayes model (from naivebayes package): all class conditional distributions are assumed to be multinomial and independent

```{r}
NB.fit <- multinomial_naive_bayes(as.matrix(X.train), y.train, laplace=.6)
NB.pred <- predict(NB.fit, as.matrix(X.test))

NB.prob <- predict(NB.fit, as.matrix(X.test),type="prob")
hist(NB.prob)
```

```{r}
# Type the confusion matrix here

```

Now, accuracy in testing set is over 97%, that's a lot!

Probabilities are not as extreme as before


### Bernoulli version

Bernoulli Naive Bayes model (from naivebayes package): all class conditional distributions are assumed to be Bernoulli and independent

```{r}
NB.fit <- bernoulli_naive_bayes(as.matrix(X.train), y.train, laplace=0.2)
NB.pred <- predict(NB.fit, as.matrix(X.test))

NB.prob <- predict(NB.fit, as.matrix(X.test),type="prob")
hist(NB.prob)
```

```{r}
# Type the confusion matrix here

```

A bit better...


# With Caret

Remember the main function: train()
  
tidymodels is the tidy version of caret (collection of packages for modelling)

Let's try 5-fold cross validation

```{r}
ctrl <- trainControl(method = "repeatedcv", 
                     number = 5,
                     verboseIter = T)
```

Define now the tuning grid:

```{r}
nb_grid <-   expand.grid(usekernel = c(TRUE, FALSE),
                         laplace = c(0.2, 0.3, 0.4, 0.5), 
                         adjust = c(0,0.5,1))
```

Take care: the input in caret should be a data frame, not a list

```{r}
X.train.bin = X.train.bin %>% as.matrix() %>% as.data.frame()
X.test.bin = X.test.bin %>% as.matrix() %>% as.data.frame()
```

Take care: the multinomial naive bayes is not implemented in caret


```{r}
nb_mod <- train(x = X.train.bin,
                y = y.train,
                method = "naive_bayes",
                trControl = ctrl,
                tuneGrid = nb_grid)

nb_pred <- predict(nb_mod, newdata = X.test.bin)

confusionMatrix(nb_pred,y.test)
```

Visualize the tuning process:

```{r}
plot(nb_mod)
```

Not too much gain here, but in practice a good tuning makes a difference!

