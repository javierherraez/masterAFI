height="77")
library(tidyverse)
library(MASS)
library(caret)
Airlines <- read.csv("AirlineDelay.csv")
# Create the three groups or categories (labels)
Airlines$DelayClass = factor(ifelse(Airlines$TotalDelay == 0, "No Delay", ifelse(Airlines$TotalDelay >= 30, "Major Delay", "Minor Delay")))
levels(Airlines$DelayClass)
qda.model <- qda(DelayClass ~ ., data=AirlinesTrain, prior = c(1/6, 1/3, 1/2))
qda.model
# Chunk 1: global_options
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
# Chunk 2
htmltools::img(src = knitr::image_uri(file.path("AfiLogo.jpg")),
alt = 'logo',
style = 'position:absolute; top:0; right:0; padding:10px;',
width="173",
height="77")
# Chunk 3
library(tidyverse)
library(MASS)
library(caret)
# Chunk 4
Airlines <- read.csv("AirlineDelay.csv")
# Create the three groups or categories (labels)
Airlines$DelayClass = factor(ifelse(Airlines$TotalDelay == 0, "No Delay", ifelse(Airlines$TotalDelay >= 30, "Major Delay", "Minor Delay")))
levels(Airlines$DelayClass)
# Chunk 5
# Chunk 6
# split between training and testing sets
spl = createDataPartition(Airlines$DelayClass, p = 0.8, list = FALSE)  # 80% for training
AirlinesTrain = Airlines[spl,]
AirlinesTest = Airlines[-spl,]
table(AirlinesTrain$DelayClass)
# Chunk 7
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain, prior = c(1/6, 1/3, 1/2))
lda.model
# Chunk 8
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain)
# Chunk 9
probability = predict(lda.model, newdata=AirlinesTest)$posterior
head(probability)
# Chunk 10
prediction <- max.col(probability)
head(prediction)
# Chunk 11
prediction = predict(lda.model, newdata=AirlinesTest)$class
head(prediction)
# Chunk 12
confusionMatrix(prediction, AirlinesTest$DelayClass)$table
confusionMatrix(prediction, AirlinesTest$DelayClass)$overall[1]
qda.model <- qda(DelayClass ~ ., data=AirlinesTrain, prior = c(1/6, 1/3, 1/2))
qda.model
?lda
1/6 + 1/3 + 1/2
qda.model <- qda(DelayClass ~ ., data=AirlinesTrain, prior = c(1/6, 1/3, 1/2))
qda.model
# Chunk 1: global_options
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
# Chunk 2
htmltools::img(src = knitr::image_uri(file.path("AfiLogo.jpg")),
alt = 'logo',
style = 'position:absolute; top:0; right:0; padding:10px;',
width="173",
height="77")
# Chunk 3
library(tidyverse)
library(MASS)
library(caret)
# Chunk 4
Airlines <- read.csv("AirlineDelay.csv")
# Create the three groups or categories (labels)
Airlines$DelayClass = factor(ifelse(Airlines$TotalDelay == 0, "No Delay", ifelse(Airlines$TotalDelay >= 30, "Major Delay", "Minor Delay")))
levels(Airlines$DelayClass)
# Chunk 5
# Chunk 6
# split between training and testing sets
spl = createDataPartition(Airlines$DelayClass, p = 0.8, list = FALSE)  # 80% for training
AirlinesTrain = Airlines[spl,]
AirlinesTest = Airlines[-spl,]
table(AirlinesTrain$DelayClass)
table(AirlinesTrain$DelayClass) / nrow(AirlinesTrain)
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain, prior = c(1/6, 1/3, 1/2))
lda.model
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain)
probability = predict(lda.model, newdata=AirlinesTest)$posterior
head(probability)
prediction <- max.col(probability)
head(prediction)
prediction = predict(lda.model, newdata=AirlinesTest)$class
head(prediction)
confusionMatrix(prediction, AirlinesTest$DelayClass)$table
confusionMatrix(prediction, AirlinesTest$DelayClass)$overall[1]
# Chunk 1: global_options
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
# Chunk 2
htmltools::img(src = knitr::image_uri(file.path("AfiLogo.jpg")),
alt = 'logo',
style = 'position:absolute; top:0; right:0; padding:10px;',
width="173",
height="77")
# Chunk 3
library(tidyverse)
library(MASS)
library(caret)
# Chunk 4
Airlines <- read.csv("AirlineDelay.csv")
# Create the three groups or categories (labels)
Airlines$DelayClass = factor(ifelse(Airlines$TotalDelay == 0, "No Delay", ifelse(Airlines$TotalDelay >= 30, "Major Delay", "Minor Delay")))
levels(Airlines$DelayClass)
# Chunk 5
# Chunk 6
# split between training and testing sets
spl = createDataPartition(Airlines$DelayClass, p = 0.8, list = FALSE)  # 80% for training
AirlinesTrain = Airlines[spl,]
AirlinesTest = Airlines[-spl,]
table(AirlinesTrain$DelayClass)
table(AirlinesTrain$DelayClass) / nrow(AirlinesTrain)
# Chunk 7
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain, prior = c(1/6, 1/3, 1/2))
lda.model
# Chunk 8
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain)
# Chunk 9
probability = predict(lda.model, newdata=AirlinesTest)$posterior
head(probability)
# Chunk 10
prediction <- max.col(probability)
head(prediction)
# Chunk 11
prediction = predict(lda.model, newdata=AirlinesTest)$class
head(prediction)
# Chunk 12
confusionMatrix(prediction, AirlinesTest$DelayClass)$table
confusionMatrix(prediction, AirlinesTest$DelayClass)$overall[1]
qda.model <- qda(DelayClass ~ ., data=AirlinesTrain, prior = c(1/6, 1/3, 1/2))
qda.model
# Chunk 1: global_options
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
# Chunk 2
htmltools::img(src = knitr::image_uri(file.path("AfiLogo.jpg")),
alt = 'logo',
style = 'position:absolute; top:0; right:0; padding:10px;',
width="173",
height="77")
# Chunk 3
library(tidyverse)
library(MASS)
library(caret)
# Chunk 4
Airlines <- read.csv("AirlineDelay.csv")
# Create the three groups or categories (labels)
Airlines$DelayClass = factor(ifelse(Airlines$TotalDelay == 0, "No Delay", ifelse(Airlines$TotalDelay >= 30, "Major Delay", "Minor Delay")))
levels(Airlines$DelayClass)
# Chunk 5
# Chunk 6
# split between training and testing sets
spl = createDataPartition(Airlines$DelayClass, p = 0.9, list = FALSE)  # 80% for training
AirlinesTrain = Airlines[spl,]
AirlinesTest = Airlines[-spl,]
table(AirlinesTrain$DelayClass)
table(AirlinesTrain$DelayClass) / nrow(AirlinesTrain)
# Chunk 7
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain, prior = c(1/6, 1/3, 1/2))
lda.model
# Chunk 8
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain)
# Chunk 9
probability = predict(lda.model, newdata=AirlinesTest)$posterior
head(probability)
# Chunk 10
prediction <- max.col(probability)
head(prediction)
# Chunk 11
prediction = predict(lda.model, newdata=AirlinesTest)$class
head(prediction)
# Chunk 12
confusionMatrix(prediction, AirlinesTest$DelayClass)$table
confusionMatrix(prediction, AirlinesTest$DelayClass)$overall[1]
qda.model <- qda(DelayClass ~ ., data=AirlinesTrain, prior = c(1/6, 1/3, 1/2))
qda.model
# Chunk 1: global_options
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
# Chunk 2
htmltools::img(src = knitr::image_uri(file.path("AfiLogo.jpg")),
alt = 'logo',
style = 'position:absolute; top:0; right:0; padding:10px;',
width="173",
height="77")
# Chunk 3
library(tidyverse)
library(MASS)
library(caret)
# Chunk 4
Airlines <- read.csv("AirlineDelay.csv")
# Create the three groups or categories (labels)
Airlines$DelayClass = factor(ifelse(Airlines$TotalDelay == 0, "No Delay", ifelse(Airlines$TotalDelay >= 30, "Major Delay", "Minor Delay")))
levels(Airlines$DelayClass)
# Chunk 5
# Chunk 6
# split between training and testing sets
spl = createDataPartition(Airlines$DelayClass, p = 0.8, list = FALSE)  # 80% for training
AirlinesTrain = Airlines[spl,]
AirlinesTest = Airlines[-spl,]
table(AirlinesTrain$DelayClass)
table(AirlinesTrain$DelayClass) / nrow(AirlinesTrain)
# Chunk 7
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain, prior = c(1/6, 1/3, 1/2))
lda.model
# Chunk 8
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain)
# Chunk 9
probability = predict(lda.model, newdata=AirlinesTest)$posterior
head(probability)
# Chunk 10
prediction <- max.col(probability)
head(prediction)
# Chunk 11
prediction = predict(lda.model, newdata=AirlinesTest)$class
head(prediction)
# Chunk 12
confusionMatrix(prediction, AirlinesTest$DelayClass)$table
confusionMatrix(prediction, AirlinesTest$DelayClass)$overall[1]
# Chunk 13
qda.model <- qda(DelayClass ~ ., data=AirlinesTrain, prior = c(1/6, 1/3, 1/2))
qda.model
# Chunk 14
prediction = predict(qda.model, newdata=AirlinesTest)$class
confusionMatrix(prediction, AirlinesTest$DelayClass)$table
confusionMatrix(prediction, AirlinesTest$DelayClass)$overall[1]
# Chunk 15
table(AirlinesTrain$DelayClass)
obs <- max(table(AirlinesTest$DelayClass))
# Accuracy:
obs/nrow(AirlinesTest)
# Chunk 16
Airlines$DelayClass = factor(ifelse(Airlines$DelayClass == "No Delay", "No Delay", "Delay"))
levels(Airlines$DelayClass)
AirlinesTrain = Airlines[spl,]
AirlinesTest = Airlines[-spl,]
table(AirlinesTrain$DelayClass)
# Chunk 17
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain)
prediction = predict(lda.model, newdata=AirlinesTest)$class
confusionMatrix(prediction, AirlinesTest$DelayClass)$table
confusionMatrix(prediction, AirlinesTest$DelayClass)$overall[1]
# Chunk 18
# 5-fold cross validation
ctrl <- trainControl(method = "repeatedcv",
number = 5)
# Define a method
method = "sparseLDA"   # "lda" "PenalizedLDA"  "stepLDA"
# Define a grid for the hyper-parameters
param_grid = expand.grid(NumVars = seq(20, 50, 5), lambda = seq(0, 1, 0.2))
# Train
ldaFit <- train(DelayClass ~ .,
method = method,
data = AirlinesTrain,
tuneGrid = param_grid,
preProcess = c("center", "scale"),
metric = "Accuracy",
trControl = ctrl)
# Chunk 1: global_options
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
# Chunk 2
htmltools::img(src = knitr::image_uri(file.path("AfiLogo.jpg")),
alt = 'logo',
style = 'position:absolute; top:0; right:0; padding:10px;',
width="173",
height="77")
# Chunk 3
library(tidyverse)
library(MASS)
library(caret)
# Chunk 4
Airlines <- read.csv("AirlineDelay.csv")
# Create the three groups or categories (labels)
Airlines$DelayClass = factor(ifelse(Airlines$TotalDelay == 0, "No Delay", ifelse(Airlines$TotalDelay >= 30, "Major Delay", "Minor Delay")))
levels(Airlines$DelayClass)
# Chunk 5
# Chunk 6
# split between training and testing sets
spl = createDataPartition(Airlines$DelayClass, p = 0.8, list = FALSE)  # 80% for training
AirlinesTrain = Airlines[spl,]
AirlinesTest = Airlines[-spl,]
table(AirlinesTrain$DelayClass)
table(AirlinesTrain$DelayClass) / nrow(AirlinesTrain)
# Chunk 7
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain, prior = c(1/6, 1/3, 1/2))
lda.model
# Chunk 8
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain)
# Chunk 9
probability = predict(lda.model, newdata=AirlinesTest)$posterior
head(probability)
# Chunk 10
prediction <- max.col(probability)
head(prediction)
# Chunk 11
prediction = predict(lda.model, newdata=AirlinesTest)$class
head(prediction)
# Chunk 12
confusionMatrix(prediction, AirlinesTest$DelayClass)$table
confusionMatrix(prediction, AirlinesTest$DelayClass)$overall[1]
# Chunk 13
qda.model <- qda(DelayClass ~ ., data=AirlinesTrain, prior = c(1/6, 1/3, 1/2))
qda.model
# Chunk 14
prediction = predict(qda.model, newdata=AirlinesTest)$class
confusionMatrix(prediction, AirlinesTest$DelayClass)$table
confusionMatrix(prediction, AirlinesTest$DelayClass)$overall[1]
# Chunk 15
table(AirlinesTrain$DelayClass)
obs <- max(table(AirlinesTest$DelayClass))
# Accuracy:
obs/nrow(AirlinesTest)
# Chunk 16
Airlines$DelayClass = factor(ifelse(Airlines$DelayClass == "No Delay", "No Delay", "Delay"))
levels(Airlines$DelayClass)
AirlinesTrain = Airlines[spl,]
AirlinesTest = Airlines[-spl,]
table(AirlinesTrain$DelayClass)
# Chunk 17
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain)
prediction = predict(lda.model, newdata=AirlinesTest)$class
confusionMatrix(prediction, AirlinesTest$DelayClass)$table
confusionMatrix(prediction, AirlinesTest$DelayClass)$overall[1]
# Chunk 18
# 5-fold cross validation
ctrl <- trainControl(method = "repeatedcv",
number = 5)
# Define a method
method = "sparseLDA"   # "lda" "PenalizedLDA"  "stepLDA"
# Define a grid for the hyper-parameters
param_grid = expand.grid(NumVars = seq(20, 50, 5), lambda = seq(0, 1, 0.2))
# Train
ldaFit <- train(DelayClass ~ .,
method = method,
data = AirlinesTrain,
tuneGrid = param_grid,
preProcess = c("center", "scale"),
metric = "Accuracy",
trControl = ctrl)
install.packages('sparseLDA')
# Chunk 1: global_options
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
# Chunk 2
htmltools::img(src = knitr::image_uri(file.path("AfiLogo.jpg")),
alt = 'logo',
style = 'position:absolute; top:0; right:0; padding:10px;',
width="173",
height="77")
# Chunk 3
library(tidyverse)
library(MASS)
library(caret)
# Chunk 4
Airlines <- read.csv("AirlineDelay.csv")
# Create the three groups or categories (labels)
Airlines$DelayClass = factor(ifelse(Airlines$TotalDelay == 0, "No Delay", ifelse(Airlines$TotalDelay >= 30, "Major Delay", "Minor Delay")))
levels(Airlines$DelayClass)
# Chunk 5
# Chunk 6
# split between training and testing sets
spl = createDataPartition(Airlines$DelayClass, p = 0.8, list = FALSE)  # 80% for training
AirlinesTrain = Airlines[spl,]
AirlinesTest = Airlines[-spl,]
table(AirlinesTrain$DelayClass)
table(AirlinesTrain$DelayClass) / nrow(AirlinesTrain)
# Chunk 7
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain, prior = c(1/6, 1/3, 1/2))
lda.model
# Chunk 8
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain)
# Chunk 9
probability = predict(lda.model, newdata=AirlinesTest)$posterior
head(probability)
# Chunk 10
prediction <- max.col(probability)
head(prediction)
# Chunk 11
prediction = predict(lda.model, newdata=AirlinesTest)$class
head(prediction)
# Chunk 12
confusionMatrix(prediction, AirlinesTest$DelayClass)$table
confusionMatrix(prediction, AirlinesTest$DelayClass)$overall[1]
# Chunk 13
qda.model <- qda(DelayClass ~ ., data=AirlinesTrain, prior = c(1/6, 1/3, 1/2))
qda.model
# Chunk 14
prediction = predict(qda.model, newdata=AirlinesTest)$class
confusionMatrix(prediction, AirlinesTest$DelayClass)$table
confusionMatrix(prediction, AirlinesTest$DelayClass)$overall[1]
# Chunk 15
table(AirlinesTrain$DelayClass)
obs <- max(table(AirlinesTest$DelayClass))
# Accuracy:
obs/nrow(AirlinesTest)
# Chunk 16
Airlines$DelayClass = factor(ifelse(Airlines$DelayClass == "No Delay", "No Delay", "Delay"))
levels(Airlines$DelayClass)
AirlinesTrain = Airlines[spl,]
AirlinesTest = Airlines[-spl,]
table(AirlinesTrain$DelayClass)
# Chunk 17
lda.model <- lda(DelayClass ~ ., data=AirlinesTrain)
prediction = predict(lda.model, newdata=AirlinesTest)$class
confusionMatrix(prediction, AirlinesTest$DelayClass)$table
confusionMatrix(prediction, AirlinesTest$DelayClass)$overall[1]
# Chunk 18
# 5-fold cross validation
ctrl <- trainControl(method = "repeatedcv",
number = 5)
# Define a method
method = "sparseLDA"   # "lda" "PenalizedLDA"  "stepLDA"
# Define a grid for the hyper-parameters
param_grid = expand.grid(NumVars = seq(20, 50, 5), lambda = seq(0, 1, 0.2))
# Train
ldaFit <- train(DelayClass ~ .,
method = method,
data = AirlinesTrain,
tuneGrid = param_grid,
preProcess = c("center", "scale"),
metric = "Accuracy",
trControl = ctrl)
print(ldaFit)
# Predict and validate
ldaPred = predict(ldaFit, AirlinesTest)
confusionMatrix(ldaPred,AirlinesTest$DelayClass)
setwd("../Lab 2 clasificación de textos/")
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
htmltools::img(src = knitr::image_uri(file.path("AfiLogo.jpg")),
alt = 'logo',
style = 'position:absolute; top:0; right:0; padding:10px;',
width="173",
height="77")
library(tidyverse)
library(tm)
library(wordcloud)
library(SnowballC)
library(caret)
library(e1071)
library(naivebayes)
text <- read.delim("SMSSpamCollection.csv", sep="\t", header=F, colClasses="character", quote="")
head(text)
text = text %>% rename(type=V1, text=V2)
text$type = text$type %>% factor
prop.table(table(text$type))
table(text$type)
?DocumentTermMatrix
# Chunk 1: global_options
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
# Chunk 2
htmltools::img(src = knitr::image_uri(file.path("AfiLogo.jpg")),
alt = 'logo',
style = 'position:absolute; top:0; right:0; padding:10px;',
width="173",
height="77")
# Chunk 3
library(tidyverse)
library(tm)
library(wordcloud)
library(SnowballC)
library(caret)
library(e1071)
library(naivebayes)
# Chunk 4
text <- read.delim("SMSSpamCollection.csv", sep="\t", header=F, colClasses="character", quote="")
head(text)
text = text %>% rename(type=V1, text=V2)
text$type = text$type %>% factor
prop.table(table(text$type))
# Chunk 5
# Global wordcloud
wordcloud(text$text, max.words = 100, random.order = FALSE,
colors=brewer.pal(8, "Dark2"))
# Chunk 6
# Wordcloud for spam messages
spam <- subset(text, type == "spam")
wordcloud(spam$text, max.words = 100, random.order = FALSE,
colors=brewer.pal(8, "Dark2"), main = "spam")
# Chunk 7
# Wordcloud for ham messages
ham <- subset(text, type != "spam")
wordcloud(ham$text, max.words = 100, random.order = FALSE,
colors=brewer.pal(8, "Dark2"), main = "ham")
text_corpus <- VCorpus(VectorSource(text$text))
X <- DocumentTermMatrix(text_corpus,
control = list(
tolower = TRUE,
removeNumbers = TRUE,
stopwords = TRUE,
removePunctuation = TRUE,
stemming = TRUE
))
X
dim(X)
inspect(X[1:10, 1000:1010])
# choose one of these two:
freq_words <- findFreqTerms(X, 20)
#X = removeSparseTerms(X, 0.999)
X = X[, freq_words]
X
index=createDataPartition(text$type,p=0.8,list=FALSE)
X.train=X[index,]
X.test=X[-index,]
y.train=text[index,]$type
y.test=text[-index,]$type
NB.fit <- naiveBayes(as.matrix(X.train), y.train, laplace = 1) # laplace controls smoothing of probabilities: it adds a small non-zero count to all the word counts to avoid zero prob
NB.pred <- predict(NB.fit, as.matrix(X.test))
#confusion matrix
confusionMatrix(NB.pred,y.test)
