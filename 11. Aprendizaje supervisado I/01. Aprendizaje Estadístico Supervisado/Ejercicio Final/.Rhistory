require("knitr")
library("caret")
library("dplyr")
opts_knit$set(root.dir = "C:/Proyectos/AFI/cursos_20212022/Regular")
# setwd("C:/Proyectos/AFI/cursos_20212022/Regular")
setwd("C:/Users/jherraez/Documents/masterAFI/09. Aprendizaje no supervisado/01. Clustering jerarquico y no jerarquico/")
####################
# Lectura de datos #
####################
datosBanca <- read.csv("Data/datosBanca.csv", header = TRUE, sep=",")
set.seed(1404)
datosBanca <- datosBanca[sample(nrow(datosBanca), nrow(datosBanca) * 0.8), ]
rownames(datosBanca) <- 1:nrow(datosBanca)
summary(datosBanca)
# Estandarización mediante discretización
# install.packages("nima")
library(nima)
datosBanca$checkingAccount_CAT <- discrete_by_quantile(datosBanca$checkingAccount)/4
datosBanca$deposit_CAT <- discrete_by_quantile(datosBanca$deposit)/4
datosBanca$shareOfStock_CAT <- discrete_by_quantile(datosBanca$shareOfStock)/4
datosBanca$pensionPlan_CAT <- discrete_by_quantile(datosBanca$pensionPlan)/4
#datosBanca$mortgage_CAT<-discrete_by_quantile(datosBanca$mortgage)/4
# Como da un error, la asignamos con IF
summary(datosBanca$mortgage)
datosBanca$mortgage_CAT <- datosBanca$mortgage
datosBanca$mortgage_CAT <- ifelse(datosBanca$mortgage <= 0, 1, datosBanca$mortgage_CAT)
datosBanca$mortgage_CAT <- ifelse(0<datosBanca$mortgage & datosBanca$mortgage<= 45104, 2, datosBanca$mortgage_CAT)
datosBanca$mortgage_CAT <- ifelse(45104<datosBanca$mortgage & datosBanca$mortgage<= 125979, 3, datosBanca$mortgage_CAT)
datosBanca$mortgage_CAT <- ifelse(125979<datosBanca$mortgage, 4, datosBanca$mortgage_CAT)
datosBanca$mortgage_CAT <- datosBanca$mortgage_CAT/4
summary(datosBanca$mortgage_CAT)
datosBanca$loan_CAT<-discrete_by_quantile(datosBanca$loan)/4
datosBanca$cards_CAT<-discrete_by_quantile(datosBanca$cards)/4
datosBanca$insurance_CAT<-discrete_by_quantile(datosBanca$insurance)/4
datosBanca$billPayment_CAT<-discrete_by_quantile(datosBanca$billPayment)/4
# La domiciliación de nómina es binaria y no es preciso estandarizarla
# Importante hacerla numérica porque si no, la considera integer y su AVERAGE vía SQL devuelve 0
datosBanca$salary_CAT<-as.numeric(datosBanca$salary)
summary(datosBanca)
# Cambiar missings por 0 #
datosBanca$checkingAccount_CAT[is.na(datosBanca$checkingAccount_CAT)]<-0
datosBanca$deposit_CAT[is.na(datosBanca$deposit_CAT)]<-0
datosBanca$shareOfStock_CAT[is.na(datosBanca$shareOfStock_CAT)]<-0
datosBanca$pensionPlan_CAT[is.na(datosBanca$pensionPlan_CAT)]<-0
datosBanca$mortgage_CAT[is.na(datosBanca$mortgage_CAT)]<-0
datosBanca$loan_CAT[is.na(datosBanca$loan_CAT)]<-0
datosBanca$cards_CAT[is.na(datosBanca$cards_CAT)]<-0
datosBanca$insurance_CAT[is.na(datosBanca$insurance_CAT)]<-0
datosBanca$billPayment_CAT[is.na(datosBanca$billPayment_CAT)]<-0
datosBanca.cat <- datosBanca %>%
select(ends_with('_CAT'))
library(cluster)
library(factoextra)
library(vegan)
datosBanca.cat.subset <- datosBanca.cat[sample(nrow(datosBanca.cat), nrow(datosBanca.cat) * 0.1), ]
matrizDistancias <- vegdist(datosBanca.cat, method = "euclidean")
datosBanca.cat.subset <- datosBanca.cat[sample(nrow(datosBanca.cat), nrow(datosBanca.cat) * 0.1), ]
matrizDistancias <- vegdist(datosBanca.cat.subset, method = "euclidean")
clusterJerarquico <- hclust(matrizDistancias, method="ward.D2")
plot(as.dendrogram(clusterJerarquico),  main = "Dendrograma")
library(dendextend)
plot(as.dendrogram(clusterJerarquico),  main = "Dendrograma")
rect.hclust(clusterJerarquico, k=2, border="red")
rect.hclust(clusterJerarquico, k=3, border="blue")
rect.hclust(clusterJerarquico, k=4, border="green")
rect.hclust(clusterJerarquico, k=5, border="yellow")
rect.hclust(clusterJerarquico, k=6, border="purple")
rect.hclust(clusterJerarquico, k=7, border="gray")
rect.hclust(clusterJerarquico, k=8, border="black")
datosBanca.cat.subset <- datosBanca.cat[sample(nrow(datosBanca.cat), nrow(datosBanca.cat) * 0.1), ]
rownames(datosBanca.cat.subset) <- 1:nrow(datosBanca.cat.subset)
matrizDistancias <- vegdist(datosBanca.cat.subset, method = "euclidean")
plot(as.dendrogram(clusterJerarquico),  main = "Dendrograma")
rect.hclust(clusterJerarquico, k=2, border="red")
rect.hclust(clusterJerarquico, k=3, border="blue")
rect.hclust(clusterJerarquico, k=4, border="green")
rect.hclust(clusterJerarquico, k=5, border="yellow")
rect.hclust(clusterJerarquico, k=6, border="purple")
rect.hclust(clusterJerarquico, k=7, border="gray")
rect.hclust(clusterJerarquico, k=8, border="black")
dend <- as.dendrogram(clusterJerarquico)
dend <- color_branches(dend, k=4)
plot(dend)
library(dplyr)
rm(list = ls())
setwd("C:/Users/jherraez/Documents/masterAFI/11. Aprendizaje supervisado I/01. Aprendizaje Estadístico Supervisado/Ejercicio Final")
df <- read.csv("BreastCancerData.csv", na.strings = 100)
target <- colnames(df)[ncol(df)]
target
table(df[, target])
hist(rowSums(is.na(df)))
table(rowSums(is.na(df)))
hist(colSums(is.na(df)))
table(colSums(is.na(df)))
#borrar columnas con todos missing values
nasColumns <- sapply(df, function(x) all(is.na(x)))
df <- df[, !(nasColumns)]
table(rowSums(is.na(df)))
table(colSums(is.na(df)))
####################################################
df <- df[!(rowSums(is.na(df)) > 10000),]
table(colSums(is.na(df)))
nasColumns_2 <- sapply(df, function(x) any(is.na(x)))
df <- df[, !(nasColumns_2)]
table(colSums(is.na(df)))
genes <- df[, 1:ncol(df)-1]
max(genes)
min(genes)
pca = prcomp(genes, scale=T)
summary(pca)
barplot(pca$rotation[,1], las=2, col="darkblue")
pca$rotation[,1]
View(pca)
pca$rotation
ctrl <- trainControl(method = "cv", number = 5,
classProbs = TRUE,
verboseIter=T)
library(caret)
ctrl <- trainControl(method = "cv", number = 5,
classProbs = TRUE,
verboseIter=T)
# We have many predictors, hence use penalized logistic regression
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = df,
preProcess = c("pca"),
trControl = ctrl)
# We have many predictors, hence use penalized logistic regression
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = df,
preProcess = c("center", "scale"), #pca
trControl = ctrl)
# We have many predictors, hence use penalized logistic regression
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = df,
preProcess = c("center", "scale", "pca"), #pca
trControl = ctrl)
?preProcess
# We have many predictors, hence use penalized logistic regression
pre <- preProcess(df, method = "pca", pcaComp = 60)
pre
?trainControl
df[,1:ncol(df) - 1]
df[,1:ncol(df]
df[,1:ncol(df)]
# We have many predictors, hence use penalized logistic regression
pre <- preProcess(df[,1:ncol(df) - 1], method=c("scale","pca"), thresh=0.8)
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = predict(pre, df),
preProcess = c("center", "scale", "pca"), #pca
trControl = ctrl)
print(rdaFit)
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = predict(pre, df),
preProcess = c("center", "scale", "pca"), #pca
trControl = ctrl)
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = predict(pre, df),
#preProcess = c("center", "scale", "pca"),
trControl = ctrl)
ctrl <- trainControl(method = "cv", number = 5,
classProbs = TRUE,
verboseIter=T,
)
pre <- preProcess(df[,1:ncol(df) - 1], method = c("scale","pca"), thresh=0.8)
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = predict(pre, df),
#preProcess = c("center", "scale", "pca"),
trControl = ctrl)
pre
ctrl <- trainControl(method = "cv", number = 5,
classProbs = TRUE,
verboseIter=T,
preProcOptions = list(thresh = 0.9))
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = df,
preProcess = c("pca"),
trControl = ctrl)
predict(pre, df)
prueba = predict(pre, df)
View(prueba)
View(prueba)
pre <- preProcess(df[,1:ncol(df) - 1], method = c("scale","pca"), thresh=0.5)
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = predict(pre, df),
#preProcess = c("center", "scale", "pca"),
trControl = ctrl)
?make.names
?trainControl
ctrl <- trainControl(method = "cv", number = 5,
classProbs = TRUE,
#verboseIter=T,
)
pre <- preProcess(df[,1:ncol(df) - 1], method = c("scale","pca"), thresh=0.5)
pre
predict(pre, df)
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = predict(pre, df),
trControl = ctrl)
str(prueba)
prueba$Class <- as.factor(prueba$Class)
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = prueba),
trControl = ctrl)
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = prueba),
trControl = ctrl)
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = prueba,
trControl = ctrl)
df_pca <- predict(pre, df)
str(df_pca)
df_pca$Class <- as.factor(df_pca$Class)
str(df_pca)
levels(df_pca$Class)
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = prueba,
trControl = ctrl)
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = df_pca,
trControl = ctrl)
levels(df_pca$Class)
levels(df_pca$Class) <- c("No", "Yes")
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = df_pca,
trControl = ctrl)
print(rdaFit)
pre <- preProcess(df[,1:ncol(df) - 1], method = c("scale","pca"), thresh=0.9)
df_pca <- predict(pre, df)
df_pca$Class <- as.factor(df_pca$Class)
levels(df_pca$Class) <- c("No", "Yes")
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = df_pca,
trControl = ctrl)
pre <- preProcess(df[,1:ncol(df) - 1], method = c("scale","pca"), thresh=0.8)
ctrl <- trainControl(method = "cv", number = 5,
classProbs = TRUE,
#verboseIter=T,
)
df_pca <- predict(pre, df)
df_pca$Class <- as.factor(df_pca$Class)
levels(df_pca$Class) <- c("No", "Yes")
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = df_pca,
trControl = ctrl)
pre <- preProcess(df[,1:ncol(df) - 1], method = c("scale","pca"), thresh=0.7)
pre
df_pca <- predict(pre, df)
df_pca$Class <- as.factor(df_pca$Class)
levels(df_pca$Class) <- c("No", "Yes")
df_pca
rdaFit <- train(Class ~ .,
method = "rda",
tuneGrid = expand.grid(gamma = seq(0, 1, 0.2), lambda = seq(0, 1, .2)),
metric = "Kappa",
data = df_pca,
trControl = ctrl)
rdaFit
predict(rdaFit, df_pca)
confusionMatrix(predict(rdaFit, df_pca), df_pca$Class)
