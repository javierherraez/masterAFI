{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svuzsW-c_Va0"
      },
      "source": [
        "Text Mining - 6. Clasificacion textos\n",
        "\n",
        "AFI - Máster en Data Science y Big Data\n",
        "\n",
        "Juan de Dios Romero Palop\n",
        "\n",
        "Abril 2022\n",
        "\n",
        "Source: Andrew Task, Udacity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5Y0tolWGdIo"
      },
      "source": [
        "### 1. Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eqOmYFCU_caw"
      },
      "outputs": [],
      "source": [
        "## Críticas de películas\n",
        "g = open('../reviews.txt','r') \n",
        "reviews = g.read().splitlines()\n",
        "g.close()\n",
        "\n",
        "## Sentimiento asociado\n",
        "g = open('../labels.txt','r') # What we WANT to know!\n",
        "labels = g.read().upper().splitlines()\n",
        "g.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sCNRyZge_q-S"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m4-aZ98KApvE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers . unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting . even those from the era should be turned off . the cryptic dialogue would make shakespeare seem easy to a third grader . on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond . future stars sally kirkland and frederic forrest can be seen briefly .  '"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_Sp0eh4FAgAm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xsYwZbY8Alu3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'NEGATIVE'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7NnpYsu8b9-9"
      },
      "outputs": [],
      "source": [
        "def pretty_print_review_and_label(i):\n",
        "    print(labels[i] + \"\\t:\\t\" + reviews[i][:80] + \"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2uZIkLHR-658",
        "nbpresent": {
          "id": "e67a709f-234f-4493-bae6-4fb192141ee0"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels.txt \t : \t reviews.txt\n",
            "\n",
            "NEGATIVE\t:\tthis movie is terrible but it has some good effects .  ...\n",
            "POSITIVE\t:\tadrian pasdar is excellent is this film . he makes a fascinating woman .  ...\n",
            "NEGATIVE\t:\tcomment this movie is impossible . is terrible  very improbable  bad interpretat...\n",
            "POSITIVE\t:\texcellent episode movie ala pulp fiction .  days   suicides . it doesnt get more...\n",
            "NEGATIVE\t:\tif you haven  t seen this  it  s terrible . it is pure trash . i saw this about ...\n",
            "POSITIVE\t:\tthis schiffer guy is a real genius  the movie is of excellent quality and both e...\n"
          ]
        }
      ],
      "source": [
        "print(\"labels.txt \\t : \\t reviews.txt\\n\")\n",
        "pretty_print_review_and_label(2137)\n",
        "pretty_print_review_and_label(12816)\n",
        "pretty_print_review_and_label(6267)\n",
        "pretty_print_review_and_label(21934)\n",
        "pretty_print_review_and_label(5297)\n",
        "pretty_print_review_and_label(4998)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLGTusxtGV87"
      },
      "source": [
        "### 2. Análisis cuantitativo términos: ¿Qué términos aparecen en los comentarios positivos, cuales en los negativos y cuales aparecen en ambos?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nlqB8_qn-66C"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M91OwP4ecNyN"
      },
      "source": [
        "Vamos a utilizar la estructura Counter de python para ver cuantas veces aparece cada palabra en las críticas. Debajo tienes un ejemplo de como utilizar un contador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbZsxhiYcvuc"
      },
      "source": [
        "https://docs.python.org/2/library/collections.html#collections.Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "C5zuEETgcXD2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('palabra2', 5), ('palabra1', 3)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ex_count = Counter()\n",
        "ex_count['palabra1'] = 3\n",
        "ex_count['palabra2'] = 5\n",
        "ex_count.most_common()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZrNcZkIpGmT1"
      },
      "outputs": [],
      "source": [
        "# Un contandor para cada tipo de review y uno total\n",
        "positive_counts = Counter()\n",
        "negative_counts = Counter()\n",
        "total_counts = Counter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BbU5hbuzHRQ9"
      },
      "outputs": [],
      "source": [
        "# Crea un bucle que, para cada crítica, recorra sus palabras una a una e incremente en 1 el número de aparaciones.\n",
        "# Aumenta el contador siempre en total_counts y en positive_counts O en negative_counts dependiendo de si es una crítica\n",
        "# positiva o negativa\n",
        "for i in range(len(reviews)):\n",
        "  for word in reviews[i].split(' '):   \n",
        "    if labels[i] == 'NEGATIVE':\n",
        "      negative_counts[word] += 1\n",
        "    else: \n",
        "      positive_counts[word] += 1\n",
        "    total_counts[word] += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IX6QYAZAHWKA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('', 550468),\n",
              " ('the', 173324),\n",
              " ('.', 159654),\n",
              " ('and', 89722),\n",
              " ('a', 83688),\n",
              " ('of', 76855),\n",
              " ('to', 66746),\n",
              " ('is', 57245),\n",
              " ('in', 50215),\n",
              " ('br', 49235)]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positive_counts.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "d9jcE5CGbZab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('', 561462),\n",
              " ('.', 167538),\n",
              " ('the', 163389),\n",
              " ('a', 79321),\n",
              " ('and', 74385),\n",
              " ('of', 69009),\n",
              " ('to', 68974),\n",
              " ('br', 52637),\n",
              " ('is', 50083),\n",
              " ('it', 48327)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "negative_counts.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "56UEs2mpbZlA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('', 1111930),\n",
              " ('the', 336713),\n",
              " ('.', 327192),\n",
              " ('and', 164107),\n",
              " ('a', 163009),\n",
              " ('of', 145864),\n",
              " ('to', 135720),\n",
              " ('is', 107328),\n",
              " ('br', 101872),\n",
              " ('it', 96352)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_counts.most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeZvc1p6dj84"
      },
      "source": [
        "El resultado del conteo muestra que las stopwords están presentes tanto en críticas positivas como en críticas negativas y pueden añadir ruido a la hora crear un modelo de clasificación. ¿Cómo podemos sacar aquellas palabras que son un indicador claro de que se trata de una crítica positiva o negativa? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viJr7UXGeVbu"
      },
      "source": [
        "### 3. Análisis cuantitativo términos: Ratios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmhHY4jvek4X"
      },
      "source": [
        "Vamos a calcular los ratios de aparición de los términos de la siguiente manera: ratio = positive_counts/float(negative_counts + 1).\n",
        "\n",
        "**Nota**: vamos a trabajar unicamente con aquellos términos que **en total** aparecen 101 o más veces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDOywUqOfDli"
      },
      "source": [
        "*   ¿Por qué ese +1 en el denominador?\n",
        "*   A bote pronto, ¿cómo interpretaríamos los resultados? ¿En qué rango se van a mover los ratios?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ktFv5uKydaCP"
      },
      "outputs": [],
      "source": [
        "pos_neg_ratios = Counter()\n",
        "\n",
        "# Calcula el ratio para los término más comunes\n",
        "for term,cnt in list(total_counts.most_common()):\n",
        "  ### Inserta tu codigo aqui\n",
        "  if cnt > 100:\n",
        "    pos_neg_ratios[term] = positive_counts[term]/float(negative_counts[term] + 1)\n",
        "  else:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "O2BnMZPsf3_7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('edie', 109.0),\n",
              " ('paulie', 59.0),\n",
              " ('felix', 23.4),\n",
              " ('polanski', 16.833333333333332),\n",
              " ('matthau', 16.555555555555557),\n",
              " ('victoria', 14.6),\n",
              " ('mildred', 13.5),\n",
              " ('gandhi', 12.666666666666666),\n",
              " ('flawless', 11.6),\n",
              " ('superbly', 9.583333333333334),\n",
              " ('perfection', 8.666666666666666),\n",
              " ('astaire', 8.5),\n",
              " ('captures', 7.68),\n",
              " ('voight', 7.615384615384615),\n",
              " ('wonderfully', 7.552631578947368)]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_neg_ratios.most_common(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HVQ2eL6j-66Z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pos-to-neg ratio for 'the' = 1.0607993145235326\n",
            "Pos-to-neg ratio for 'amazing' = 4.022813688212928\n",
            "Pos-to-neg ratio for 'terrible' = 0.17744252873563218\n"
          ]
        }
      ],
      "source": [
        "## Algunos ejemplos que nos ayudan a interpretar los resultados\n",
        "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
        "print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\n",
        "print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaRceyK0gTdi"
      },
      "source": [
        "¿Qué problema tiene esta definición de ratio? ¿Cómo lo solucionamos?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CquUDSegmpV"
      },
      "source": [
        "### 4. Análisis cuantitativo términos: Logaritmos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEFWetNNg2pR"
      },
      "source": [
        "Al aplicar logaritmos a los valores calculados en el apartado anterior hacemos que los valores por debajo de 1 pasen a ser negativos (y con valor absoluto más alto cuanto más cercanos a 0 sean) y además conseguimos que dos términos con frecuencias relativas parecidas pero en críticas de signo distinto tomen valores con valor absoluto parecido y signo contrario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "w6SwM1-5-66d"
      },
      "outputs": [],
      "source": [
        "# Calcula el logaritmo de los ratios para todos los términos\n",
        "## Inserta tu código aqui\n",
        "for term, cnt in list(pos_neg_ratios.most_common()):\n",
        "    pos_neg_ratios[term] = np.log(cnt) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nelsu3orhrz_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('edie', 4.6913478822291435),\n",
              " ('paulie', 4.07753744390572),\n",
              " ('felix', 3.152736022363656),\n",
              " ('polanski', 2.8233610476132043),\n",
              " ('matthau', 2.80672172860924),\n",
              " ('victoria', 2.681021528714291),\n",
              " ('mildred', 2.6026896854443837),\n",
              " ('gandhi', 2.538973871058276),\n",
              " ('flawless', 2.451005098112319),\n",
              " ('superbly', 2.26002547857525),\n",
              " ('perfection', 2.159484249353372),\n",
              " ('astaire', 2.1400661634962708),\n",
              " ('captures', 2.038619547159581),\n",
              " ('voight', 2.030170492673053),\n",
              " ('wonderfully', 2.0218960560332353)]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_neg_ratios.most_common(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ac4dUOgEhnML"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pos-to-neg ratio for 'the' = 0.05902269426102881\n",
            "Pos-to-neg ratio for 'amazing' = 1.3919815802404802\n",
            "Pos-to-neg ratio for 'terrible' = -1.7291085042663878\n"
          ]
        }
      ],
      "source": [
        "## Algunos ejemplos que nos ayudan a interpretar los resultados\n",
        "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
        "print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\n",
        "print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "BuwnIl_Wh8e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('boll', -4.969813299576001),\n",
              " ('uwe', -4.624972813284271),\n",
              " ('seagal', -3.644143560272545),\n",
              " ('unwatchable', -3.258096538021482),\n",
              " ('stinker', -3.2088254890146994),\n",
              " ('mst', -2.9502698994772336),\n",
              " ('incoherent', -2.9368917735310576),\n",
              " ('unfunny', -2.6922395950755678),\n",
              " ('waste', -2.6193845640165536),\n",
              " ('blah', -2.5704288232261625),\n",
              " ('horrid', -2.4849066497880004),\n",
              " ('pointless', -2.4553061800117097),\n",
              " ('atrocious', -2.4259083090260445),\n",
              " ('redeeming', -2.3682390632154826),\n",
              " ('prom', -2.3608540011180215),\n",
              " ('drivel', -2.3470368555648795),\n",
              " ('lousy', -2.307572634505085),\n",
              " ('worst', -2.286987896180378),\n",
              " ('laughable', -2.264363880173848),\n",
              " ('awful', -2.227194247027435),\n",
              " ('poorly', -2.2207550747464135),\n",
              " ('wasting', -2.204604684633842),\n",
              " ('remotely', -2.1972245773362196),\n",
              " ('existent', -2.0794415416798357),\n",
              " ('boredom', -1.995100393246085),\n",
              " ('miserably', -1.9924301646902063),\n",
              " ('sucks', -1.987068221548821),\n",
              " ('uninspired', -1.9832976811269336),\n",
              " ('lame', -1.981767458946166),\n",
              " ('insult', -1.978345424808467)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_neg_ratios.most_common()[:-31:-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hdAIKBvJEKa"
      },
      "source": [
        "### 5. Modelo de clasificación basado en bag of words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD8mLKkKJOaL"
      },
      "source": [
        "Vamos a aplicar la técnica de bag of words paso a paso a cada una de las críticas con el objetivo de convertirlas en vectores numéricos que sirvan de features de nuestro modelo.\n",
        "\n",
        "#### Primer paso: construir el conjunto de palabras de nuestro vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XbWDpvonhp7n"
      },
      "outputs": [],
      "source": [
        "vocab = set(total_counts.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ASu4GwbSJt_u"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "74074"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size = len(vocab)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeneoUAXKRe5"
      },
      "source": [
        "#### Segundo paso: construímos un vector del tamaño de nuestro vocabulario. Para ganar tiempo lo creamos como un vector entero de 0s usando la función de numpy zeros()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "re4cRsBcJy9L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "zeros = np.zeros(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FwlXPMQUKMSp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-wjmc3TKl7n"
      },
      "source": [
        "#### Tercer paso: asignar a cada palabra un índice del vector y crear una tabla maestra que guarde esta relación y nos permita crear fácilmente nuestros vectores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WyTGXExmKOto"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'': 0,\n",
              " 'doubly': 1,\n",
              " 'converge': 2,\n",
              " 'tunnel': 3,\n",
              " 'roemheld': 4,\n",
              " 'warlike': 5,\n",
              " 'hool': 6,\n",
              " 'forefathers': 7,\n",
              " 'proposing': 8,\n",
              " 'defunct': 9,\n",
              " 'perverse': 10,\n",
              " 'wazoo': 11,\n",
              " 'menagerie': 12,\n",
              " 'grody': 13,\n",
              " 'delaware': 14,\n",
              " 'disassociative': 15,\n",
              " 'restoration': 16,\n",
              " 'konishita': 17,\n",
              " 'spotlights': 18,\n",
              " 'enyclopedia': 19,\n",
              " 'hill': 20,\n",
              " 'recalled': 21,\n",
              " 'cloth': 22,\n",
              " 'hares': 23,\n",
              " 'conclusiondirector': 24,\n",
              " 'grounding': 25,\n",
              " 'pheasant': 26,\n",
              " 'newsreel': 27,\n",
              " 'galton': 28,\n",
              " 'oodishon': 29,\n",
              " 'kairo': 30,\n",
              " 'kho': 31,\n",
              " 'slave': 32,\n",
              " 'homeless': 33,\n",
              " 'wowsers': 34,\n",
              " 'hoss': 35,\n",
              " 'jutta': 36,\n",
              " 'creaks': 37,\n",
              " 'neagle': 38,\n",
              " 'techno': 39,\n",
              " 'sandbox': 40,\n",
              " 'absolutey': 41,\n",
              " 'complaint': 42,\n",
              " 'cherri': 43,\n",
              " 'oiks': 44,\n",
              " 'tugged': 45,\n",
              " 'digby': 46,\n",
              " 'morvern': 47,\n",
              " 'bingham': 48,\n",
              " 'sargeants': 49,\n",
              " 'larky': 50,\n",
              " 'therethat': 51,\n",
              " 'healthy': 52,\n",
              " 'survives': 53,\n",
              " 'shabby': 54,\n",
              " 'harpy': 55,\n",
              " 'steady': 56,\n",
              " 'horor': 57,\n",
              " 'underlies': 58,\n",
              " 'locating': 59,\n",
              " 'katzelmacher': 60,\n",
              " 'lovableness': 61,\n",
              " 'blameless': 62,\n",
              " 'wai': 63,\n",
              " 'efrem': 64,\n",
              " 'textual': 65,\n",
              " 'grievances': 66,\n",
              " 'kensit': 67,\n",
              " 'importantly': 68,\n",
              " 'clanging': 69,\n",
              " 'dinsdale': 70,\n",
              " 'defer': 71,\n",
              " 'sauna': 72,\n",
              " 'sherriff': 73,\n",
              " 'phoned': 74,\n",
              " 'popularising': 75,\n",
              " 'jeanson': 76,\n",
              " 'trice': 77,\n",
              " 'trickster': 78,\n",
              " 'smouldered': 79,\n",
              " 'billys': 80,\n",
              " 'sponsors': 81,\n",
              " 'voorhees': 82,\n",
              " 'kai': 83,\n",
              " 'jonatha': 84,\n",
              " 'spring': 85,\n",
              " 'sending': 86,\n",
              " 'ajeeb': 87,\n",
              " 'adventist': 88,\n",
              " 'knuckleface': 89,\n",
              " 'gower': 90,\n",
              " 'analogies': 91,\n",
              " 'interpreter': 92,\n",
              " 'tampons': 93,\n",
              " 'relentlessly': 94,\n",
              " 'sporks': 95,\n",
              " 'stagestruck': 96,\n",
              " 'saffron': 97,\n",
              " 'besant': 98,\n",
              " 'brethren': 99,\n",
              " 'fobh': 100,\n",
              " 'yewbenighted': 101,\n",
              " 'manuscript': 102,\n",
              " 'wont': 103,\n",
              " 'rajendranath': 104,\n",
              " 'dts': 105,\n",
              " 'mixture': 106,\n",
              " 'nominating': 107,\n",
              " 'ni': 108,\n",
              " 'valise': 109,\n",
              " 'bullwinkle': 110,\n",
              " 'visconti': 111,\n",
              " 'fugitives': 112,\n",
              " 'dou': 113,\n",
              " 'spanjers': 114,\n",
              " 'oil': 115,\n",
              " 'flacks': 116,\n",
              " 'unlooked': 117,\n",
              " 'pacingly': 118,\n",
              " 'lunchmeat': 119,\n",
              " 'inadvertantly': 120,\n",
              " 'dirtying': 121,\n",
              " 'tighten': 122,\n",
              " 'encounter': 123,\n",
              " 'flemish': 124,\n",
              " 'sympathizing': 125,\n",
              " 'unawkward': 126,\n",
              " 'clinched': 127,\n",
              " 'nightmares': 128,\n",
              " 'hallways': 129,\n",
              " 'dashing': 130,\n",
              " 'matekoni': 131,\n",
              " 'newer': 132,\n",
              " 'woohoo': 133,\n",
              " 'proliferating': 134,\n",
              " 'simultaneous': 135,\n",
              " 'protgs': 136,\n",
              " 'penitentiaries': 137,\n",
              " 'backstreets': 138,\n",
              " 'evacuee': 139,\n",
              " 'sadly': 140,\n",
              " 'cream': 141,\n",
              " 'sisyphean': 142,\n",
              " 'broad': 143,\n",
              " 'revitalize': 144,\n",
              " 'blazers': 145,\n",
              " 'magnates': 146,\n",
              " 'sanctimoniousness': 147,\n",
              " 'caas': 148,\n",
              " 'remoteness': 149,\n",
              " 'facetious': 150,\n",
              " 'jellybeans': 151,\n",
              " 'commencement': 152,\n",
              " 'simplistically': 153,\n",
              " 'critters': 154,\n",
              " 'tinge': 155,\n",
              " 'pennelope': 156,\n",
              " 'levens': 157,\n",
              " 'avail': 158,\n",
              " 'boomerangs': 159,\n",
              " 'jester': 160,\n",
              " 'rodrigo': 161,\n",
              " 'gratuitously': 162,\n",
              " 'neo': 163,\n",
              " 'retired': 164,\n",
              " 'fell': 165,\n",
              " 'morena': 166,\n",
              " 'perico': 167,\n",
              " 'beachcomber': 168,\n",
              " 'ambivalent': 169,\n",
              " 'opprobrium': 170,\n",
              " 'eamonn': 171,\n",
              " 'drexler': 172,\n",
              " 'garda': 173,\n",
              " 'schotland': 174,\n",
              " 'bodhisattva': 175,\n",
              " 'boooring': 176,\n",
              " 'savales': 177,\n",
              " 'tremblay': 178,\n",
              " 'youngberries': 179,\n",
              " 'unstructured': 180,\n",
              " 'randon': 181,\n",
              " 'martian': 182,\n",
              " 'drifted': 183,\n",
              " 'overthrows': 184,\n",
              " 'nothan': 185,\n",
              " 'glancing': 186,\n",
              " 'corkscrew': 187,\n",
              " 'defective': 188,\n",
              " 'einsteins': 189,\n",
              " 'priyanka': 190,\n",
              " 'hullabaloo': 191,\n",
              " 'jj': 192,\n",
              " 'industrious': 193,\n",
              " 'allover': 194,\n",
              " 'praised': 195,\n",
              " 'thicket': 196,\n",
              " 'locataire': 197,\n",
              " 'tanny': 198,\n",
              " 'bernsen': 199,\n",
              " 'regurgitating': 200,\n",
              " 'tourette': 201,\n",
              " 'feldman': 202,\n",
              " 'jia': 203,\n",
              " 'usage': 204,\n",
              " 'guardians': 205,\n",
              " 'iambic': 206,\n",
              " 'lopped': 207,\n",
              " 'flirtations': 208,\n",
              " 'corrective': 209,\n",
              " 'rolly': 210,\n",
              " 'calil': 211,\n",
              " 'loans': 212,\n",
              " 'suicida': 213,\n",
              " 'calculatingly': 214,\n",
              " 'kei': 215,\n",
              " 'motocross': 216,\n",
              " 'scotches': 217,\n",
              " 'scapes': 218,\n",
              " 'stowe': 219,\n",
              " 'whizzpopping': 220,\n",
              " 'cmmandments': 221,\n",
              " 'caribbeans': 222,\n",
              " 'saran': 223,\n",
              " 'piero': 224,\n",
              " 'racism': 225,\n",
              " 'merge': 226,\n",
              " 'stayed': 227,\n",
              " 'oakland': 228,\n",
              " 'eradicator': 229,\n",
              " 'walston': 230,\n",
              " 'donate': 231,\n",
              " 'woooooow': 232,\n",
              " 'friedberg': 233,\n",
              " 'collaborating': 234,\n",
              " 'confuddled': 235,\n",
              " 'scolds': 236,\n",
              " 'torchon': 237,\n",
              " 'enslin': 238,\n",
              " 'complicatedness': 239,\n",
              " 'assigning': 240,\n",
              " 'chonopolisians': 241,\n",
              " 'beijing': 242,\n",
              " 'sedation': 243,\n",
              " 'uprightness': 244,\n",
              " 'tablet': 245,\n",
              " 'grind': 246,\n",
              " 'huhuhuhuhu': 247,\n",
              " 'inserts': 248,\n",
              " 'bimbos': 249,\n",
              " 'coherence': 250,\n",
              " 'festival': 251,\n",
              " 'sexed': 252,\n",
              " 'grabovsky': 253,\n",
              " 'holmies': 254,\n",
              " 'sailor': 255,\n",
              " 'mangeshkar': 256,\n",
              " 'devoted': 257,\n",
              " 'flushed': 258,\n",
              " 'congregates': 259,\n",
              " 'macarthur': 260,\n",
              " 'burst': 261,\n",
              " 'parter': 262,\n",
              " 'luque': 263,\n",
              " 'audry': 264,\n",
              " 'broadcasted': 265,\n",
              " 'sloggy': 266,\n",
              " 'gapes': 267,\n",
              " 'askeys': 268,\n",
              " 'derides': 269,\n",
              " 'snickersnicker': 270,\n",
              " 'gazillion': 271,\n",
              " 'ornella': 272,\n",
              " 'undertakers': 273,\n",
              " 'imbreds': 274,\n",
              " 'chronologically': 275,\n",
              " 'plumped': 276,\n",
              " 'grades': 277,\n",
              " 'redhead': 278,\n",
              " 'michiko': 279,\n",
              " 'toon': 280,\n",
              " 'froze': 281,\n",
              " 'mockable': 282,\n",
              " 'sentimentalized': 283,\n",
              " 'olathe': 284,\n",
              " 'commentator': 285,\n",
              " 'sociopathy': 286,\n",
              " 'labs': 287,\n",
              " 'nyaako': 288,\n",
              " 'hoodwinked': 289,\n",
              " 'necklines': 290,\n",
              " 'bruhls': 291,\n",
              " 'favourites': 292,\n",
              " 'smalltalk': 293,\n",
              " 'approxiamtely': 294,\n",
              " 'frobe': 295,\n",
              " 'breathnach': 296,\n",
              " 'billingham': 297,\n",
              " 'tight': 298,\n",
              " 'gretchen': 299,\n",
              " 'dereliction': 300,\n",
              " 'brave': 301,\n",
              " 'nympho': 302,\n",
              " 'saugages': 303,\n",
              " 'concussive': 304,\n",
              " 'crucial': 305,\n",
              " 'undertakings': 306,\n",
              " 'mongkut': 307,\n",
              " 'murmur': 308,\n",
              " 'boobless': 309,\n",
              " 'uncomfortable': 310,\n",
              " 'brazilian': 311,\n",
              " 'busying': 312,\n",
              " 'gacy': 313,\n",
              " 'glosses': 314,\n",
              " 'mange': 315,\n",
              " 'conti': 316,\n",
              " 'zaz': 317,\n",
              " 'yuzna': 318,\n",
              " 'lumbered': 319,\n",
              " 'amg': 320,\n",
              " 'explosive': 321,\n",
              " 'gto': 322,\n",
              " 'feinstone': 323,\n",
              " 'obese': 324,\n",
              " 'chans': 325,\n",
              " 'vestment': 326,\n",
              " 'denero': 327,\n",
              " 'vivacious': 328,\n",
              " 'trotta': 329,\n",
              " 'discoverer': 330,\n",
              " 'refracting': 331,\n",
              " 'coordinator': 332,\n",
              " 'incredibility': 333,\n",
              " 'santorini': 334,\n",
              " 'poseidon': 335,\n",
              " 'groups': 336,\n",
              " 'spotters': 337,\n",
              " 'slr': 338,\n",
              " 'furie': 339,\n",
              " 'proleteriat': 340,\n",
              " 'affirmative': 341,\n",
              " 'hearse': 342,\n",
              " 'miscommunication': 343,\n",
              " 'onrunning': 344,\n",
              " 'scootin': 345,\n",
              " 'drunken': 346,\n",
              " 'flossing': 347,\n",
              " 'boredome': 348,\n",
              " 'ardent': 349,\n",
              " 'dea': 350,\n",
              " 'moneymaker': 351,\n",
              " 'glommed': 352,\n",
              " 'spectecular': 353,\n",
              " 'prometheus': 354,\n",
              " 'unprovokedly': 355,\n",
              " 'kaiju': 356,\n",
              " 'alissia': 357,\n",
              " 'unfocused': 358,\n",
              " 'matey': 359,\n",
              " 'nakano': 360,\n",
              " 'callahan': 361,\n",
              " 'forbidding': 362,\n",
              " 'deedy': 363,\n",
              " 'goldenhagen': 364,\n",
              " 'catweazle': 365,\n",
              " 'postman': 366,\n",
              " 'shook': 367,\n",
              " 'warholian': 368,\n",
              " 'superaction': 369,\n",
              " 'zoheb': 370,\n",
              " 'hurled': 371,\n",
              " 'fichtner': 372,\n",
              " 'expansiveness': 373,\n",
              " 'acrobat': 374,\n",
              " 'purification': 375,\n",
              " 'ericco': 376,\n",
              " 'ato': 377,\n",
              " 'chim': 378,\n",
              " 'shank': 379,\n",
              " 'followings': 380,\n",
              " 'aragorns': 381,\n",
              " 'refine': 382,\n",
              " 'vue': 383,\n",
              " 'smalltime': 384,\n",
              " 'anterior': 385,\n",
              " 'seeing': 386,\n",
              " 'moons': 387,\n",
              " 'muppet': 388,\n",
              " 'deniz': 389,\n",
              " 'loved': 390,\n",
              " 'mar': 391,\n",
              " 'juveniles': 392,\n",
              " 'knuckling': 393,\n",
              " 'rightfully': 394,\n",
              " 'aphrodisiac': 395,\n",
              " 'tray': 396,\n",
              " 'crews': 397,\n",
              " 'yaniss': 398,\n",
              " 'drinking': 399,\n",
              " 'yogi': 400,\n",
              " 'zowee': 401,\n",
              " 'excitied': 402,\n",
              " 'glaudini': 403,\n",
              " 'purged': 404,\n",
              " 'th': 405,\n",
              " 'laurens': 406,\n",
              " 'villasenor': 407,\n",
              " 'ingenuos': 408,\n",
              " 'reese': 409,\n",
              " 'midwinter': 410,\n",
              " 'chia': 411,\n",
              " 'boardroom': 412,\n",
              " 'biosphere': 413,\n",
              " 'quadraphenia': 414,\n",
              " 'ryonosuke': 415,\n",
              " 'spender': 416,\n",
              " 'augmenting': 417,\n",
              " 'throwaways': 418,\n",
              " 'mt': 419,\n",
              " 'sides': 420,\n",
              " 'purdom': 421,\n",
              " 'visuals': 422,\n",
              " 'volition': 423,\n",
              " 'safans': 424,\n",
              " 'aluminum': 425,\n",
              " 'piere': 426,\n",
              " 'tribulations': 427,\n",
              " 'dinero': 428,\n",
              " 'demonstrator': 429,\n",
              " 'fray': 430,\n",
              " 'outgrown': 431,\n",
              " 'spatula': 432,\n",
              " 'drink': 433,\n",
              " 'squelched': 434,\n",
              " 'shadings': 435,\n",
              " 'kingdoms': 436,\n",
              " 'thapar': 437,\n",
              " 'westerberg': 438,\n",
              " 'eagles': 439,\n",
              " 'waldau': 440,\n",
              " 'upswing': 441,\n",
              " 'sheila': 442,\n",
              " 'ac': 443,\n",
              " 'unglamorous': 444,\n",
              " 'apricorn': 445,\n",
              " 'stuffiness': 446,\n",
              " 'jobbers': 447,\n",
              " 'juniors': 448,\n",
              " 'arbanville': 449,\n",
              " 'ronin': 450,\n",
              " 'witless': 451,\n",
              " 'cero': 452,\n",
              " 'pussed': 453,\n",
              " 'granite': 454,\n",
              " 'commiserations': 455,\n",
              " 'belaboured': 456,\n",
              " 'liquidators': 457,\n",
              " 'harrowingly': 458,\n",
              " 'supersoftie': 459,\n",
              " 'fanatically': 460,\n",
              " 'prospers': 461,\n",
              " 'reece': 462,\n",
              " 'megahy': 463,\n",
              " 'reverently': 464,\n",
              " 'woolsey': 465,\n",
              " 'duncan': 466,\n",
              " 'delegate': 467,\n",
              " 'spinell': 468,\n",
              " 'sympathizer': 469,\n",
              " 'goodliffe': 470,\n",
              " 'venerated': 471,\n",
              " 'naidu': 472,\n",
              " 'lick': 473,\n",
              " 'remus': 474,\n",
              " 'syberia': 475,\n",
              " 'bettany': 476,\n",
              " 'missile': 477,\n",
              " 'athena': 478,\n",
              " 'bood': 479,\n",
              " 'yosimite': 480,\n",
              " 'diplomats': 481,\n",
              " 'unevitable': 482,\n",
              " 'afflicted': 483,\n",
              " 'charasmatic': 484,\n",
              " 'stuns': 485,\n",
              " 'squirmy': 486,\n",
              " 'rona': 487,\n",
              " 'fluidity': 488,\n",
              " 'flunk': 489,\n",
              " 'btw': 490,\n",
              " 'practices': 491,\n",
              " 'gnome': 492,\n",
              " 'brooklynese': 493,\n",
              " 'mildewing': 494,\n",
              " 'atlantians': 495,\n",
              " 'plastecine': 496,\n",
              " 'kubricks': 497,\n",
              " 'narrowing': 498,\n",
              " 'donohoe': 499,\n",
              " 'vibrant': 500,\n",
              " 'slake': 501,\n",
              " 'lszl': 502,\n",
              " 'pacte': 503,\n",
              " 'trenchcoat': 504,\n",
              " 'beal': 505,\n",
              " 'occupants': 506,\n",
              " 'sky': 507,\n",
              " 'welfare': 508,\n",
              " 'ol': 509,\n",
              " 'cornball': 510,\n",
              " 'putain': 511,\n",
              " 'riot': 512,\n",
              " 'brillant': 513,\n",
              " 'napa': 514,\n",
              " 'batperson': 515,\n",
              " 'nicklodeon': 516,\n",
              " 'normal': 517,\n",
              " 'annivesery': 518,\n",
              " 'sumerel': 519,\n",
              " 'murkwood': 520,\n",
              " 'intellectually': 521,\n",
              " 'farkus': 522,\n",
              " 'nosey': 523,\n",
              " 'heading': 524,\n",
              " 'ultraviolence': 525,\n",
              " 'bagatelle': 526,\n",
              " 'massacessi': 527,\n",
              " 'instinct': 528,\n",
              " 'unnerve': 529,\n",
              " 'programme': 530,\n",
              " 'polluted': 531,\n",
              " 'toffs': 532,\n",
              " 'vallee': 533,\n",
              " 'pouches': 534,\n",
              " 'drivin': 535,\n",
              " 'petaluma': 536,\n",
              " 'bakvaas': 537,\n",
              " 'endangered': 538,\n",
              " 'trampling': 539,\n",
              " 'expositional': 540,\n",
              " 'validation': 541,\n",
              " 'tuff': 542,\n",
              " 'wasteful': 543,\n",
              " 'downplays': 544,\n",
              " 'durant': 545,\n",
              " 'gamin': 546,\n",
              " 'celoron': 547,\n",
              " 'dentures': 548,\n",
              " 'tropical': 549,\n",
              " 'poppingly': 550,\n",
              " 'synacures': 551,\n",
              " 'misadventure': 552,\n",
              " 'yun': 553,\n",
              " 'altro': 554,\n",
              " 'zaroffs': 555,\n",
              " 'pes': 556,\n",
              " 'winifred': 557,\n",
              " 'shlater': 558,\n",
              " 'yung': 559,\n",
              " 'patten': 560,\n",
              " 'highjinks': 561,\n",
              " 'gunason': 562,\n",
              " 'fur': 563,\n",
              " 'seussical': 564,\n",
              " 'exercises': 565,\n",
              " 'euphues': 566,\n",
              " 'illustrates': 567,\n",
              " 'wed': 568,\n",
              " 'parry': 569,\n",
              " 'bowersock': 570,\n",
              " 'marti': 571,\n",
              " 'scriptors': 572,\n",
              " 'pronto': 573,\n",
              " 'cigars': 574,\n",
              " 'surpassed': 575,\n",
              " 'religions': 576,\n",
              " 'luke': 577,\n",
              " 'scandinavian': 578,\n",
              " 'brinke': 579,\n",
              " 'megaphone': 580,\n",
              " 'capitulation': 581,\n",
              " 'lazslo': 582,\n",
              " 'lr': 583,\n",
              " 'despite': 584,\n",
              " 'epidemiologist': 585,\n",
              " 'sanguisga': 586,\n",
              " 'chumps': 587,\n",
              " 'taffy': 588,\n",
              " 'lea': 589,\n",
              " 'jewry': 590,\n",
              " 'yesterdays': 591,\n",
              " 'harbour': 592,\n",
              " 'boober': 593,\n",
              " 'offshoots': 594,\n",
              " 'expresssions': 595,\n",
              " 'goldies': 596,\n",
              " 'encyclicals': 597,\n",
              " 'criteria': 598,\n",
              " 'ul': 599,\n",
              " 'reparation': 600,\n",
              " 'dab': 601,\n",
              " 'antagonized': 602,\n",
              " 'inspector': 603,\n",
              " 'mindhunters': 604,\n",
              " 'incensere': 605,\n",
              " 'aback': 606,\n",
              " 'hulme': 607,\n",
              " 'talinn': 608,\n",
              " 'brakeman': 609,\n",
              " 'margaux': 610,\n",
              " 'burdening': 611,\n",
              " 'beheadings': 612,\n",
              " 'unpredictability': 613,\n",
              " 'clastrophobic': 614,\n",
              " 'distanced': 615,\n",
              " 'vil': 616,\n",
              " 'olin': 617,\n",
              " 'supervillains': 618,\n",
              " 'electromagnetic': 619,\n",
              " 'spliff': 620,\n",
              " 'huze': 621,\n",
              " 'zzzzzzzzzzzzz': 622,\n",
              " 'shockingly': 623,\n",
              " 'restore': 624,\n",
              " 'bothering': 625,\n",
              " 'vette': 626,\n",
              " 'networking': 627,\n",
              " 'insues': 628,\n",
              " 'appearences': 629,\n",
              " 'atlantica': 630,\n",
              " 'humorof': 631,\n",
              " 'bombings': 632,\n",
              " 'pink': 633,\n",
              " 'slobbery': 634,\n",
              " 'bucketful': 635,\n",
              " 'dry': 636,\n",
              " 'altering': 637,\n",
              " 'valjean': 638,\n",
              " 'ssp': 639,\n",
              " 'impelled': 640,\n",
              " 'itv': 641,\n",
              " 'plagiarism': 642,\n",
              " 'larue': 643,\n",
              " 'yugoslavian': 644,\n",
              " 'mulls': 645,\n",
              " 'burglars': 646,\n",
              " 'expire': 647,\n",
              " 'congress': 648,\n",
              " 'individual': 649,\n",
              " 'lagaan': 650,\n",
              " 'difficult': 651,\n",
              " 'fkin': 652,\n",
              " 'gretel': 653,\n",
              " 'preamble': 654,\n",
              " 'traffic': 655,\n",
              " 'walk': 656,\n",
              " 'veracity': 657,\n",
              " 'pnc': 658,\n",
              " 'comic': 659,\n",
              " 'sinus': 660,\n",
              " 'viru': 661,\n",
              " 'resourcefully': 662,\n",
              " 'bookworm': 663,\n",
              " 'percussionist': 664,\n",
              " 'belabored': 665,\n",
              " 'irreplaceable': 666,\n",
              " 'repossessed': 667,\n",
              " 'commonplace': 668,\n",
              " 'lowe': 669,\n",
              " 'unpredictably': 670,\n",
              " 'prerequisite': 671,\n",
              " 'stringy': 672,\n",
              " 'fairuza': 673,\n",
              " 'irrefutably': 674,\n",
              " 'nightfall': 675,\n",
              " 'butterick': 676,\n",
              " 'iscariot': 677,\n",
              " 'windu': 678,\n",
              " 'falklands': 679,\n",
              " 'jabs': 680,\n",
              " 'physique': 681,\n",
              " 'unmercilessly': 682,\n",
              " 'domineers': 683,\n",
              " 'vicadin': 684,\n",
              " 'ustr': 685,\n",
              " 'stellar': 686,\n",
              " 'intercoms': 687,\n",
              " 'mold': 688,\n",
              " 'insure': 689,\n",
              " 'wacthing': 690,\n",
              " 'computerized': 691,\n",
              " 'catalua': 692,\n",
              " 'generalities': 693,\n",
              " 'egm': 694,\n",
              " 'lambert': 695,\n",
              " 'propelling': 696,\n",
              " 'blackberry': 697,\n",
              " 'centralized': 698,\n",
              " 'freq': 699,\n",
              " 'reprise': 700,\n",
              " 'smoochy': 701,\n",
              " 'entities': 702,\n",
              " 'yog': 703,\n",
              " 'freeway': 704,\n",
              " 'jarome': 705,\n",
              " 'nigel': 706,\n",
              " 'vs': 707,\n",
              " 'bedelia': 708,\n",
              " 'fallwell': 709,\n",
              " 'overshoots': 710,\n",
              " 'happend': 711,\n",
              " 'madcap': 712,\n",
              " 'deray': 713,\n",
              " 'cravens': 714,\n",
              " 'falsetto': 715,\n",
              " 'minbari': 716,\n",
              " 'spectacled': 717,\n",
              " 'neuro': 718,\n",
              " 'townships': 719,\n",
              " 'unlawful': 720,\n",
              " 'bankcrupcy': 721,\n",
              " 'krivtsov': 722,\n",
              " 'clampets': 723,\n",
              " 'miracolo': 724,\n",
              " 'schapelle': 725,\n",
              " 'norwegia': 726,\n",
              " 'transpires': 727,\n",
              " 'menczer': 728,\n",
              " 'tono': 729,\n",
              " 'steadier': 730,\n",
              " 'redid': 731,\n",
              " 'sluty': 732,\n",
              " 'balaclava': 733,\n",
              " 'danzel': 734,\n",
              " 'humongous': 735,\n",
              " 'glitz': 736,\n",
              " 'impatient': 737,\n",
              " 'garia': 738,\n",
              " 'ghostlike': 739,\n",
              " 'leah': 740,\n",
              " 'fatale': 741,\n",
              " 'prepares': 742,\n",
              " 'intercourse': 743,\n",
              " 'imaginegay': 744,\n",
              " 'stubborn': 745,\n",
              " 'enforces': 746,\n",
              " 'animosity': 747,\n",
              " 'reset': 748,\n",
              " 'einstien': 749,\n",
              " 'dove': 750,\n",
              " 'peary': 751,\n",
              " 'competitors': 752,\n",
              " 'parodies': 753,\n",
              " 'akim': 754,\n",
              " 'hyun': 755,\n",
              " 'spotter': 756,\n",
              " 'pdf': 757,\n",
              " 'shellie': 758,\n",
              " 'spatulamadness': 759,\n",
              " 'maclagan': 760,\n",
              " 'dirs': 761,\n",
              " 'advani': 762,\n",
              " 'thresholds': 763,\n",
              " 'coopers': 764,\n",
              " 'stalely': 765,\n",
              " 'wv': 766,\n",
              " 'trademarks': 767,\n",
              " 'brocksmith': 768,\n",
              " 'papal': 769,\n",
              " 'aftertaste': 770,\n",
              " 'grumbling': 771,\n",
              " 'april': 772,\n",
              " 'pressure': 773,\n",
              " 'strengthened': 774,\n",
              " 'jovic': 775,\n",
              " 'argonautica': 776,\n",
              " 'confiscation': 777,\n",
              " 'emphysema': 778,\n",
              " 'margarete': 779,\n",
              " 'spoilerokay': 780,\n",
              " 'cutaways': 781,\n",
              " 'unimpressed': 782,\n",
              " 'baccarat': 783,\n",
              " 'vilification': 784,\n",
              " 'transcription': 785,\n",
              " 'kliches': 786,\n",
              " 'braved': 787,\n",
              " 'villiers': 788,\n",
              " 'sloppiness': 789,\n",
              " 'answeryou': 790,\n",
              " 'gojoe': 791,\n",
              " 'plunges': 792,\n",
              " 'giannini': 793,\n",
              " 'courses': 794,\n",
              " 'otter': 795,\n",
              " 'banged': 796,\n",
              " 'breakup': 797,\n",
              " 'divagations': 798,\n",
              " 'goldworthy': 799,\n",
              " 'committal': 800,\n",
              " 'gona': 801,\n",
              " 'comforted': 802,\n",
              " 'ladty': 803,\n",
              " 'laverne': 804,\n",
              " 'salvage': 805,\n",
              " 'obedience': 806,\n",
              " 'conductors': 807,\n",
              " 'aditiya': 808,\n",
              " 'jockhood': 809,\n",
              " 'floundered': 810,\n",
              " 'conjure': 811,\n",
              " 'burgermister': 812,\n",
              " 'comedown': 813,\n",
              " 'paring': 814,\n",
              " 'befalls': 815,\n",
              " 'leanings': 816,\n",
              " 'kallio': 817,\n",
              " 'bruise': 818,\n",
              " 'estrangement': 819,\n",
              " 'beng': 820,\n",
              " 'excursus': 821,\n",
              " 'bryans': 822,\n",
              " 'dudleys': 823,\n",
              " 'virgnina': 824,\n",
              " 'pickford': 825,\n",
              " 'soha': 826,\n",
              " 'testifies': 827,\n",
              " 'shizophrenic': 828,\n",
              " 'flexes': 829,\n",
              " 'swiri': 830,\n",
              " 'courtrooms': 831,\n",
              " 'shoddiest': 832,\n",
              " 'ralf': 833,\n",
              " 'leonel': 834,\n",
              " 'symona': 835,\n",
              " 'breuer': 836,\n",
              " 'cavern': 837,\n",
              " 'chasers': 838,\n",
              " 'crown': 839,\n",
              " 'scrimping': 840,\n",
              " 'apologise': 841,\n",
              " 'mongoloid': 842,\n",
              " 'zvezda': 843,\n",
              " 'interjection': 844,\n",
              " 'supercilious': 845,\n",
              " 'lake': 846,\n",
              " 'bonuses': 847,\n",
              " 'ruminations': 848,\n",
              " 'answer': 849,\n",
              " 'reals': 850,\n",
              " 'clench': 851,\n",
              " 'artworks': 852,\n",
              " 'oja': 853,\n",
              " 'daag': 854,\n",
              " 'quipped': 855,\n",
              " 'krisak': 856,\n",
              " 'zealnd': 857,\n",
              " 'tuesdays': 858,\n",
              " 'tamahori': 859,\n",
              " 'dang': 860,\n",
              " 'lions': 861,\n",
              " 'greenman': 862,\n",
              " 'engine': 863,\n",
              " 'enthusiastically': 864,\n",
              " 'wildside': 865,\n",
              " 'scours': 866,\n",
              " 'affable': 867,\n",
              " 'fuckups': 868,\n",
              " 'encountering': 869,\n",
              " 'rycart': 870,\n",
              " 'abduct': 871,\n",
              " 'jamesbondish': 872,\n",
              " 'regenerative': 873,\n",
              " 'riddick': 874,\n",
              " 'nelligan': 875,\n",
              " 'coulter': 876,\n",
              " 'convince': 877,\n",
              " 'plumage': 878,\n",
              " 'wisetake': 879,\n",
              " 'mutilation': 880,\n",
              " 'characterised': 881,\n",
              " 'lsd': 882,\n",
              " 'dedicates': 883,\n",
              " 'macnee': 884,\n",
              " 'yousef': 885,\n",
              " 'bipartisanism': 886,\n",
              " 'maitland': 887,\n",
              " 'iliada': 888,\n",
              " 'afford': 889,\n",
              " 'residencia': 890,\n",
              " 'polnareff': 891,\n",
              " 'unknown': 892,\n",
              " 'foreignness': 893,\n",
              " 'imputes': 894,\n",
              " 'sealing': 895,\n",
              " 'krypton': 896,\n",
              " 'spiraled': 897,\n",
              " 'intellects': 898,\n",
              " 'musuraca': 899,\n",
              " 'co': 900,\n",
              " 'pleasantly': 901,\n",
              " 'interferring': 902,\n",
              " 'disadvantaged': 903,\n",
              " 'radars': 904,\n",
              " 'justia': 905,\n",
              " 'puzzlingly': 906,\n",
              " 'vanquish': 907,\n",
              " 'prettiest': 908,\n",
              " 'barbeau': 909,\n",
              " 'attaches': 910,\n",
              " 'vary': 911,\n",
              " 'define': 912,\n",
              " 'atmosphereic': 913,\n",
              " 'abstraction': 914,\n",
              " 'hanlon': 915,\n",
              " 'sockets': 916,\n",
              " 'dibiase': 917,\n",
              " 'ambiguity': 918,\n",
              " 'dalmation': 919,\n",
              " 'duduce': 920,\n",
              " 'succeeds': 921,\n",
              " 'zizola': 922,\n",
              " 'plane': 923,\n",
              " 'whinnying': 924,\n",
              " 'respiration': 925,\n",
              " 'sloppily': 926,\n",
              " 'thornfield': 927,\n",
              " 'holmfrid': 928,\n",
              " 'campos': 929,\n",
              " 'jawed': 930,\n",
              " 'gaberial': 931,\n",
              " 'granddaughters': 932,\n",
              " 'execrable': 933,\n",
              " 'bergerac': 934,\n",
              " 'gretta': 935,\n",
              " 'gapers': 936,\n",
              " 'disclaimers': 937,\n",
              " 'bigbossman': 938,\n",
              " 'streeb': 939,\n",
              " 'stablemate': 940,\n",
              " 'infraction': 941,\n",
              " 'disc': 942,\n",
              " 'fincher': 943,\n",
              " 'wine': 944,\n",
              " 'wrights': 945,\n",
              " 'empties': 946,\n",
              " 'preparedness': 947,\n",
              " 'activities': 948,\n",
              " 'pouter': 949,\n",
              " 'wavering': 950,\n",
              " 'gulager': 951,\n",
              " 'shortened': 952,\n",
              " 'crisply': 953,\n",
              " 'vaccaro': 954,\n",
              " 'manipulates': 955,\n",
              " 'gut': 956,\n",
              " 'kashue': 957,\n",
              " 'cabal': 958,\n",
              " 'coronary': 959,\n",
              " 'ballads': 960,\n",
              " 'narasimha': 961,\n",
              " 'quire': 962,\n",
              " 'dedicative': 963,\n",
              " 'rents': 964,\n",
              " 'youssou': 965,\n",
              " 'tashlin': 966,\n",
              " 'mugged': 967,\n",
              " 'penguins': 968,\n",
              " 'olympics': 969,\n",
              " 'mannara': 970,\n",
              " 'gorillas': 971,\n",
              " 'grime': 972,\n",
              " 'utlimately': 973,\n",
              " 'jenner': 974,\n",
              " 'effects': 975,\n",
              " 'scumbags': 976,\n",
              " 'brightly': 977,\n",
              " 'stressing': 978,\n",
              " 'scrooged': 979,\n",
              " 'smg': 980,\n",
              " 'lynley': 981,\n",
              " 'filler': 982,\n",
              " 'teardrop': 983,\n",
              " 'reaffirms': 984,\n",
              " 'nightstick': 985,\n",
              " 'ricardo': 986,\n",
              " 'blurr': 987,\n",
              " 'chesterton': 988,\n",
              " 'denim': 989,\n",
              " 'ninos': 990,\n",
              " 'landes': 991,\n",
              " 'greenness': 992,\n",
              " 'guise': 993,\n",
              " 'eww': 994,\n",
              " 'leno': 995,\n",
              " 'andre': 996,\n",
              " 'rusted': 997,\n",
              " 'fartsy': 998,\n",
              " 'slashings': 999,\n",
              " ...}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creamos un diccionario que tiene como key la palabra y como valor el índice asociado\n",
        "word2index = {}\n",
        "for i,word in enumerate(vocab):\n",
        "    word2index[word] = i\n",
        "    \n",
        "word2index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00djBLcWLe3-"
      },
      "source": [
        "#### Cuarto paso: crear la función que dada una crítica devuelve un vector contando la frecuencia de las palabras utilizadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "9Iov2PNeLEw5"
      },
      "outputs": [],
      "source": [
        "## Rellena la función que para cada crítica devuelve el vector asociado aplicando bag of words\n",
        "def bag_of_words(review):\n",
        "  v = np.zeros(vocab_size)\n",
        "  ## Inserta tu código aquí\n",
        "  for word in review.split(' '):\n",
        "    v[word2index[word]] += 1\n",
        "  return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4uR3jCvuSBrf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   '"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "t2iUM_MeSGkP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word2index['']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "3ASg9r1ga6en"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13982"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word2index[\"bromwell\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "n7BOLYxRMJFL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([18.,  0.,  0., ...,  0.,  0.,  0.])"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bag_of_words(reviews[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "3KDk4iVB21hQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bag_of_words(reviews[0])[13982]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8e-pUBV5ay1t"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(74074,)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bag_of_words(reviews[0]).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zy1Su0ENDzb"
      },
      "source": [
        "#### Quinto paso: el target de nuestro modelo serán 1s y 0s. Vamos a crear una función que convierta los cadenas POSITIVE y NEGATIVE a 1 y 0. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "LUQ52KX3MLfC"
      },
      "outputs": [],
      "source": [
        "## Rellena la función para que dada la etiqueta en forma de cadena devuelve el entero asociado\n",
        "def target_numerico(label):\n",
        "    return int(label == 'POSITIVE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NXFHGGG8Ngf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_numerico(labels[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3socGi2cP_v4"
      },
      "source": [
        "#### Sexto paso: dividimos los datos que tenemos en train y test (esta vez lo hacemos a ojo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Hiy_hHiNQKHV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5000\n",
            "10000\n"
          ]
        }
      ],
      "source": [
        "training_size = 5000\n",
        "test_size = 10000\n",
        "training_rev = reviews[:training_size]\n",
        "training_lab = labels[:training_size]\n",
        "test_rev = reviews[-test_size:]\n",
        "test_lab = labels[-test_size:]\n",
        "print(len(training_lab))\n",
        "print(len(test_lab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wjjnhbmQ2bR"
      },
      "source": [
        "#### Séptimo paso: calculamos las matrices de entrenamiento y de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "5CnlYbNnNkdA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5000, 74074)\n"
          ]
        }
      ],
      "source": [
        "X = np.empty((len(training_rev), vocab_size))\n",
        "print(X.shape)\n",
        "### Rellena X aquí\n",
        "for i in range(len(training_rev)):\n",
        "    X[i] = bag_of_words(training_rev[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "mDfnC2WRVkAA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 74074)\n"
          ]
        }
      ],
      "source": [
        "X_test = np.empty((len(test_rev), vocab_size))\n",
        "print(X_test.shape)\n",
        "for i in range(len(test_rev)):\n",
        "    X_test[i] = bag_of_words(test_rev[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8dRHQFKVPLaB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5000,)\n"
          ]
        }
      ],
      "source": [
        "y = np.empty((len(training_lab),))\n",
        "print(y.shape)\n",
        "# Rellena y aquí\n",
        "\n",
        "for i in range(len(training_rev)):\n",
        "    y[i] = target_numerico(training_lab[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "wQ8H8PfQVuiC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "y_test = np.empty((len(test_lab),))\n",
        "print(y_test.shape)\n",
        "# Rellena y_test aquí\n",
        "\n",
        "for i in range(len(test_lab)):\n",
        "    y_test[i] = target_numerico(test_lab[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BUgNbNaVZQI"
      },
      "source": [
        "#### Octavo paso: entrenamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "418HbjvnS3R6"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "FFw3UoZDTNrz"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = linear_model.LogisticRegression()\n",
        "model.fit(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHbMoVIvVd37"
      },
      "source": [
        "#### Noveno paso: aplicamos el predict sobre el conjunto de test y vemos qué tal funciona."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "4ew7DEftTOnr"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "jz8FOER4VSYf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9988"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5EMDdavGWEs-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8402"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ZTVPXI4TWHvS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[4310  690]\n",
            " [ 908 4092]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_test, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "qGy6v14K-Ovy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.86      0.84      5000\n",
            "         1.0       0.86      0.82      0.84      5000\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1_6xKsU-cOe"
      },
      "source": [
        "#### Decimo paso: preparamos el código para probar el modelo con cadenas nuevas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "Melhwgn7-YVv"
      },
      "outputs": [],
      "source": [
        "# Rellena la función para, dada una crítica, aplicar el modelo que hemos entrenado\n",
        "# e imprimir POSITIVE/NEGATIVE\n",
        "def sentiment_analysis(review):\n",
        "  ## Inserta tu código aqui\n",
        "  vector_input = np.empty((1, vocab_size))\n",
        "  vector_input[0] = bag_of_words(review)\n",
        "  pred = model.predict(vector_input)\n",
        "  if pred == 1:\n",
        "    return 'POSITIVE'\n",
        "  else:\n",
        "    return 'NEGATIVE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "83AM8es9_oNl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'NEGATIVE'"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_analysis('movie bad')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "cVkYqDqC_rLm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words not found:  0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'NEGATIVE'"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_analysis('not horrible')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "Rj8IWCGxAHNZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words not founds:  1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_analysis('España')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oUKhEDkASes"
      },
      "source": [
        "¿Qué hacemos con el error que se obtiene al meter una palabra que no está en el vocabulario? Solucionar este error es parte de la práctica de la asignatura."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "LxIV-DyqAKUF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words not found:  0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_analysis('Cool')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDNO9LHVAp6E"
      },
      "source": [
        "Pero si Cool si es una palabra inglesa. ¿Qué ocurre? ¿Cómo lo solucionamos? Esto también es parte de la práctica de la asignatura. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Práctica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modificaremos la función bag_of_words para que, primero, convierta en minúsculas la review que introducimos y, segundo, añada un condicional que compruebe si existen las palabras de la review en nuestro diccionario. Además, crearemos un contador para imprimir por pantalla cuantas palabras no se encontraban en el diccionario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Rellena la función que para cada crítica devuelve el vector asociado aplicando bag of words\n",
        "def bag_of_words(review):\n",
        "  review = review.lower()\n",
        "  v = np.zeros(vocab_size)\n",
        "  words_not_founds = 0\n",
        "  ## Inserta tu código aquí\n",
        "  for word in review.split(' '):\n",
        "    if word not in word2index:\n",
        "        words_not_founds += 1\n",
        "    else:\n",
        "        v[word2index[word]] += 1\n",
        "  print(f'Words not found:  {words_not_founds}')\n",
        "  return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words not found:  1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_analysis('España')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words not found:  0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_analysis('Cool')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "6 Clasificacion Textos.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
