{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svuzsW-c_Va0"
      },
      "source": [
        "Text Mining - 6. Clasificacion textos\n",
        "\n",
        "AFI - Máster en Data Science y Big Data\n",
        "\n",
        "Juan de Dios Romero Palop\n",
        "\n",
        "Abril 2022\n",
        "\n",
        "Source: Andrew Task, Udacity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5Y0tolWGdIo"
      },
      "source": [
        "### 1. Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eqOmYFCU_caw"
      },
      "outputs": [],
      "source": [
        "## Críticas de películas\n",
        "g = open('../reviews.txt','r') \n",
        "reviews = g.read().splitlines()\n",
        "g.close()\n",
        "\n",
        "## Sentimiento asociado\n",
        "g = open('../labels.txt','r') # What we WANT to know!\n",
        "labels = g.read().upper().splitlines()\n",
        "g.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sCNRyZge_q-S"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m4-aZ98KApvE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers . unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting . even those from the era should be turned off . the cryptic dialogue would make shakespeare seem easy to a third grader . on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond . future stars sally kirkland and frederic forrest can be seen briefly .  '"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_Sp0eh4FAgAm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xsYwZbY8Alu3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'NEGATIVE'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7NnpYsu8b9-9"
      },
      "outputs": [],
      "source": [
        "def pretty_print_review_and_label(i):\n",
        "    print(labels[i] + \"\\t:\\t\" + reviews[i][:80] + \"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2uZIkLHR-658",
        "nbpresent": {
          "id": "e67a709f-234f-4493-bae6-4fb192141ee0"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels.txt \t : \t reviews.txt\n",
            "\n",
            "NEGATIVE\t:\tthis movie is terrible but it has some good effects .  ...\n",
            "POSITIVE\t:\tadrian pasdar is excellent is this film . he makes a fascinating woman .  ...\n",
            "NEGATIVE\t:\tcomment this movie is impossible . is terrible  very improbable  bad interpretat...\n",
            "POSITIVE\t:\texcellent episode movie ala pulp fiction .  days   suicides . it doesnt get more...\n",
            "NEGATIVE\t:\tif you haven  t seen this  it  s terrible . it is pure trash . i saw this about ...\n",
            "POSITIVE\t:\tthis schiffer guy is a real genius  the movie is of excellent quality and both e...\n"
          ]
        }
      ],
      "source": [
        "print(\"labels.txt \\t : \\t reviews.txt\\n\")\n",
        "pretty_print_review_and_label(2137)\n",
        "pretty_print_review_and_label(12816)\n",
        "pretty_print_review_and_label(6267)\n",
        "pretty_print_review_and_label(21934)\n",
        "pretty_print_review_and_label(5297)\n",
        "pretty_print_review_and_label(4998)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLGTusxtGV87"
      },
      "source": [
        "### 2. Análisis cuantitativo términos: ¿Qué términos aparecen en los comentarios positivos, cuales en los negativos y cuales aparecen en ambos?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nlqB8_qn-66C"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M91OwP4ecNyN"
      },
      "source": [
        "Vamos a utilizar la estructura Counter de python para ver cuantas veces aparece cada palabra en las críticas. Debajo tienes un ejemplo de como utilizar un contador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbZsxhiYcvuc"
      },
      "source": [
        "https://docs.python.org/2/library/collections.html#collections.Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "C5zuEETgcXD2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('palabra2', 5), ('palabra1', 3)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ex_count = Counter()\n",
        "ex_count['palabra1'] = 3\n",
        "ex_count['palabra2'] = 5\n",
        "ex_count.most_common()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZrNcZkIpGmT1"
      },
      "outputs": [],
      "source": [
        "# Un contandor para cada tipo de review y uno total\n",
        "positive_counts = Counter()\n",
        "negative_counts = Counter()\n",
        "total_counts = Counter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BbU5hbuzHRQ9"
      },
      "outputs": [],
      "source": [
        "# Crea un bucle que, para cada crítica, recorra sus palabras una a una e incremente en 1 el número de aparaciones.\n",
        "# Aumenta el contador siempre en total_counts y en positive_counts O en negative_counts dependiendo de si es una crítica\n",
        "# positiva o negativa\n",
        "for i in range(len(reviews)):\n",
        "  for word in reviews[i].split(' '):   \n",
        "    if labels[i] == 'NEGATIVE':\n",
        "      negative_counts[word] += 1\n",
        "    else: \n",
        "      positive_counts[word] += 1\n",
        "    total_counts[word] += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IX6QYAZAHWKA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('', 550468),\n",
              " ('the', 173324),\n",
              " ('.', 159654),\n",
              " ('and', 89722),\n",
              " ('a', 83688),\n",
              " ('of', 76855),\n",
              " ('to', 66746),\n",
              " ('is', 57245),\n",
              " ('in', 50215),\n",
              " ('br', 49235)]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positive_counts.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "d9jcE5CGbZab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('', 561462),\n",
              " ('.', 167538),\n",
              " ('the', 163389),\n",
              " ('a', 79321),\n",
              " ('and', 74385),\n",
              " ('of', 69009),\n",
              " ('to', 68974),\n",
              " ('br', 52637),\n",
              " ('is', 50083),\n",
              " ('it', 48327)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "negative_counts.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "56UEs2mpbZlA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('', 1111930),\n",
              " ('the', 336713),\n",
              " ('.', 327192),\n",
              " ('and', 164107),\n",
              " ('a', 163009),\n",
              " ('of', 145864),\n",
              " ('to', 135720),\n",
              " ('is', 107328),\n",
              " ('br', 101872),\n",
              " ('it', 96352)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_counts.most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeZvc1p6dj84"
      },
      "source": [
        "El resultado del conteo muestra que las stopwords están presentes tanto en críticas positivas como en críticas negativas y pueden añadir ruido a la hora crear un modelo de clasificación. ¿Cómo podemos sacar aquellas palabras que son un indicador claro de que se trata de una crítica positiva o negativa? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viJr7UXGeVbu"
      },
      "source": [
        "### 3. Análisis cuantitativo términos: Ratios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmhHY4jvek4X"
      },
      "source": [
        "Vamos a calcular los ratios de aparición de los términos de la siguiente manera: ratio = positive_counts/float(negative_counts + 1).\n",
        "\n",
        "**Nota**: vamos a trabajar unicamente con aquellos términos que **en total** aparecen 101 o más veces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDOywUqOfDli"
      },
      "source": [
        "*   ¿Por qué ese +1 en el denominador?\n",
        "*   A bote pronto, ¿cómo interpretaríamos los resultados? ¿En qué rango se van a mover los ratios?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ktFv5uKydaCP"
      },
      "outputs": [],
      "source": [
        "pos_neg_ratios = Counter()\n",
        "\n",
        "# Calcula el ratio para los término más comunes\n",
        "for term,cnt in list(total_counts.most_common()):\n",
        "  ### Inserta tu codigo aqui\n",
        "  if cnt > 100:\n",
        "    pos_neg_ratios[term] = positive_counts[term]/float(negative_counts[term] + 1)\n",
        "  else:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "O2BnMZPsf3_7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('edie', 109.0),\n",
              " ('paulie', 59.0),\n",
              " ('felix', 23.4),\n",
              " ('polanski', 16.833333333333332),\n",
              " ('matthau', 16.555555555555557),\n",
              " ('victoria', 14.6),\n",
              " ('mildred', 13.5),\n",
              " ('gandhi', 12.666666666666666),\n",
              " ('flawless', 11.6),\n",
              " ('superbly', 9.583333333333334),\n",
              " ('perfection', 8.666666666666666),\n",
              " ('astaire', 8.5),\n",
              " ('captures', 7.68),\n",
              " ('voight', 7.615384615384615),\n",
              " ('wonderfully', 7.552631578947368)]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_neg_ratios.most_common(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HVQ2eL6j-66Z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pos-to-neg ratio for 'the' = 1.0607993145235326\n",
            "Pos-to-neg ratio for 'amazing' = 4.022813688212928\n",
            "Pos-to-neg ratio for 'terrible' = 0.17744252873563218\n"
          ]
        }
      ],
      "source": [
        "## Algunos ejemplos que nos ayudan a interpretar los resultados\n",
        "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
        "print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\n",
        "print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaRceyK0gTdi"
      },
      "source": [
        "¿Qué problema tiene esta definición de ratio? ¿Cómo lo solucionamos?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CquUDSegmpV"
      },
      "source": [
        "### 4. Análisis cuantitativo términos: Logaritmos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEFWetNNg2pR"
      },
      "source": [
        "Al aplicar logaritmos a los valores calculados en el apartado anterior hacemos que los valores por debajo de 1 pasen a ser negativos (y con valor absoluto más alto cuanto más cercanos a 0 sean) y además conseguimos que dos términos con frecuencias relativas parecidas pero en críticas de signo distinto tomen valores con valor absoluto parecido y signo contrario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "w6SwM1-5-66d"
      },
      "outputs": [],
      "source": [
        "# Calcula el logaritmo de los ratios para todos los términos\n",
        "## Inserta tu código aqui\n",
        "for term, cnt in list(pos_neg_ratios.most_common()):\n",
        "    pos_neg_ratios[term] = np.log(cnt) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nelsu3orhrz_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('edie', 4.6913478822291435),\n",
              " ('paulie', 4.07753744390572),\n",
              " ('felix', 3.152736022363656),\n",
              " ('polanski', 2.8233610476132043),\n",
              " ('matthau', 2.80672172860924),\n",
              " ('victoria', 2.681021528714291),\n",
              " ('mildred', 2.6026896854443837),\n",
              " ('gandhi', 2.538973871058276),\n",
              " ('flawless', 2.451005098112319),\n",
              " ('superbly', 2.26002547857525),\n",
              " ('perfection', 2.159484249353372),\n",
              " ('astaire', 2.1400661634962708),\n",
              " ('captures', 2.038619547159581),\n",
              " ('voight', 2.030170492673053),\n",
              " ('wonderfully', 2.0218960560332353)]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_neg_ratios.most_common(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ac4dUOgEhnML"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pos-to-neg ratio for 'the' = 0.05902269426102881\n",
            "Pos-to-neg ratio for 'amazing' = 1.3919815802404802\n",
            "Pos-to-neg ratio for 'terrible' = -1.7291085042663878\n"
          ]
        }
      ],
      "source": [
        "## Algunos ejemplos que nos ayudan a interpretar los resultados\n",
        "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
        "print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\n",
        "print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "BuwnIl_Wh8e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('boll', -4.969813299576001),\n",
              " ('uwe', -4.624972813284271),\n",
              " ('seagal', -3.644143560272545),\n",
              " ('unwatchable', -3.258096538021482),\n",
              " ('stinker', -3.2088254890146994),\n",
              " ('mst', -2.9502698994772336),\n",
              " ('incoherent', -2.9368917735310576),\n",
              " ('unfunny', -2.6922395950755678),\n",
              " ('waste', -2.6193845640165536),\n",
              " ('blah', -2.5704288232261625),\n",
              " ('horrid', -2.4849066497880004),\n",
              " ('pointless', -2.4553061800117097),\n",
              " ('atrocious', -2.4259083090260445),\n",
              " ('redeeming', -2.3682390632154826),\n",
              " ('prom', -2.3608540011180215),\n",
              " ('drivel', -2.3470368555648795),\n",
              " ('lousy', -2.307572634505085),\n",
              " ('worst', -2.286987896180378),\n",
              " ('laughable', -2.264363880173848),\n",
              " ('awful', -2.227194247027435),\n",
              " ('poorly', -2.2207550747464135),\n",
              " ('wasting', -2.204604684633842),\n",
              " ('remotely', -2.1972245773362196),\n",
              " ('existent', -2.0794415416798357),\n",
              " ('boredom', -1.995100393246085),\n",
              " ('miserably', -1.9924301646902063),\n",
              " ('sucks', -1.987068221548821),\n",
              " ('uninspired', -1.9832976811269336),\n",
              " ('lame', -1.981767458946166),\n",
              " ('insult', -1.978345424808467)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_neg_ratios.most_common()[:-31:-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hdAIKBvJEKa"
      },
      "source": [
        "### 5. Modelo de clasificación basado en bag of words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD8mLKkKJOaL"
      },
      "source": [
        "Vamos a aplicar la técnica de bag of words paso a paso a cada una de las críticas con el objetivo de convertirlas en vectores numéricos que sirvan de features de nuestro modelo.\n",
        "\n",
        "#### Primer paso: construir el conjunto de palabras de nuestro vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XbWDpvonhp7n"
      },
      "outputs": [],
      "source": [
        "vocab = set(total_counts.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ASu4GwbSJt_u"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "74074"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size = len(vocab)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeneoUAXKRe5"
      },
      "source": [
        "#### Segundo paso: construímos un vector del tamaño de nuestro vocabulario. Para ganar tiempo lo creamos como un vector entero de 0s usando la función de numpy zeros()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "re4cRsBcJy9L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "zeros = np.zeros(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FwlXPMQUKMSp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-wjmc3TKl7n"
      },
      "source": [
        "#### Tercer paso: asignar a cada palabra un índice del vector y crear una tabla maestra que guarde esta relación y nos permita crear fácilmente nuestros vectores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WyTGXExmKOto"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'': 0,\n",
              " 'lawful': 1,\n",
              " 'afield': 2,\n",
              " 'leporid': 3,\n",
              " 'meadowlands': 4,\n",
              " 'von': 5,\n",
              " 'sometimes': 6,\n",
              " 'obtained': 7,\n",
              " 'tiburon': 8,\n",
              " 'mulling': 9,\n",
              " 'praise': 10,\n",
              " 'hmmmmmmmm': 11,\n",
              " 'pseudolesbian': 12,\n",
              " 'karrer': 13,\n",
              " 'charles': 14,\n",
              " 'sabotaged': 15,\n",
              " 'hardcase': 16,\n",
              " 'lps': 17,\n",
              " 'slavers': 18,\n",
              " 'skilfully': 19,\n",
              " 'mya': 20,\n",
              " 'shadow': 21,\n",
              " 'oy': 22,\n",
              " 'staggeringly': 23,\n",
              " 'stroheim': 24,\n",
              " 'franziska': 25,\n",
              " 'alternante': 26,\n",
              " 'emoted': 27,\n",
              " 'cogently': 28,\n",
              " 'neeson': 29,\n",
              " 'himmesh': 30,\n",
              " 'jigsaw': 31,\n",
              " 'surprise': 32,\n",
              " 'distributor': 33,\n",
              " 'musicals': 34,\n",
              " 'optioned': 35,\n",
              " 'babysit': 36,\n",
              " 'baggot': 37,\n",
              " 'vetoes': 38,\n",
              " 'hyperventilate': 39,\n",
              " 'illness': 40,\n",
              " 'klause': 41,\n",
              " 'fool': 42,\n",
              " 'waheeda': 43,\n",
              " 'windlass': 44,\n",
              " 'riots': 45,\n",
              " 'translating': 46,\n",
              " 'eliminating': 47,\n",
              " 'ante': 48,\n",
              " 'empathize': 49,\n",
              " 'bullhit': 50,\n",
              " 'wench': 51,\n",
              " 'grada': 52,\n",
              " 'bunker': 53,\n",
              " 'schubert': 54,\n",
              " 'dc': 55,\n",
              " 'sympathies': 56,\n",
              " 'gamecube': 57,\n",
              " 'boldly': 58,\n",
              " 'conceits': 59,\n",
              " 'fahrt': 60,\n",
              " 'incoherency': 61,\n",
              " 'familiarly': 62,\n",
              " 'johnnymacbest': 63,\n",
              " 'orlando': 64,\n",
              " 'whuppin': 65,\n",
              " 'oriented': 66,\n",
              " 'algerian': 67,\n",
              " 'fims': 68,\n",
              " 'grinning': 69,\n",
              " 'fte': 70,\n",
              " 'unrecognised': 71,\n",
              " 'otakon': 72,\n",
              " 'skye': 73,\n",
              " 'installing': 74,\n",
              " 'enablers': 75,\n",
              " 'slurpee': 76,\n",
              " 'provisional': 77,\n",
              " 'icc': 78,\n",
              " 'ringer': 79,\n",
              " 'meeting': 80,\n",
              " 'scharzenfartz': 81,\n",
              " 'house': 82,\n",
              " 'prefaced': 83,\n",
              " 'pities': 84,\n",
              " 'raced': 85,\n",
              " 'bochner': 86,\n",
              " 'signifiers': 87,\n",
              " 'horrors': 88,\n",
              " 'hapsburgs': 89,\n",
              " 'bergstrom': 90,\n",
              " 'pairings': 91,\n",
              " 'not': 92,\n",
              " 'doh': 93,\n",
              " 'proxate': 94,\n",
              " 'suggested': 95,\n",
              " 'sxsw': 96,\n",
              " 'davenport': 97,\n",
              " 'fairer': 98,\n",
              " 'cocktails': 99,\n",
              " 'tragic': 100,\n",
              " 'rove': 101,\n",
              " 'enticements': 102,\n",
              " 'centrality': 103,\n",
              " 'noriaki': 104,\n",
              " 'firefly': 105,\n",
              " 'joyously': 106,\n",
              " 'lithp': 107,\n",
              " 'trilling': 108,\n",
              " 'meteorites': 109,\n",
              " 'interplanetary': 110,\n",
              " 'shemp': 111,\n",
              " 'arkoff': 112,\n",
              " 'duster': 113,\n",
              " 'hath': 114,\n",
              " 'bartleby': 115,\n",
              " 'broods': 116,\n",
              " 'roshan': 117,\n",
              " 'concho': 118,\n",
              " 'mostly': 119,\n",
              " 'naturalizing': 120,\n",
              " 'beaus': 121,\n",
              " 'chasity': 122,\n",
              " 'santa': 123,\n",
              " 'behr': 124,\n",
              " 'beckham': 125,\n",
              " 'auctioned': 126,\n",
              " 'ciggy': 127,\n",
              " 'intenational': 128,\n",
              " 'volptuous': 129,\n",
              " 'gradual': 130,\n",
              " 'irrational': 131,\n",
              " 'frankenfish': 132,\n",
              " 'dinosaur': 133,\n",
              " 'domaine': 134,\n",
              " 'metin': 135,\n",
              " 'sniffle': 136,\n",
              " 'derita': 137,\n",
              " 'sundae': 138,\n",
              " 'chakiris': 139,\n",
              " 'priyanaka': 140,\n",
              " 'stalling': 141,\n",
              " 'reenactments': 142,\n",
              " 'laundrette': 143,\n",
              " 'ziltch': 144,\n",
              " 'astronomical': 145,\n",
              " 'bloc': 146,\n",
              " 'speilbergs': 147,\n",
              " 'beko': 148,\n",
              " 'studmuffins': 149,\n",
              " 'weired': 150,\n",
              " 'smaller': 151,\n",
              " 'chockful': 152,\n",
              " 'catweazle': 153,\n",
              " 'electrolysis': 154,\n",
              " 'comes': 155,\n",
              " 'crisper': 156,\n",
              " 'hamptons': 157,\n",
              " 'satisfies': 158,\n",
              " 'zagros': 159,\n",
              " 'thad': 160,\n",
              " 'darby': 161,\n",
              " 'anbu': 162,\n",
              " 'commiserated': 163,\n",
              " 'encouraging': 164,\n",
              " 'cleaned': 165,\n",
              " 'nibble': 166,\n",
              " 'quentine': 167,\n",
              " 'pull': 168,\n",
              " 'slovak': 169,\n",
              " 'radioing': 170,\n",
              " 'ethnical': 171,\n",
              " 'ari': 172,\n",
              " 'nubb': 173,\n",
              " 'favortism': 174,\n",
              " 'macnamara': 175,\n",
              " 'overpaid': 176,\n",
              " 'muffling': 177,\n",
              " 'transportation': 178,\n",
              " 'awakened': 179,\n",
              " 'aviatrix': 180,\n",
              " 'earner': 181,\n",
              " 'celery': 182,\n",
              " 'karas': 183,\n",
              " 'bwitch': 184,\n",
              " 'supplemented': 185,\n",
              " 'flagellistic': 186,\n",
              " 'lambastes': 187,\n",
              " 'trigger': 188,\n",
              " 'sag': 189,\n",
              " 'straddle': 190,\n",
              " 'mayfield': 191,\n",
              " 'celebrates': 192,\n",
              " 'writter': 193,\n",
              " 'raphaelson': 194,\n",
              " 'mendel': 195,\n",
              " 'jove': 196,\n",
              " 'hangers': 197,\n",
              " 'frolick': 198,\n",
              " 'everlasting': 199,\n",
              " 'washoe': 200,\n",
              " 'hawk': 201,\n",
              " 'vomiting': 202,\n",
              " 'triloki': 203,\n",
              " 'yokia': 204,\n",
              " 'replaces': 205,\n",
              " 'spontaniously': 206,\n",
              " 'cheating': 207,\n",
              " 'sunday': 208,\n",
              " 'scooping': 209,\n",
              " 'arduously': 210,\n",
              " 'pit': 211,\n",
              " 'whay': 212,\n",
              " 'angsting': 213,\n",
              " 'suppressor': 214,\n",
              " 'camazotz': 215,\n",
              " 'koschmidder': 216,\n",
              " 'simpering': 217,\n",
              " 'farrells': 218,\n",
              " 'unyielding': 219,\n",
              " 'tousled': 220,\n",
              " 'triviata': 221,\n",
              " 'bolger': 222,\n",
              " 'terrifiying': 223,\n",
              " 'writings': 224,\n",
              " 'ykai': 225,\n",
              " 'paisley': 226,\n",
              " 'brotherhood': 227,\n",
              " 'gov': 228,\n",
              " 'believably': 229,\n",
              " 'hash': 230,\n",
              " 'jackanape': 231,\n",
              " 'arbanville': 232,\n",
              " 'whistleblowing': 233,\n",
              " 'businessman': 234,\n",
              " 'givin': 235,\n",
              " 'pineal': 236,\n",
              " 'indefinite': 237,\n",
              " 'commendation': 238,\n",
              " 'higgin': 239,\n",
              " 'laughing': 240,\n",
              " 'splendour': 241,\n",
              " 'noche': 242,\n",
              " 'headline': 243,\n",
              " 'bats': 244,\n",
              " 'kickboxer': 245,\n",
              " 'pests': 246,\n",
              " 'condoleezza': 247,\n",
              " 'sake': 248,\n",
              " 'hallam': 249,\n",
              " 'items': 250,\n",
              " 'reopened': 251,\n",
              " 'truncated': 252,\n",
              " 'acquaint': 253,\n",
              " 'redeem': 254,\n",
              " 'traitor': 255,\n",
              " 'dufus': 256,\n",
              " 'dullest': 257,\n",
              " 'bashings': 258,\n",
              " 'scuddamore': 259,\n",
              " 'supersoldiers': 260,\n",
              " 'horthy': 261,\n",
              " 'rarer': 262,\n",
              " 'puppets': 263,\n",
              " 'informational': 264,\n",
              " 'hutch': 265,\n",
              " 'rowell': 266,\n",
              " 'settee': 267,\n",
              " 'hepcats': 268,\n",
              " 'inoculates': 269,\n",
              " 'rosza': 270,\n",
              " 'estonian': 271,\n",
              " 'tak': 272,\n",
              " 'kharbanda': 273,\n",
              " 'obsess': 274,\n",
              " 'seminal': 275,\n",
              " 'blood': 276,\n",
              " 'sensationalized': 277,\n",
              " 'mcc': 278,\n",
              " 'sensory': 279,\n",
              " 'slapsticky': 280,\n",
              " 'cory': 281,\n",
              " 'exposed': 282,\n",
              " 'uckridge': 283,\n",
              " 'rituals': 284,\n",
              " 'spiritited': 285,\n",
              " 'tastic': 286,\n",
              " 'floozie': 287,\n",
              " 'dissatisfied': 288,\n",
              " 'travis': 289,\n",
              " 'tease': 290,\n",
              " 'sic': 291,\n",
              " 'mammaries': 292,\n",
              " 'gretchen': 293,\n",
              " 'bleeds': 294,\n",
              " 'scum': 295,\n",
              " 'outshining': 296,\n",
              " 'grooms': 297,\n",
              " 'procure': 298,\n",
              " 'confiscating': 299,\n",
              " 'lives': 300,\n",
              " 'greenbacks': 301,\n",
              " 'ironed': 302,\n",
              " 'mitch': 303,\n",
              " 'yoga': 304,\n",
              " 'tutu': 305,\n",
              " 'etzel': 306,\n",
              " 'gillmore': 307,\n",
              " 'rufus': 308,\n",
              " 'cathryn': 309,\n",
              " 'teammates': 310,\n",
              " 'smithereens': 311,\n",
              " 'librarianship': 312,\n",
              " 'dahlia': 313,\n",
              " 'glare': 314,\n",
              " 'hamilton': 315,\n",
              " 'veddy': 316,\n",
              " 'sophie': 317,\n",
              " 'kilcher': 318,\n",
              " 'vichy': 319,\n",
              " 'markey': 320,\n",
              " 'sympathiser': 321,\n",
              " 'lumbers': 322,\n",
              " 'curtailing': 323,\n",
              " 'reinforcing': 324,\n",
              " 'impudent': 325,\n",
              " 'contract': 326,\n",
              " 'censoring': 327,\n",
              " 'quacking': 328,\n",
              " 'moh': 329,\n",
              " 'kelley': 330,\n",
              " 'howze': 331,\n",
              " 'unstuck': 332,\n",
              " 'demme': 333,\n",
              " 'mclaglen': 334,\n",
              " 'anaheim': 335,\n",
              " 'skids': 336,\n",
              " 'trods': 337,\n",
              " 'leat': 338,\n",
              " 'condorwhich': 339,\n",
              " 'rebenga': 340,\n",
              " 'etvorka': 341,\n",
              " 'desultory': 342,\n",
              " 'bajpai': 343,\n",
              " 'raconteur': 344,\n",
              " 'grieg': 345,\n",
              " 'coda': 346,\n",
              " 'deriviative': 347,\n",
              " 'emplacement': 348,\n",
              " 'sherwin': 349,\n",
              " 'existences': 350,\n",
              " 'expanding': 351,\n",
              " 'repel': 352,\n",
              " 'wada': 353,\n",
              " 'dreamer': 354,\n",
              " 'lyrics': 355,\n",
              " 'danny': 356,\n",
              " 'chaney': 357,\n",
              " 'peripheral': 358,\n",
              " 'caramel': 359,\n",
              " 'tickles': 360,\n",
              " 'harni': 361,\n",
              " 'angelwas': 362,\n",
              " 'auditory': 363,\n",
              " 'termination': 364,\n",
              " 'clubfoot': 365,\n",
              " 'dyslexic': 366,\n",
              " 'stables': 367,\n",
              " 'looped': 368,\n",
              " 'jugde': 369,\n",
              " 'hirehotmail': 370,\n",
              " 'cardboard': 371,\n",
              " 'nondenominational': 372,\n",
              " 'djjohn': 373,\n",
              " 'uth': 374,\n",
              " 'extemporised': 375,\n",
              " 'salli': 376,\n",
              " 'nm': 377,\n",
              " 'beached': 378,\n",
              " 'slovakian': 379,\n",
              " 'pilots': 380,\n",
              " 'jeeves': 381,\n",
              " 'blended': 382,\n",
              " 'bauble': 383,\n",
              " 'phoren': 384,\n",
              " 'ordination': 385,\n",
              " 'darts': 386,\n",
              " 'impotence': 387,\n",
              " 'overacted': 388,\n",
              " 'lard': 389,\n",
              " 'displays': 390,\n",
              " 'waalkes': 391,\n",
              " 'ende': 392,\n",
              " 'unprejudiced': 393,\n",
              " 'prostitutes': 394,\n",
              " 'shopkeeper': 395,\n",
              " 'meaner': 396,\n",
              " 'dower': 397,\n",
              " 'pagemaster': 398,\n",
              " 'descendant': 399,\n",
              " 'pathologists': 400,\n",
              " 'byproduct': 401,\n",
              " 'bullhorns': 402,\n",
              " 'handcrafted': 403,\n",
              " 'pyromaniac': 404,\n",
              " 'bezzerides': 405,\n",
              " 'knowledge': 406,\n",
              " 'sluggish': 407,\n",
              " 'pluckish': 408,\n",
              " 'georgina': 409,\n",
              " 'droves': 410,\n",
              " 'vili': 411,\n",
              " 'habitat': 412,\n",
              " 'trickiest': 413,\n",
              " 'filicide': 414,\n",
              " 'bigas': 415,\n",
              " 'visited': 416,\n",
              " 'aros': 417,\n",
              " 'overzealous': 418,\n",
              " 'eurocult': 419,\n",
              " 'visiteurs': 420,\n",
              " 'expiration': 421,\n",
              " 'aissa': 422,\n",
              " 'saleable': 423,\n",
              " 'raskolnikov': 424,\n",
              " 'frasers': 425,\n",
              " 'hypersensitive': 426,\n",
              " 'cacoyanis': 427,\n",
              " 'mihajlovic': 428,\n",
              " 'terminated': 429,\n",
              " 'iguana': 430,\n",
              " 'deadfall': 431,\n",
              " 'eradicating': 432,\n",
              " 'controversially': 433,\n",
              " 'blotched': 434,\n",
              " 'texts': 435,\n",
              " 'completist': 436,\n",
              " 'hobbyhorse': 437,\n",
              " 'condescend': 438,\n",
              " 'elman': 439,\n",
              " 'agamemnon': 440,\n",
              " 'sonheim': 441,\n",
              " 'intrusive': 442,\n",
              " 'isham': 443,\n",
              " 'cretinous': 444,\n",
              " 'helping': 445,\n",
              " 'quai': 446,\n",
              " 'coghlan': 447,\n",
              " 'weinstein': 448,\n",
              " 'tumult': 449,\n",
              " 'gassing': 450,\n",
              " 'valvoline': 451,\n",
              " 'scarcity': 452,\n",
              " 'disruptive': 453,\n",
              " 'outlaws': 454,\n",
              " 'bloodshet': 455,\n",
              " 'rotld': 456,\n",
              " 'leave': 457,\n",
              " 'filmette': 458,\n",
              " 'approaching': 459,\n",
              " 'censure': 460,\n",
              " 'fountain': 461,\n",
              " 'merrie': 462,\n",
              " 'paulista': 463,\n",
              " 'pining': 464,\n",
              " 'trumpery': 465,\n",
              " 'satanised': 466,\n",
              " 'virtuouslypaced': 467,\n",
              " 'focus': 468,\n",
              " 'alok': 469,\n",
              " 'unbelievers': 470,\n",
              " 'resumed': 471,\n",
              " 'townie': 472,\n",
              " 'engulfed': 473,\n",
              " 'diagnosed': 474,\n",
              " 'gumshoes': 475,\n",
              " 'registers': 476,\n",
              " 'horridly': 477,\n",
              " 'progressional': 478,\n",
              " 'jewel': 479,\n",
              " 'chracter': 480,\n",
              " 'prickett': 481,\n",
              " 'sequiturs': 482,\n",
              " 'schlessinger': 483,\n",
              " 'plonk': 484,\n",
              " 'maximilian': 485,\n",
              " 'saccharin': 486,\n",
              " 'boofs': 487,\n",
              " 'safe': 488,\n",
              " 'puppeteer': 489,\n",
              " 'vocational': 490,\n",
              " 'rabochiy': 491,\n",
              " 'darla': 492,\n",
              " 'slumdog': 493,\n",
              " 'maltese': 494,\n",
              " 'codswallop': 495,\n",
              " 'wook': 496,\n",
              " 'hooting': 497,\n",
              " 'winterbottom': 498,\n",
              " 'golf': 499,\n",
              " 'homo': 500,\n",
              " 'huey': 501,\n",
              " 'inaccessible': 502,\n",
              " 'circumventing': 503,\n",
              " 'monikers': 504,\n",
              " 'bluth': 505,\n",
              " 'mcmahonagement': 506,\n",
              " 'countryside': 507,\n",
              " 'therapy': 508,\n",
              " 'trespassed': 509,\n",
              " 'boggins': 510,\n",
              " 'jungles': 511,\n",
              " 'shelled': 512,\n",
              " 'drinkable': 513,\n",
              " 'guncrazy': 514,\n",
              " 'politically': 515,\n",
              " 'marilla': 516,\n",
              " 'metaphoric': 517,\n",
              " 'hardyz': 518,\n",
              " 'hounslow': 519,\n",
              " 'allowed': 520,\n",
              " 'zelah': 521,\n",
              " 'around': 522,\n",
              " 'souler': 523,\n",
              " 'traveled': 524,\n",
              " 'dodgeball': 525,\n",
              " 'kage': 526,\n",
              " 'rung': 527,\n",
              " 'dovey': 528,\n",
              " 'driller': 529,\n",
              " 'housemaid': 530,\n",
              " 'beullar': 531,\n",
              " 'bullit': 532,\n",
              " 'unneeded': 533,\n",
              " 'easterns': 534,\n",
              " 'monteiro': 535,\n",
              " 'fraticelli': 536,\n",
              " 'punctuations': 537,\n",
              " 'filmmaking': 538,\n",
              " 'throbbing': 539,\n",
              " 'maintains': 540,\n",
              " 'undertone': 541,\n",
              " 'bushes': 542,\n",
              " 'pratt': 543,\n",
              " 'redheaded': 544,\n",
              " 'polson': 545,\n",
              " 'merlyn': 546,\n",
              " 'gravediggers': 547,\n",
              " 'authorty': 548,\n",
              " 'satsuo': 549,\n",
              " 'dvder': 550,\n",
              " 'contaminants': 551,\n",
              " 'autie': 552,\n",
              " 'sexploitation': 553,\n",
              " 'blai': 554,\n",
              " 'initiates': 555,\n",
              " 'altamont': 556,\n",
              " 'whines': 557,\n",
              " 'quine': 558,\n",
              " 'mofu': 559,\n",
              " 'symptoms': 560,\n",
              " 'mwuhahahaa': 561,\n",
              " 'face': 562,\n",
              " 'schildkraut': 563,\n",
              " 'rubali': 564,\n",
              " 'stayed': 565,\n",
              " 'adriana': 566,\n",
              " 'romcomic': 567,\n",
              " 'aff': 568,\n",
              " 'differentiation': 569,\n",
              " 'chainsmoking': 570,\n",
              " 'hazardous': 571,\n",
              " 'miah': 572,\n",
              " 'chronologies': 573,\n",
              " 'shida': 574,\n",
              " 'billed': 575,\n",
              " 'nanadini': 576,\n",
              " 'linden': 577,\n",
              " 'chaliya': 578,\n",
              " 'spurt': 579,\n",
              " 'coolidge': 580,\n",
              " 'baxtor': 581,\n",
              " 'shihito': 582,\n",
              " 'codeveronica': 583,\n",
              " 'dibler': 584,\n",
              " 'sleepwalk': 585,\n",
              " 'students': 586,\n",
              " 'torments': 587,\n",
              " 'shadmehr': 588,\n",
              " 'kitchens': 589,\n",
              " 'turveydrop': 590,\n",
              " 'bristle': 591,\n",
              " 'deville': 592,\n",
              " 'schtupping': 593,\n",
              " 'maclachlan': 594,\n",
              " 'slogan': 595,\n",
              " 'devourer': 596,\n",
              " 'pragmatically': 597,\n",
              " 'hugger': 598,\n",
              " 'zeppelins': 599,\n",
              " 'fonts': 600,\n",
              " 'yugoslavia': 601,\n",
              " 'guhther': 602,\n",
              " 'illegal': 603,\n",
              " 'baying': 604,\n",
              " 'leonida': 605,\n",
              " 'sefa': 606,\n",
              " 'linking': 607,\n",
              " 'blades': 608,\n",
              " 'gyudon': 609,\n",
              " 'oss': 610,\n",
              " 'rotates': 611,\n",
              " 'lovelock': 612,\n",
              " 'dsv': 613,\n",
              " 'complained': 614,\n",
              " 'debuting': 615,\n",
              " 'sverak': 616,\n",
              " 'moneyfamefashion': 617,\n",
              " 'argent': 618,\n",
              " 'penance': 619,\n",
              " 'mattress': 620,\n",
              " 'stylus': 621,\n",
              " 'maman': 622,\n",
              " 'yummy': 623,\n",
              " 'opinon': 624,\n",
              " 'intensification': 625,\n",
              " 'henstridge': 626,\n",
              " 'ejaculation': 627,\n",
              " 'beggining': 628,\n",
              " 'jarndyce': 629,\n",
              " 'kaempfen': 630,\n",
              " 'phonus': 631,\n",
              " 'armand': 632,\n",
              " 'dank': 633,\n",
              " 'lucina': 634,\n",
              " 'terry': 635,\n",
              " 'surfboards': 636,\n",
              " 'troublemaker': 637,\n",
              " 'vacate': 638,\n",
              " 'milverton': 639,\n",
              " 'fabulous': 640,\n",
              " 'anchor': 641,\n",
              " 'humbling': 642,\n",
              " 'botox': 643,\n",
              " 'tpb': 644,\n",
              " 'railways': 645,\n",
              " 'fundamentalists': 646,\n",
              " 'masons': 647,\n",
              " 'hesitantly': 648,\n",
              " 'chao': 649,\n",
              " 'ego': 650,\n",
              " 'wrinklies': 651,\n",
              " 'freebie': 652,\n",
              " 'm': 653,\n",
              " 'evidenced': 654,\n",
              " 'uranium': 655,\n",
              " 'kaafi': 656,\n",
              " 'macabrely': 657,\n",
              " 'minty': 658,\n",
              " 'cotangent': 659,\n",
              " 'tsunami': 660,\n",
              " 'waring': 661,\n",
              " 'fifteen': 662,\n",
              " 'vicadin': 663,\n",
              " 'fostering': 664,\n",
              " 'soxers': 665,\n",
              " 'thunderbird': 666,\n",
              " 'synopsize': 667,\n",
              " 'melody': 668,\n",
              " 'kittenishly': 669,\n",
              " 'deepness': 670,\n",
              " 'drewitt': 671,\n",
              " 'guitars': 672,\n",
              " 'kingship': 673,\n",
              " 'excrements': 674,\n",
              " 'sensless': 675,\n",
              " 'detectors': 676,\n",
              " 'emergency': 677,\n",
              " 'surya': 678,\n",
              " 'grindley': 679,\n",
              " 'lexa': 680,\n",
              " 'debit': 681,\n",
              " 'bleak': 682,\n",
              " 'british': 683,\n",
              " 'mindset': 684,\n",
              " 'crock': 685,\n",
              " 'choking': 686,\n",
              " 'pooh': 687,\n",
              " 'defenetly': 688,\n",
              " 'exclusive': 689,\n",
              " 'larissa': 690,\n",
              " 'hoppe': 691,\n",
              " 'queries': 692,\n",
              " 'hault': 693,\n",
              " 'humaine': 694,\n",
              " 'journalist': 695,\n",
              " 'undertook': 696,\n",
              " 'bayou': 697,\n",
              " 'tag': 698,\n",
              " 'unsuitable': 699,\n",
              " 'physicist': 700,\n",
              " 'horsewhips': 701,\n",
              " 'sleazebags': 702,\n",
              " 'smita': 703,\n",
              " 'jagged': 704,\n",
              " 'vidpic': 705,\n",
              " 'mist': 706,\n",
              " 'sciorra': 707,\n",
              " 'benedetti': 708,\n",
              " 'hatchard': 709,\n",
              " 'vina': 710,\n",
              " 'bletchly': 711,\n",
              " 'unusually': 712,\n",
              " 'strangelove': 713,\n",
              " 'andalthough': 714,\n",
              " 'corrected': 715,\n",
              " 'sacredness': 716,\n",
              " 'accusing': 717,\n",
              " 'pointe': 718,\n",
              " 'distill': 719,\n",
              " 'duping': 720,\n",
              " 'trunks': 721,\n",
              " 'rossini': 722,\n",
              " 'etcetera': 723,\n",
              " 'voight': 724,\n",
              " 'thrifty': 725,\n",
              " 'mouton': 726,\n",
              " 'cess': 727,\n",
              " 'density': 728,\n",
              " 'toussaint': 729,\n",
              " 'geeze': 730,\n",
              " 'consummate': 731,\n",
              " 'kensington': 732,\n",
              " 'vicar': 733,\n",
              " 'normalizing': 734,\n",
              " 'byronic': 735,\n",
              " 'marielitos': 736,\n",
              " 'telescopic': 737,\n",
              " 'clueless': 738,\n",
              " 'geyser': 739,\n",
              " 'vision': 740,\n",
              " 'chandu': 741,\n",
              " 'confining': 742,\n",
              " 'hein': 743,\n",
              " 'utilizing': 744,\n",
              " 'amusement': 745,\n",
              " 'anual': 746,\n",
              " 'yaks': 747,\n",
              " 'honkytonks': 748,\n",
              " 'preposterously': 749,\n",
              " 'shagging': 750,\n",
              " 'brackets': 751,\n",
              " 'cornwall': 752,\n",
              " 'cheesiest': 753,\n",
              " 'remedios': 754,\n",
              " 'comp': 755,\n",
              " 'princely': 756,\n",
              " 'predefined': 757,\n",
              " 'spruce': 758,\n",
              " 'everet': 759,\n",
              " 'quantity': 760,\n",
              " 'rekindling': 761,\n",
              " 'expedient': 762,\n",
              " 'overlapped': 763,\n",
              " 'dsm': 764,\n",
              " 'gap': 765,\n",
              " 'servered': 766,\n",
              " 'syrianna': 767,\n",
              " 'stinker': 768,\n",
              " 'megalomaniacal': 769,\n",
              " 'closups': 770,\n",
              " 'pantangeli': 771,\n",
              " 'conspirators': 772,\n",
              " 'horniphobia': 773,\n",
              " 'courttv': 774,\n",
              " 'nestled': 775,\n",
              " 'hellborn': 776,\n",
              " 'lapse': 777,\n",
              " 'delay': 778,\n",
              " 'sweeter': 779,\n",
              " 'mollifies': 780,\n",
              " 'kont': 781,\n",
              " 'schoedsack': 782,\n",
              " 'farris': 783,\n",
              " 'mutilations': 784,\n",
              " 'decayed': 785,\n",
              " 'itll': 786,\n",
              " 'convince': 787,\n",
              " 'vulgate': 788,\n",
              " 'imp': 789,\n",
              " 'coleridge': 790,\n",
              " 'strikingly': 791,\n",
              " 'muddled': 792,\n",
              " 'schoenaerts': 793,\n",
              " 'blends': 794,\n",
              " 'healed': 795,\n",
              " 'pasts': 796,\n",
              " 'inviolable': 797,\n",
              " 'abdominal': 798,\n",
              " 'mam': 799,\n",
              " 'shackled': 800,\n",
              " 'heures': 801,\n",
              " 'upswept': 802,\n",
              " 'obs': 803,\n",
              " 'wallbangers': 804,\n",
              " 'shingles': 805,\n",
              " 'confine': 806,\n",
              " 'connory': 807,\n",
              " 'frequent': 808,\n",
              " 'reimann': 809,\n",
              " 'snidely': 810,\n",
              " 'levy': 811,\n",
              " 'twined': 812,\n",
              " 'lions': 813,\n",
              " 'reef': 814,\n",
              " 'shrewdly': 815,\n",
              " 'visionaries': 816,\n",
              " 'talen': 817,\n",
              " 'chickens': 818,\n",
              " 'nicer': 819,\n",
              " 'dialect': 820,\n",
              " 'bogroll': 821,\n",
              " 'yc': 822,\n",
              " 'wilke': 823,\n",
              " 'artem': 824,\n",
              " 'guerin': 825,\n",
              " 'classism': 826,\n",
              " 'fuming': 827,\n",
              " 'gittes': 828,\n",
              " 'discs': 829,\n",
              " 'moviefreak': 830,\n",
              " 'murkily': 831,\n",
              " 'navigable': 832,\n",
              " 'trawled': 833,\n",
              " 'ola': 834,\n",
              " 'flabbergasting': 835,\n",
              " 'spanked': 836,\n",
              " 'inflected': 837,\n",
              " 'knob': 838,\n",
              " 'quieter': 839,\n",
              " 'brainwash': 840,\n",
              " 'yanos': 841,\n",
              " 'gopher': 842,\n",
              " 'braveheart': 843,\n",
              " 'helmets': 844,\n",
              " 'fightm': 845,\n",
              " 'vemork': 846,\n",
              " 'unironic': 847,\n",
              " 'musalman': 848,\n",
              " 'grist': 849,\n",
              " 'squeezes': 850,\n",
              " 'fews': 851,\n",
              " 'glum': 852,\n",
              " 'clanging': 853,\n",
              " 'exploitationer': 854,\n",
              " 'enhance': 855,\n",
              " 'thingamajig': 856,\n",
              " 'appeal': 857,\n",
              " 'logistical': 858,\n",
              " 'taoist': 859,\n",
              " 'chiaroscuro': 860,\n",
              " 'consumingly': 861,\n",
              " 'panchamda': 862,\n",
              " 'flawlessly': 863,\n",
              " 'expansion': 864,\n",
              " 'collector': 865,\n",
              " 'stuntwork': 866,\n",
              " 'cussler': 867,\n",
              " 'taxes': 868,\n",
              " 'tedra': 869,\n",
              " 'nlson': 870,\n",
              " 'bucatinsky': 871,\n",
              " 'ahista': 872,\n",
              " 'intricacies': 873,\n",
              " 'dayan': 874,\n",
              " 'reread': 875,\n",
              " 'supposably': 876,\n",
              " 'ithot': 877,\n",
              " 'auditioned': 878,\n",
              " 'escapist': 879,\n",
              " 'snails': 880,\n",
              " 'bogs': 881,\n",
              " 'musican': 882,\n",
              " 'cowering': 883,\n",
              " 'onj': 884,\n",
              " 'flounce': 885,\n",
              " 'peacemaker': 886,\n",
              " 'cuteness': 887,\n",
              " 'anually': 888,\n",
              " 'garrigan': 889,\n",
              " 'calhern': 890,\n",
              " 'sm': 891,\n",
              " 'flared': 892,\n",
              " 'howlers': 893,\n",
              " 'skates': 894,\n",
              " 'shorter': 895,\n",
              " 'deflower': 896,\n",
              " 'peter': 897,\n",
              " 'millie': 898,\n",
              " 'consistence': 899,\n",
              " 'eratic': 900,\n",
              " 'totty': 901,\n",
              " 'patronised': 902,\n",
              " 'toothy': 903,\n",
              " 'wournow': 904,\n",
              " 'saccharine': 905,\n",
              " 'sal': 906,\n",
              " 'inquire': 907,\n",
              " 'inamorata': 908,\n",
              " 'nivoli': 909,\n",
              " 'advise': 910,\n",
              " 'algy': 911,\n",
              " 'mears': 912,\n",
              " 'frameworks': 913,\n",
              " 'deities': 914,\n",
              " 'sudetanland': 915,\n",
              " 'sherriff': 916,\n",
              " 'discounted': 917,\n",
              " 'spirtas': 918,\n",
              " 'boxcover': 919,\n",
              " 'eel': 920,\n",
              " 'macluhen': 921,\n",
              " 'burwell': 922,\n",
              " 'jewelery': 923,\n",
              " 'misued': 924,\n",
              " 'doran': 925,\n",
              " 'pd': 926,\n",
              " 'mummy': 927,\n",
              " 'primus': 928,\n",
              " 'carltio': 929,\n",
              " 'maslin': 930,\n",
              " 'feore': 931,\n",
              " 'activision': 932,\n",
              " 'feinstone': 933,\n",
              " 'brunhilda': 934,\n",
              " 'balconys': 935,\n",
              " 'floradora': 936,\n",
              " 'artistically': 937,\n",
              " 'xylophone': 938,\n",
              " 'griffen': 939,\n",
              " 'lodgings': 940,\n",
              " 'ruse': 941,\n",
              " 'spectacular': 942,\n",
              " 'ring': 943,\n",
              " 'habits': 944,\n",
              " 'homoerotic': 945,\n",
              " 'fminin': 946,\n",
              " 'grammatically': 947,\n",
              " 'demarcation': 948,\n",
              " 'brownesque': 949,\n",
              " 'deltas': 950,\n",
              " 'trruck': 951,\n",
              " 'tenenkrommend': 952,\n",
              " 'trelkovksy': 953,\n",
              " 'scrapbook': 954,\n",
              " 'tollywood': 955,\n",
              " 'lindfors': 956,\n",
              " 'chickened': 957,\n",
              " 'lurking': 958,\n",
              " 'fills': 959,\n",
              " 'affectations': 960,\n",
              " 'unmercilessly': 961,\n",
              " 'unluckiest': 962,\n",
              " 'yasushi': 963,\n",
              " 'yolu': 964,\n",
              " 'phasered': 965,\n",
              " 'elusively': 966,\n",
              " 'lilith': 967,\n",
              " 'gatt': 968,\n",
              " 'personl': 969,\n",
              " 'redeye': 970,\n",
              " 'unvented': 971,\n",
              " 'reaves': 972,\n",
              " 'unwisely': 973,\n",
              " 'sequences': 974,\n",
              " 'unwraps': 975,\n",
              " 'extremists': 976,\n",
              " 'rush': 977,\n",
              " 'underfoot': 978,\n",
              " 'isabel': 979,\n",
              " 'pederson': 980,\n",
              " 'teatime': 981,\n",
              " 'fouke': 982,\n",
              " 'esmerelda': 983,\n",
              " 'judmila': 984,\n",
              " 'obscenely': 985,\n",
              " 'notting': 986,\n",
              " 'schoolgirl': 987,\n",
              " 'fmvs': 988,\n",
              " 'result': 989,\n",
              " 'weeping': 990,\n",
              " 'sorts': 991,\n",
              " 'increadably': 992,\n",
              " 'sparse': 993,\n",
              " 'jayenge': 994,\n",
              " 'burn': 995,\n",
              " 'mcculley': 996,\n",
              " 'vashti': 997,\n",
              " 'deputies': 998,\n",
              " 'operatic': 999,\n",
              " ...}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creamos un diccionario que tiene como key la palabra y como valor el índice asociado\n",
        "word2index = {}\n",
        "for i,word in enumerate(vocab):\n",
        "    word2index[word] = i\n",
        "    \n",
        "word2index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00djBLcWLe3-"
      },
      "source": [
        "#### Cuarto paso: crear la función que dada una crítica devuelve un vector contando la frecuencia de las palabras utilizadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9Iov2PNeLEw5"
      },
      "outputs": [],
      "source": [
        "## Rellena la función que para cada crítica devuelve el vector asociado aplicando bag of words\n",
        "def bag_of_words(review):\n",
        "  v = np.zeros(vocab_size)\n",
        "  ## Inserta tu código aquí\n",
        "  for word in review.split(' '):\n",
        "    v[word2index[word]] += 1\n",
        "  return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4uR3jCvuSBrf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   '"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "t2iUM_MeSGkP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word2index['']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "3ASg9r1ga6en"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "41699"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word2index[\"bromwell\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "n7BOLYxRMJFL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([18.,  0.,  0., ...,  0.,  0.,  0.])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bag_of_words(reviews[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3KDk4iVB21hQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bag_of_words(reviews[0])[13982]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8e-pUBV5ay1t"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(74074,)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bag_of_words(reviews[0]).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zy1Su0ENDzb"
      },
      "source": [
        "#### Quinto paso: el target de nuestro modelo serán 1s y 0s. Vamos a crear una función que convierta los cadenas POSITIVE y NEGATIVE a 1 y 0. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "LUQ52KX3MLfC"
      },
      "outputs": [],
      "source": [
        "## Rellena la función para que dada la etiqueta en forma de cadena devuelve el entero asociado\n",
        "def target_numerico(label):\n",
        "    return int(label == 'POSITIVE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NXFHGGG8Ngf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_numerico(labels[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3socGi2cP_v4"
      },
      "source": [
        "#### Sexto paso: dividimos los datos que tenemos en train y test (esta vez lo hacemos a ojo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Hiy_hHiNQKHV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5000\n",
            "10000\n"
          ]
        }
      ],
      "source": [
        "training_size = 5000\n",
        "test_size = 10000\n",
        "training_rev = reviews[:training_size]\n",
        "training_lab = labels[:training_size]\n",
        "test_rev = reviews[-test_size:]\n",
        "test_lab = labels[-test_size:]\n",
        "print(len(training_lab))\n",
        "print(len(test_lab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wjjnhbmQ2bR"
      },
      "source": [
        "#### Séptimo paso: calculamos las matrices de entrenamiento y de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "5CnlYbNnNkdA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5000, 74074)\n"
          ]
        }
      ],
      "source": [
        "X = np.empty((len(training_rev), vocab_size))\n",
        "print(X.shape)\n",
        "### Rellena X aquí\n",
        "for i in range(len(training_rev)):\n",
        "    X[i] = bag_of_words(training_rev[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "mDfnC2WRVkAA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 74074)\n"
          ]
        }
      ],
      "source": [
        "X_test = np.empty((len(test_rev), vocab_size))\n",
        "print(X_test.shape)\n",
        "for i in range(len(test_rev)):\n",
        "    X_test[i] = bag_of_words(test_rev[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8dRHQFKVPLaB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5000,)\n"
          ]
        }
      ],
      "source": [
        "y = np.empty((len(training_lab),))\n",
        "print(y.shape)\n",
        "# Rellena y aquí\n",
        "\n",
        "for i in range(len(training_rev)):\n",
        "    y[i] = target_numerico(training_lab[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "wQ8H8PfQVuiC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "y_test = np.empty((len(test_lab),))\n",
        "print(y_test.shape)\n",
        "# Rellena y_test aquí\n",
        "\n",
        "for i in range(len(test_lab)):\n",
        "    y_test[i] = target_numerico(test_lab[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BUgNbNaVZQI"
      },
      "source": [
        "#### Octavo paso: entrenamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "418HbjvnS3R6"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "FFw3UoZDTNrz"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = linear_model.LogisticRegression()\n",
        "model.fit(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHbMoVIvVd37"
      },
      "source": [
        "#### Noveno paso: aplicamos el predict sobre el conjunto de test y vemos qué tal funciona."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "4ew7DEftTOnr"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "jz8FOER4VSYf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9988"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5EMDdavGWEs-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8402"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ZTVPXI4TWHvS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[4312  688]\n",
            " [ 910 4090]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_test, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "qGy6v14K-Ovy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.86      0.84      5000\n",
            "         1.0       0.86      0.82      0.84      5000\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1_6xKsU-cOe"
      },
      "source": [
        "#### Decimo paso: preparamos el código para probar el modelo con cadenas nuevas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Melhwgn7-YVv"
      },
      "outputs": [],
      "source": [
        "# Rellena la función para, dada una crítica, aplicar el modelo que hemos entrenado\n",
        "# e imprimir POSITIVE/NEGATIVE\n",
        "def sentiment_analysis(review):\n",
        "  ## Inserta tu código aqui\n",
        "  vector_input = np.empty((1, vocab_size))\n",
        "  vector_input[0] = bag_of_words(review)\n",
        "  pred = model.predict(vector_input)\n",
        "  if pred == 1:\n",
        "    return 'POSITIVE'\n",
        "  else:\n",
        "    return 'NEGATIVE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "83AM8es9_oNl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'NEGATIVE'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_analysis('movie bad')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "cVkYqDqC_rLm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'NEGATIVE'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_analysis('not horrible')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Rj8IWCGxAHNZ"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'España'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Javier\\Documents\\masterAFI\\17. Datos no estructurados\\TextMining\\practica\\6_Clasificacion_Textos_practica.ipynb Cell 74'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000073?line=0'>1</a>\u001b[0m sentiment_analysis(\u001b[39m'\u001b[39;49m\u001b[39mEspaña\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "\u001b[1;32mc:\\Users\\Javier\\Documents\\masterAFI\\17. Datos no estructurados\\TextMining\\practica\\6_Clasificacion_Textos_practica.ipynb Cell 71'\u001b[0m in \u001b[0;36msentiment_analysis\u001b[1;34m(review)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000070?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msentiment_analysis\u001b[39m(review):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000070?line=3'>4</a>\u001b[0m   \u001b[39m## Inserta tu código aqui\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000070?line=4'>5</a>\u001b[0m   vector_input \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((\u001b[39m1\u001b[39m, vocab_size))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000070?line=5'>6</a>\u001b[0m   vector_input[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m bag_of_words(review)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000070?line=6'>7</a>\u001b[0m   pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(vector_input)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000070?line=7'>8</a>\u001b[0m   \u001b[39mif\u001b[39;00m pred \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
            "\u001b[1;32mc:\\Users\\Javier\\Documents\\masterAFI\\17. Datos no estructurados\\TextMining\\practica\\6_Clasificacion_Textos_practica.ipynb Cell 44'\u001b[0m in \u001b[0;36mbag_of_words\u001b[1;34m(review)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000043?line=3'>4</a>\u001b[0m \u001b[39m## Inserta tu código aquí\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000043?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m review\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000043?line=5'>6</a>\u001b[0m   v[word2index[word]] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000043?line=6'>7</a>\u001b[0m \u001b[39mreturn\u001b[39;00m v\n",
            "\u001b[1;31mKeyError\u001b[0m: 'España'"
          ]
        }
      ],
      "source": [
        "sentiment_analysis('España')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oUKhEDkASes"
      },
      "source": [
        "¿Qué hacemos con el error que se obtiene al meter una palabra que no está en el vocabulario? Solucionar este error es parte de la práctica de la asignatura."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "LxIV-DyqAKUF"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'Cool'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Javier\\Documents\\masterAFI\\17. Datos no estructurados\\TextMining\\practica\\6_Clasificacion_Textos_practica.ipynb Cell 76'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000075?line=0'>1</a>\u001b[0m sentiment_analysis(\u001b[39m'\u001b[39;49m\u001b[39mCool\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "\u001b[1;32mc:\\Users\\Javier\\Documents\\masterAFI\\17. Datos no estructurados\\TextMining\\practica\\6_Clasificacion_Textos_practica.ipynb Cell 71'\u001b[0m in \u001b[0;36msentiment_analysis\u001b[1;34m(review)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000070?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msentiment_analysis\u001b[39m(review):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000070?line=3'>4</a>\u001b[0m   \u001b[39m## Inserta tu código aqui\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000070?line=4'>5</a>\u001b[0m   vector_input \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((\u001b[39m1\u001b[39m, vocab_size))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000070?line=5'>6</a>\u001b[0m   vector_input[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m bag_of_words(review)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000070?line=6'>7</a>\u001b[0m   pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(vector_input)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000070?line=7'>8</a>\u001b[0m   \u001b[39mif\u001b[39;00m pred \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
            "\u001b[1;32mc:\\Users\\Javier\\Documents\\masterAFI\\17. Datos no estructurados\\TextMining\\practica\\6_Clasificacion_Textos_practica.ipynb Cell 44'\u001b[0m in \u001b[0;36mbag_of_words\u001b[1;34m(review)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000043?line=3'>4</a>\u001b[0m \u001b[39m## Inserta tu código aquí\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000043?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m review\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000043?line=5'>6</a>\u001b[0m   v[word2index[word]] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Javier/Documents/masterAFI/17.%20Datos%20no%20estructurados/TextMining/practica/6_Clasificacion_Textos_practica.ipynb#ch0000043?line=6'>7</a>\u001b[0m \u001b[39mreturn\u001b[39;00m v\n",
            "\u001b[1;31mKeyError\u001b[0m: 'Cool'"
          ]
        }
      ],
      "source": [
        "sentiment_analysis('Cool')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDNO9LHVAp6E"
      },
      "source": [
        "Pero si Cool si es una palabra inglesa. ¿Qué ocurre? ¿Cómo lo solucionamos? Esto también es parte de la práctica de la asignatura. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Práctica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modificaremos la función bag_of_words para que, primero, convierta en minúsculas la review que introducimos y, segundo, añada un condicional que compruebe si existen las palabras de la review en nuestro diccionario. Además, crearemos un contador para imprimir por pantalla cuantas palabras no se encontraban en el diccionario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Rellena la función que para cada crítica devuelve el vector asociado aplicando bag of words\n",
        "def bag_of_words(review):\n",
        "  review = review.lower()\n",
        "  v = np.zeros(vocab_size)\n",
        "  words_not_founds = 0\n",
        "  ## Inserta tu código aquí\n",
        "  for word in review.split(' '):\n",
        "    if word not in word2index:\n",
        "        words_not_founds += 1\n",
        "    else:\n",
        "        v[word2index[word]] += 1\n",
        "  print(f'Words not found:  {words_not_founds}')\n",
        "  return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words not found:  1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_analysis('España')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words not found:  0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_analysis('Cool')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "6 Clasificacion Textos.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
